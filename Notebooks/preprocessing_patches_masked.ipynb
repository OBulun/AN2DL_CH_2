{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "020adc77",
   "metadata": {},
   "source": [
    "## **I. Google Colab Initializtion (Only on Colab)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a81ad74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# cur_dir = \"/content/drive/MyDrive/CH2/Notebooks\"\n",
    "# %cd $cur_dir\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ada10e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install torchview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4969644a",
   "metadata": {},
   "source": [
    "## **1. Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "109a22c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "SEED = 42\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "\n",
    "# Set environment variables before importing modules\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "os.environ['MPLCONFIGDIR'] = os.getcwd() + '/configs/'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "# Import necessary modules\n",
    "import logging\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Set seeds for random number generators in NumPy and Python\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "from torchvision.transforms import v2 as transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchview import draw_graph\n",
    "from scipy import ndimage\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Import other libraries\n",
    "import cv2\n",
    "import copy\n",
    "import shutil\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import gc\n",
    "\n",
    "# Configure plot display settings\n",
    "sns.set(font_scale=1.4)\n",
    "sns.set_style('white')\n",
    "plt.rc('font', size=14)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6087eb0c",
   "metadata": {},
   "source": [
    "## **2. Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188fcb47",
   "metadata": {},
   "source": [
    "- Preprocessing pipeline : \n",
    "    - Get Loaded Images\n",
    "    - Create Goo Masks\n",
    "    - Apply Goo Removal + Resizing\n",
    "    - Discard Shrek Images\n",
    "    - Apply the external Masks (optional)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc6208d",
   "metadata": {},
   "source": [
    "### 2.1 Preprocessing Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a2ca48",
   "metadata": {},
   "source": [
    "#### 2.1.1 _get_smart_goo_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9df4948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_smart_goo_mask(img_bgr):\n",
    "    \"\"\"\n",
    "    Internal helper to detect goo using Core & Shell logic + 1px Nudge.\n",
    "    Returns a binary mask (White = Goo, Black = Safe).\n",
    "    \"\"\"\n",
    "    # 1. Convert to HSV\n",
    "    hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # 2. Define Ranges\n",
    "    # CORE: Solid Green (Strict)\n",
    "    core_lower = np.array([35, 100, 50])\n",
    "    core_upper = np.array([85, 255, 255])\n",
    "    \n",
    "    # SHELL: Faint Halo (Loose/Transparent)\n",
    "    shell_lower = np.array([30, 30, 30])\n",
    "    shell_upper = np.array([95, 255, 255])\n",
    "\n",
    "    # 3. Create initial masks\n",
    "    mask_core = cv2.inRange(hsv, core_lower, core_upper)\n",
    "    mask_shell = cv2.inRange(hsv, shell_lower, shell_upper)\n",
    "\n",
    "    # 4. Smart Combine (Connected Components)\n",
    "    # Keep 'Shell' blobs ONLY if they touch 'Core' blobs\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask_shell, connectivity=8)\n",
    "    smart_mask = np.zeros_like(mask_core)\n",
    "\n",
    "    for label_id in range(1, num_labels): # Skip background (0)\n",
    "        blob_mask = (labels == label_id).astype(np.uint8) * 255\n",
    "        \n",
    "        # Check overlap with Core\n",
    "        overlap = cv2.bitwise_and(blob_mask, mask_core)\n",
    "        \n",
    "        # If there is ANY overlap, keep the blob\n",
    "        if cv2.countNonZero(overlap) > 0:\n",
    "            smart_mask = cv2.bitwise_or(smart_mask, blob_mask)\n",
    "\n",
    "    # 5. Fill Holes (in case the goo has shiny reflections)\n",
    "    contours, _ = cv2.findContours(smart_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    final_filled_mask = np.zeros_like(smart_mask)\n",
    "    for contour in contours:\n",
    "        # Minimum area filter (200px) to remove tiny stray noise\n",
    "        if cv2.contourArea(contour) > 200:\n",
    "            cv2.drawContours(final_filled_mask, [contour], -1, (255), thickness=cv2.FILLED)\n",
    "\n",
    "    # 6. The \"1-Pixel Nudge\"\n",
    "    # Safely expand by 1 pixel to cover the final anti-aliased fringe\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    final_expanded_mask = cv2.dilate(final_filled_mask, kernel, iterations=1)\n",
    "\n",
    "    return final_expanded_mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d4f365",
   "metadata": {},
   "source": [
    "#### 2.1.2 remove_goo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12c2ed58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_goo(input_dir, output_dir, target_size=(224, 224), remove_goo=True, save_masks=True, replacement_color=(0, 0, 0)):\n",
    "    \"\"\"\n",
    "    Iterates through input_dir, finds 'img_xxxx', resizes them to target_size, \n",
    "    and saves the result to output_dir.\n",
    "    If remove_goo is True, it replaces green pixels (using Smart Core/Shell logic) with replacement_color.\n",
    "    replacement_color: Tuple of (B, G, R) values. Default is black (0, 0, 0).\n",
    "    \"\"\"\n",
    "    input_dir = Path(input_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Extensions to look for\n",
    "    valid_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}\n",
    "    \n",
    "    # 1. Gather all valid image files first\n",
    "    print(f\"Scanning for images in: {input_dir}...\")\n",
    "    image_files = [\n",
    "        f for f in input_dir.iterdir() \n",
    "        if f.name.startswith('img_') and f.suffix.lower() in valid_extensions\n",
    "    ]\n",
    "    \n",
    "    if not image_files:\n",
    "        print(\"No images found starting with 'img_' in the directory.\")\n",
    "        return\n",
    "\n",
    "    # 2. Iterate with tqdm\n",
    "    count = 0\n",
    "    \n",
    "    for file_path in tqdm(image_files, desc=\"Removing Goo from Images\", unit=\"img\"):\n",
    "        output_path = output_dir / file_path.name\n",
    "        \n",
    "        if output_path.exists():\n",
    "            # Skip silently\n",
    "            continue\n",
    "\n",
    "        img = cv2.imread(str(file_path))\n",
    "        if img is None:\n",
    "            continue\n",
    "            \n",
    "        if target_size is not None:\n",
    "            img = cv2.resize(img, target_size)\n",
    "            \n",
    "        if remove_goo:\n",
    "            # --- NEW SMART GOO LOGIC ---\n",
    "            # Get the smart mask (White = Goo)\n",
    "            goo_mask = _get_smart_goo_mask(img)\n",
    "            \n",
    "            # Invert Goo Mask (White = Safe)\n",
    "            not_goo_mask = cv2.bitwise_not(goo_mask)\n",
    "            \n",
    "            # Apply Mask to keep safe areas (Goo areas become black/0)\n",
    "            img_safe = cv2.bitwise_and(img, img, mask=not_goo_mask)\n",
    "            \n",
    "            # Create background with replacement color\n",
    "            bg = np.full_like(img, replacement_color)\n",
    "            \n",
    "            # Keep background only where Goo is\n",
    "            bg_goo = cv2.bitwise_and(bg, bg, mask=goo_mask)\n",
    "            \n",
    "            # Combine: Safe Image + Colored Goo Areas\n",
    "            img = cv2.add(img_safe, bg_goo)\n",
    "\n",
    "            if save_masks:\n",
    "                # Save the mask (White = Safe/Tissue, Black = Goo)\n",
    "                mask_name = file_path.name.replace('img_', 'goo_mask_', 1)\n",
    "                mask_output_path = os.path.join(output_dir, \"goo_masks\", mask_name)\n",
    "                Path(os.path.dirname(mask_output_path)).mkdir(parents=True, exist_ok=True)\n",
    "                cv2.imwrite(str(mask_output_path), not_goo_mask)\n",
    "            \n",
    "        cv2.imwrite(str(output_path), img)\n",
    "        count += 1\n",
    "\n",
    "    print(f\"Resizing complete. Processed {count} new images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59eb8937",
   "metadata": {},
   "source": [
    "#### 2.1.3 clean_and_save_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63fdde37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_save_masks(goo_masks_dir, external_masks_dir, output_dir, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Loads goo masks (White=Safe) and original external masks.\n",
    "    Removes goo areas from external masks and saves the cleaned versions.\n",
    "    Skips processing if a cleaned mask already exists in the output directory.\n",
    "    \"\"\"\n",
    "    goo_masks_dir = Path(goo_masks_dir)\n",
    "    external_masks_dir = Path(external_masks_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    goo_mask_files = list(goo_masks_dir.glob('goo_mask_*.png'))\n",
    "    \n",
    "    if not goo_mask_files:\n",
    "        print(f\"No goo masks found in {goo_masks_dir}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(goo_mask_files)} goo masks. Checking for existing and processing new masks...\")\n",
    "\n",
    "    processed_count = 0\n",
    "    skipped_count = 0\n",
    "    for goo_mask_path in tqdm(goo_mask_files, desc=\"Cleaning External Masks\"):\n",
    "        # Derive the corresponding output mask name\n",
    "        mask_name = goo_mask_path.name.replace('goo_mask_', 'mask_', 1)\n",
    "        output_path = output_dir / mask_name\n",
    "\n",
    "\n",
    "        # Check if the cleaned mask already exists to skip reprocessing\n",
    "        if output_path.exists():\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "\n",
    "\n",
    "        external_mask_path = external_masks_dir / mask_name\n",
    "        \n",
    "        if not external_mask_path.exists():\n",
    "            # This part was commented out in the original, but it's good practice\n",
    "            # to log when a corresponding file is missing.\n",
    "            # tqdm.write(f\"Warning: External mask not found for {goo_mask_path.name}\")\n",
    "            continue\n",
    "\n",
    "        # Load masks\n",
    "        goo_mask = cv2.imread(str(goo_mask_path), cv2.IMREAD_GRAYSCALE)\n",
    "        external_mask = cv2.imread(str(external_mask_path), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if goo_mask is None or external_mask is None:\n",
    "            tqdm.write(f\"Warning: Could not read one of the masks for {mask_name}\")\n",
    "            continue\n",
    "\n",
    "        # Resize external mask if a target size is specified\n",
    "        if target_size is not None:\n",
    "             external_mask = cv2.resize(external_mask, target_size, interpolation=cv2.INTER_NEAREST)\n",
    "             # Ensure goo_mask also matches the target size\n",
    "             if goo_mask.shape[:2] != (target_size[1], target_size[0]):\n",
    "                 goo_mask = cv2.resize(goo_mask, target_size, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        # Ensure masks are binary (0 or 255)\n",
    "        _, external_mask = cv2.threshold(external_mask, 127, 255, cv2.THRESH_BINARY)\n",
    "        _, goo_mask = cv2.threshold(goo_mask, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Combine masks: The resulting pixel is white only if it's white in BOTH masks.\n",
    "        # This effectively removes \"goo\" areas from the \"region of interest\".\n",
    "        cleaned_mask = cv2.bitwise_and(external_mask, goo_mask)\n",
    "\n",
    "        # Save the final cleaned mask\n",
    "        cv2.imwrite(str(output_path), cleaned_mask)\n",
    "        processed_count += 1\n",
    "\n",
    "    print(\"\\nProcessing complete.\")\n",
    "    print(f\"  - Cleaned and saved: {processed_count} masks to {output_dir}\")\n",
    "    if skipped_count > 0:\n",
    "        print(f\"  - Skipped: {skipped_count} masks that already existed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c4f03f",
   "metadata": {},
   "source": [
    "#### 2.1.4 apply_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82d1ba7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mask(image_path, mask_path, output_path, target_size=(224, 224), remove_goo=True):\n",
    "    \"\"\"\n",
    "    Loads an image and a mask. \n",
    "    If remove_goo is True, it subtracts green pixels (using Smart Core/Shell logic) \n",
    "    from the valid mask area. Resizes and saves the result.\n",
    "    \"\"\"\n",
    "    # 1. Load Image\n",
    "    img = cv2.imread(str(image_path))\n",
    "    if img is None:\n",
    "        tqdm.write(f\"Error: Could not load image at {image_path}\")\n",
    "        return\n",
    "\n",
    "    # 2. Load External Mask (Read as grayscale)\n",
    "    mask = cv2.imread(str(mask_path), 0)\n",
    "    if mask is None:\n",
    "        tqdm.write(f\"Error: Could not load mask at {mask_path}\")\n",
    "        return\n",
    "\n",
    "    # 3. Resize both to target size\n",
    "    if target_size is not None:\n",
    "        img = cv2.resize(img, target_size)\n",
    "        mask = cv2.resize(mask, target_size)\n",
    "\n",
    "    # 4. Standardize External Mask (Binary 0 or 255)\n",
    "    _, binary_mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # 5. Determine Final Mask\n",
    "    if remove_goo:\n",
    "        # --- NEW SMART GOO LOGIC ---\n",
    "        # Get the smart mask (White = Goo)\n",
    "        goo_mask = _get_smart_goo_mask(img)\n",
    "        \n",
    "        # Invert Goo Mask (White = Safe)\n",
    "        not_goo_mask = cv2.bitwise_not(goo_mask)\n",
    "        \n",
    "        # Combine: Must be Tissue (binary_mask) AND Safe (not_goo_mask)\n",
    "        final_mask = cv2.bitwise_and(binary_mask, not_goo_mask)\n",
    "    else:\n",
    "        # --- ORIGINAL LOGIC ---\n",
    "        final_mask = binary_mask\n",
    "\n",
    "    # 6. Apply Final Mask\n",
    "    # Areas outside the final mask become Black (0)\n",
    "    masked_img = cv2.bitwise_and(img, img, mask=final_mask)\n",
    "\n",
    "    # 7. Save result\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(os.path.dirname(str(output_path)), exist_ok=True)\n",
    "    cv2.imwrite(str(output_path), masked_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ef40d9",
   "metadata": {},
   "source": [
    "#### 2.1.5 filter_bright_green_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2e66cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_bright_green_areas(image, lg_H=20, lg_S=45, lg_V=0, ug_H=84, ug_S=255, ug_V=255, dilate_iterations=2):\n",
    "    \"\"\"\n",
    "    Filters out bright green areas from the input image with improved residual removal.\n",
    "    \n",
    "    Args:\n",
    "        image: Input image in RGB format (0-1 range)\n",
    "        lg_H, lg_S, lg_V: Lower bounds for HSV green detection\n",
    "        ug_H, ug_S, ug_V: Upper bounds for HSV green detection\n",
    "        dilate_iterations: Number of dilation iterations to expand mask (removes edge artifacts)\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert from RGB (0-1) to BGR (0-255) for OpenCV\n",
    "    original_bgr = (image * 255).astype(np.uint8)[..., ::-1]\n",
    "\n",
    "    # 1. Convert to HSV (Hue, Saturation, Value)\n",
    "    hsv = cv2.cvtColor(original_bgr, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # 2. Define the \"Bright Green\" Range\n",
    "    lower_green = (lg_H, lg_S, lg_V)\n",
    "    upper_green = (ug_H, ug_S, ug_V)\n",
    "\n",
    "    # Create the initial mask\n",
    "    mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "\n",
    "    # 3. Morphological operations to clean up the mask\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "\n",
    "    # OPEN: Remove small noise\n",
    "    clean_mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "\n",
    "    # DILATE: Expand the mask to catch edge artifacts and residuals\n",
    "    # This ensures we remove green pixels at the boundaries\n",
    "    if dilate_iterations > 0:\n",
    "        clean_mask = cv2.dilate(clean_mask, kernel, iterations=dilate_iterations)\n",
    "\n",
    "    # 4. Additional step: Detect any remaining green-ish pixels\n",
    "    # Create a more aggressive mask for subtle green tones\n",
    "    lower_green_subtle = (max(0, lg_H - 10), max(0, lg_S - 10), 0)\n",
    "    upper_green_subtle = (min(180, ug_H + 10), 255, 255)\n",
    "    subtle_mask = cv2.inRange(hsv, lower_green_subtle, upper_green_subtle)\n",
    "    \n",
    "    # Only keep subtle green pixels that are near the main green area\n",
    "    subtle_mask = cv2.morphologyEx(subtle_mask, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    \n",
    "    # Combine masks\n",
    "    combined_mask = cv2.bitwise_or(clean_mask, subtle_mask)\n",
    "\n",
    "    # 5. Invert mask to keep the useful parts\n",
    "    mask_inv = cv2.bitwise_not(combined_mask)\n",
    "\n",
    "    # 6. Apply the mask\n",
    "    result_bgr = cv2.bitwise_and(original_bgr, original_bgr, mask=mask_inv)\n",
    "\n",
    "    return result_bgr, combined_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1a9a86",
   "metadata": {},
   "source": [
    "#### 2.1.6 analyze_dataset_for_shreks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb8cbc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dataset_for_shreks(directory, shrek_dir, ratio_threshold=0.0125):\n",
    "    shrek_images = []\n",
    "    tissue_images = []\n",
    "    \n",
    "    image_files = glob.glob(os.path.join(directory, 'img_*.png'))\n",
    "    print(f\"Found {len(image_files)} images in {directory}\")\n",
    "\n",
    "    for f in tqdm(image_files, desc=\"Analyzing for Shreks\"):\n",
    "        try:\n",
    "            # Load image (BGR)\n",
    "            img = cv2.imread(f)\n",
    "            if img is None: continue\n",
    "            \n",
    "            # Prepare image for the new filter: Convert BGR to RGB (0-1 float)\n",
    "            img_rgb_norm = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
    "            \n",
    "            # Apply Filter\n",
    "            result_bgr, mask = filter_bright_green_areas(img_rgb_norm)\n",
    "            \n",
    "            # Calculate Ratio of Green Pixels from the combined mask\n",
    "            total_pixels = img.shape[0] * img.shape[1]\n",
    "            green_pixels = np.count_nonzero(mask)\n",
    "            ratio = green_pixels / total_pixels\n",
    "            \n",
    "            # Convert BGR to RGB for plotting\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            entry = {\n",
    "                'name': os.path.basename(f), \n",
    "                'path': f,\n",
    "                'img': img_rgb, \n",
    "                'ratio': ratio,\n",
    "                'mask': mask\n",
    "            }\n",
    "\n",
    "            # === CLASSIFICATION LOGIC ===\n",
    "            if ratio > ratio_threshold:\n",
    "                shrek_images.append(entry)\n",
    "            else:\n",
    "                tissue_images.append(entry)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {f}: {e}\")\n",
    "\n",
    "    return shrek_images, tissue_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216ae7c8",
   "metadata": {},
   "source": [
    "#### 2.1.7 process_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7bfb7c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dataset_for_shreks(directory, shrek_dir, ratio_threshold=0.0125, expected_count=150):\n",
    "    \"\"\"\n",
    "    Analyzes images in a directory to classify them as \"shrek\" or \"tissue\".\n",
    "\n",
    "    If the target shrek_dir already exists and contains the expected_count of images,\n",
    "    this function will skip the analysis to save time.\n",
    "\n",
    "    Args:\n",
    "        directory (str): The source directory containing images to analyze.\n",
    "        shrek_dir (str): The target directory where \"shrek\" images are saved.\n",
    "                         This is used to check if processing can be skipped.\n",
    "        ratio_threshold (float): The threshold for green pixel ratio to be classified as \"shrek\".\n",
    "        expected_count (int): The number of images expected in shrek_dir to skip processing.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two lists: (shrek_images, tissue_images).\n",
    "               Returns ([], []) if processing is skipped.\n",
    "    \"\"\"\n",
    "    # --- Start of new implementation ---\n",
    "    shrek_dir_path = Path(shrek_dir)\n",
    "    if shrek_dir_path.is_dir():\n",
    "        # Count image files (e.g., .png, .jpg) in the shrek directory\n",
    "        num_existing_images = len(list(shrek_dir_path.glob('img_*.png')))\n",
    "        \n",
    "        if num_existing_images == expected_count:\n",
    "            print(f\"'{shrek_dir}' already contains exactly {expected_count} images. Skipping analysis.\")\n",
    "            return [], [] # Return empty lists as the analysis is skipped\n",
    "    # --- End of new implementation ---\n",
    "\n",
    "    shrek_images = []\n",
    "    tissue_images = []\n",
    "    \n",
    "    image_files = glob.glob(os.path.join(directory, 'img_*.png'))\n",
    "    print(f\"Found {len(image_files)} images in '{directory}'. Analyzing for 'Shreks'...\")\n",
    "\n",
    "    for f in tqdm(image_files, desc=\"Analyzing for Shreks\"):\n",
    "        try:\n",
    "            img = cv2.imread(f)\n",
    "            if img is None: continue\n",
    "            \n",
    "            img_rgb_norm = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
    "            \n",
    "            # This function call is part of your original code\n",
    "            result_bgr, mask = filter_bright_green_areas(img_rgb_norm)\n",
    "            \n",
    "            total_pixels = img.shape[0] * img.shape[1]\n",
    "            green_pixels = np.count_nonzero(mask)\n",
    "            ratio = green_pixels / total_pixels\n",
    "            \n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            entry = {\n",
    "                'name': os.path.basename(f), \n",
    "                'path': f,\n",
    "                'img': img_rgb, \n",
    "                'ratio': ratio,\n",
    "                'mask': mask\n",
    "            }\n",
    "\n",
    "            if ratio > ratio_threshold:\n",
    "                shrek_images.append(entry)\n",
    "            else:\n",
    "                tissue_images.append(entry)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {f}: {e}\")\n",
    "\n",
    "    return shrek_images, tissue_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c27e2e",
   "metadata": {},
   "source": [
    "#### 2.1.8 process_classification_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b5f7b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_classification_results(shrek_list, tissue_list, shrek_dir, tissue_dir, threshold, visualize = True):\n",
    "    \"\"\"\n",
    "    Saves classified images to respective directories and visualizes the results.\n",
    "    \n",
    "    Args:\n",
    "        shrek_list (list): List of dicts containing Shrek image data.\n",
    "        tissue_list (list): List of dicts containing Tissue image data.\n",
    "        shrek_dir (str): Path to save Shrek images.\n",
    "        tissue_dir (str): Path to save Tissue images.\n",
    "        threshold (float): The green ratio threshold used for classification.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Print Summary\n",
    "    print(f\"Classified {len(shrek_list)} as Shrek\")\n",
    "    print(f\"Classified {len(tissue_list)} as Tissue\")\n",
    "\n",
    "    # Ensure directories exist\n",
    "    os.makedirs(shrek_dir, exist_ok=True)\n",
    "    os.makedirs(tissue_dir, exist_ok=True)\n",
    "\n",
    "    # 2. Save Shrek images\n",
    "    print(f\"Saving {len(shrek_list)} Shrek images to {shrek_dir}...\")\n",
    "    for item in tqdm(shrek_list, desc=\"Saving Shrek Images\"):\n",
    "        dest_path = os.path.join(shrek_dir, item['name'])\n",
    "        \n",
    "        # Check if file exists to prevent overwriting\n",
    "        if os.path.exists(dest_path):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            shutil.copy2(item['path'], dest_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error copying {item['name']} to shrek folder: {e}\")\n",
    "\n",
    "    # 3. Save Tissue images\n",
    "    print(f\"Saving {len(tissue_list)} Tissue images to {tissue_dir}...\")\n",
    "    for item in tqdm(tissue_list, desc=\"Saving Tissue Images\"):\n",
    "        dest_path = os.path.join(tissue_dir, item['name'])\n",
    "        \n",
    "        # Check if file exists to prevent overwriting\n",
    "        if os.path.exists(dest_path):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            shutil.copy2(item['path'], dest_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error copying {item['name']} to tissue folder: {e}\")\n",
    "    if visualize == True:\n",
    "        # 4. Visualize Examples (2x2 Grid)\n",
    "        if len(shrek_list) >= 2 and len(tissue_list) >= 2:\n",
    "            fig_ex, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "            fig_ex.suptitle(f\"Classification Results (Threshold: {threshold:.1%})\", fontsize=16)\n",
    "\n",
    "            def show_img(ax, item, label):\n",
    "                ax.imshow(item['img'])\n",
    "                # Show the Green Ratio in the title so you can see WHY it was classified\n",
    "                ax.set_title(f\"{label}\\n{item['name']}\\nGreen Pixels: {item['ratio']:.2%}\")\n",
    "                ax.axis('off')\n",
    "\n",
    "            # Row 1: Detected Shrek\n",
    "            show_img(axes[0, 0], shrek_list[0], \"Detected Shrek\")\n",
    "            show_img(axes[0, 1], shrek_list[1], \"Detected Shrek\")\n",
    "            \n",
    "            # Row 2: Detected Tissue\n",
    "            show_img(axes[1, 0], tissue_list[0], \"Detected Tissue\")\n",
    "            show_img(axes[1, 1], tissue_list[1], \"Detected Tissue\")\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"Not enough images in one or both classes to generate 2x2 sample grid.\")\n",
    "\n",
    "        # 5. Plot Scatter Distribution for Tuning\n",
    "        shrek_ratios = [x['ratio'] for x in shrek_list]\n",
    "        tissue_ratios = [x['ratio'] for x in tissue_list]\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "\n",
    "        # Plot Tissue points (Blue)\n",
    "        plt.scatter(range(len(tissue_ratios)), tissue_ratios, color='blue', alpha=0.6, label='Classified as Tissue')\n",
    "\n",
    "        # Plot Shrek points (Green) - Shifted on x-axis to be distinct\n",
    "        # We shift the x-axis index for Shrek so they appear after the tissue points\n",
    "        plt.scatter(range(len(tissue_ratios), len(tissue_ratios) + len(shrek_ratios)), shrek_ratios, color='green', alpha=0.6, label='Classified as Shrek')\n",
    "\n",
    "        # Draw the Threshold Line\n",
    "        plt.axhline(y=threshold, color='red', linestyle='--', linewidth=2, label=f'Threshold ({threshold:.1%})')\n",
    "\n",
    "        plt.title('Green Pixel Ratio per Image', fontsize=14)\n",
    "        plt.ylabel('Ratio of Green Pixels (0.0 - 1.0)')\n",
    "        plt.xlabel('Image Index')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Shrek removal visulization OFF.\")\n",
    "\n",
    "# --- Example Usage ---\n",
    "# shrek_list, tissue_list = analyze_dataset(DATASET_PATH) # Assuming this runs before\n",
    "# process_classification_results(shrek_list, tissue_list, SHREK_DIR, TISSUE_DIR, RATIO_THRESHOLD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b15c4ec",
   "metadata": {},
   "source": [
    "#### 2.1.9 copy_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "188a5659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_masks(image_list, masks_dir, output_dir):\n",
    "    image_names = image_list\n",
    "    mask_names = [name.replace('img_', 'mask_', 1) for name in image_names]\n",
    "\n",
    "    for mask_name in tqdm(mask_names, desc=\"Copying Masks\"):\n",
    "        src_path = os.path.join(masks_dir, mask_name)\n",
    "        dst_path = os.path.join(output_dir, mask_name)\n",
    "        shutil.copy(src_path, dst_path)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42cc6b5",
   "metadata": {},
   "source": [
    "#### 2.1.10 extract_smart_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0447644e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_smart_patches(img_path, mask_path, patch_size=224, stride=224, threshold=0.30):\n",
    "    \"\"\"\n",
    "    Intelligently extracts patches. \n",
    "    UPDATED: Groups nearby tumor spots and centers the patch on the region.\n",
    "    \"\"\"\n",
    "    # Load images\n",
    "    try:\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "    except FileNotFoundError:\n",
    "        # Fallback for common extension swap if .png not found\n",
    "        if img_path.endswith(\".png\"):\n",
    "            img = Image.open(img_path.replace(\".png\", \".jpg\")).convert(\"RGB\")\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    mask = Image.open(mask_path).convert(\"L\")\n",
    "    img_arr = np.array(img)\n",
    "    mask_arr = np.array(mask)\n",
    "\n",
    "    # Normalize mask\n",
    "    if mask_arr.max() <= 1:\n",
    "        mask_check = mask_arr * 255\n",
    "    else:\n",
    "        mask_check = mask_arr\n",
    "    \n",
    "    h, w, _ = img_arr.shape\n",
    "    \n",
    "    if isinstance(patch_size, int):\n",
    "        ph, pw = patch_size, patch_size\n",
    "    else:\n",
    "        ph, pw = patch_size\n",
    "        \n",
    "    if isinstance(stride, int):\n",
    "        sh, sw = stride, stride\n",
    "    else:\n",
    "        sh, sw = stride\n",
    "\n",
    "    # --- Intelligent Extraction Logic ---\n",
    "    \n",
    "    # 1. GROUPING: Dilate the mask to merge nearby small dots into larger regions.\n",
    "    # This prevents generating 1 patch per pixel-sized dot.\n",
    "    # iterations=15 means dots within ~15 pixels of each other get merged.\n",
    "    dilated_mask = ndimage.binary_dilation(mask_check > 128, iterations=15)\n",
    "    \n",
    "    # 2. Label the merged regions\n",
    "    labeled_mask, num_features = ndimage.label(dilated_mask)\n",
    "    objects = ndimage.find_objects(labeled_mask)\n",
    "    \n",
    "    candidate_coords = set()\n",
    "    \n",
    "    def get_valid_start(val, max_val, p_dim):\n",
    "        return max(0, min(val, max_val - p_dim))\n",
    "\n",
    "    # print(f\"Found {num_features} clustered tumor regions.\") # Commented out for batch processing\n",
    "\n",
    "    for i, slice_obj in enumerate(objects):\n",
    "        y_slice, x_slice = slice_obj\n",
    "        \n",
    "        # Region boundaries\n",
    "        y_min, y_max = y_slice.start, y_slice.stop\n",
    "        x_min, x_max = x_slice.start, x_slice.stop\n",
    "        \n",
    "        # --- Strategy: Center on Blob ---\n",
    "        # We calculate the center of the blob and place the patch there.\n",
    "        \n",
    "        blob_cy = (y_min + y_max) // 2\n",
    "        blob_cx = (x_min + x_max) // 2\n",
    "        \n",
    "        # Top-left corner for the patch to be centered on the blob center\n",
    "        start_y = blob_cy - ph // 2\n",
    "        start_x = blob_cx - pw // 2\n",
    "        \n",
    "        valid_y = get_valid_start(start_y, h, ph)\n",
    "        valid_x = get_valid_start(start_x, w, pw)\n",
    "        \n",
    "        candidate_coords.add((valid_x, valid_y))\n",
    "\n",
    "    # 3. Final Validation\n",
    "    patches = []\n",
    "    coords = []\n",
    "    \n",
    "    for (x, y) in candidate_coords:\n",
    "        mask_patch = mask_check[y:y+ph, x:x+pw]\n",
    "        img_patch = img_arr[y:y+ph, x:x+pw]\n",
    "        \n",
    "        # Use Tissue Threshold (non-white pixels)\n",
    "        img_gray = np.mean(img_patch, axis=2)\n",
    "        tissue_ratio = np.sum(img_gray < 235) / (ph * pw)\n",
    "        \n",
    "        # Use Mask Threshold (tumor pixels)\n",
    "        mask_ratio = np.sum(mask_patch > 128) / (ph * pw)\n",
    "        \n",
    "        # Keep patch only if it has enough tumor AND enough tissue\n",
    "        if mask_ratio >= threshold and tissue_ratio > 0.15:\n",
    "            patches.append(img_patch)\n",
    "            coords.append((x, y))\n",
    "\n",
    "    return patches, coords, img_arr, mask_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261850b3",
   "metadata": {},
   "source": [
    "#### 2.1.11 create_patches_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d86d4381",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_patches_dataset(input_dir, output_dir, mask_dir, patch_size=224, stride=224, threshold=0.01):\n",
    "    \"\"\"\n",
    "    Iterates over images in input_dir, finds corresponding masks in mask_dir,\n",
    "    extracts smart patches, and saves them to output_dir.\n",
    "    Also saves corresponding mask patches to a 'masks' subdirectory.\n",
    "\n",
    "    This function will skip processing for any source image if its corresponding\n",
    "    patches are already found in the output directory.\n",
    "    \"\"\"\n",
    "    input_dir = Path(input_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "    mask_dir = Path(mask_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Create subdirectory for mask patches\n",
    "    masks_output_dir = output_dir / \"masks\"\n",
    "    masks_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Filter for image files\n",
    "    image_files = sorted([\n",
    "        f for f in input_dir.iterdir()\n",
    "        if f.name.startswith('img_') and f.suffix.lower() in {'.png', '.jpg', '.jpeg'}\n",
    "    ])\n",
    "\n",
    "    total_patches_saved = 0\n",
    "    images_processed = 0\n",
    "    images_skipped = 0\n",
    "    \n",
    "    print(f\"Starting patch extraction from {input_dir} to {output_dir}...\")\n",
    "    print(f\"Found {len(image_files)} source images.\")\n",
    "\n",
    "    for source_image_path in tqdm(image_files, desc=\"Processing Images\"):\n",
    "        base_name = source_image_path.stem\n",
    "\n",
    "        # --- CHECK FOR EXISTING PATCHES ---\n",
    "        # Check if any patch file for this image already exists.\n",
    "        # We use glob to find files matching the pattern like 'img_xxxx_p*.png'.\n",
    "        # next() with a default value is an efficient way to check for existence\n",
    "        # without listing all files.\n",
    "        if next(output_dir.glob(f\"{base_name}_p*.png\"), None):\n",
    "            # tqdm.write(f\"Skipping {source_image_path.name}, patches already exist.\")\n",
    "            images_skipped += 1\n",
    "            continue\n",
    "\n",
    "        # Construct mask filename (e.g., 'img_xxxx.png' -> 'mask_xxxx.png')\n",
    "        mask_name = source_image_path.name.replace('img_', 'mask_', 1)\n",
    "        mask_path = mask_dir / mask_name\n",
    "\n",
    "        # Fallback if mask has a different extension or wasn't found initially\n",
    "        if not mask_path.exists():\n",
    "             mask_path = mask_dir / (base_name.replace('img_', 'mask_', 1) + \".png\")\n",
    "\n",
    "        if mask_path.exists():\n",
    "            # Extract patches\n",
    "            patches, coords, _, mask_arr = extract_smart_patches(\n",
    "                str(source_image_path),\n",
    "                str(mask_path),\n",
    "                patch_size=patch_size,\n",
    "                stride=stride,\n",
    "                threshold=threshold\n",
    "            )\n",
    "\n",
    "            if not patches:\n",
    "                continue\n",
    "\n",
    "            # Save each patch and corresponding mask patch\n",
    "            for i, (patch_array, (x, y)) in enumerate(zip(patches, coords)):\n",
    "                # Save image patch\n",
    "                patch_img = Image.fromarray(patch_array)\n",
    "                save_name = f\"{base_name}_p{i}.png\"\n",
    "                patch_img.save(output_dir / save_name)\n",
    "                \n",
    "                # Extract and save mask patch\n",
    "                if isinstance(patch_size, int):\n",
    "                    ph, pw = patch_size, patch_size\n",
    "                else:\n",
    "                    ph, pw = patch_size\n",
    "                    \n",
    "                mask_patch = mask_arr[y:y+ph, x:x+pw]\n",
    "                mask_patch_img = Image.fromarray(mask_patch)\n",
    "                mask_save_name = f\"mask_{base_name.replace('img_', '')}_p{i}.png\"\n",
    "                mask_patch_img.save(masks_output_dir / mask_save_name)\n",
    "            \n",
    "            total_patches_saved += len(patches)\n",
    "            images_processed += 1\n",
    "        else:\n",
    "            tqdm.write(f\"Warning: Mask not found for {source_image_path.name}\")\n",
    "\n",
    "    print(\"\\n--- Extraction Summary ---\")\n",
    "    print(f\"Images Processed: {images_processed}\")\n",
    "    print(f\"Images Skipped:   {images_skipped}\")\n",
    "    print(f\"Total Patches Saved in this run: {total_patches_saved}\")\n",
    "    print(f\"Patches are located in: {output_dir}\")\n",
    "    print(f\"Mask patches are located in: {masks_output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83f4aed",
   "metadata": {},
   "source": [
    "#### 2.1.12 apply_patch_masks_to_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f4a11643",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_patch_masks_to_images(patches_dir, masks_dir=None, output_dir=None):\n",
    "    \"\"\"Apply mask patches to image patches and save masked outputs.\n",
    "    Args:\n",
    "        patches_dir: directory with img_*_p*.png\n",
    "        masks_dir: directory with mask_*_p*.png (default: patches_dir / 'masks')\n",
    "        output_dir: destination for masked patches (default: patches_dir / 'masked')\n",
    "    \"\"\"\n",
    "    patches_dir = Path(patches_dir)\n",
    "    masks_dir = Path(masks_dir) if masks_dir else patches_dir / \"masks\"\n",
    "    output_dir = Path(output_dir) if output_dir else patches_dir / \"masked\"\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    patch_files = sorted(patches_dir.glob(\"img_*_p*.png\"))\n",
    "    if not patch_files:\n",
    "        print(f\"No patch images found in {patches_dir}\")\n",
    "        return\n",
    "\n",
    "    applied, skipped = 0, 0\n",
    "    for patch_path in tqdm(patch_files, desc=\"Applying mask patches\"):\n",
    "        mask_name = patch_path.stem.replace(\"img_\", \"mask_\", 1) + patch_path.suffix\n",
    "        mask_path = masks_dir / mask_name\n",
    "        out_path = output_dir / patch_path.name\n",
    "\n",
    "        if out_path.exists():\n",
    "            skipped += 1\n",
    "            continue\n",
    "        if not mask_path.exists():\n",
    "            tqdm.write(f\"Mask not found for {patch_path.name}\")\n",
    "            continue\n",
    "\n",
    "        img = np.array(Image.open(patch_path).convert(\"RGB\"))\n",
    "        mask = np.array(Image.open(mask_path).convert(\"L\"))\n",
    "        if mask.shape[:2] != img.shape[:2]:\n",
    "            mask = np.array(Image.open(mask_path).convert(\"L\").resize((img.shape[1], img.shape[0]), Image.NEAREST))\n",
    "\n",
    "        mask_bin = (mask > 127).astype(np.uint8)\n",
    "        masked = cv2.bitwise_and(img, img, mask=mask_bin)\n",
    "        Image.fromarray(masked).save(out_path)\n",
    "        applied += 1\n",
    "\n",
    "    print(f\"Applied masks to {applied} patches. Skipped {skipped} existing outputs. Results in: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c03d7b",
   "metadata": {},
   "source": [
    "# **3. Run Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a6ea69",
   "metadata": {},
   "source": [
    "## **3.1 Preprocess the Train Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "15f4b930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset path: ..\\an2dl2526c2\n",
      "Train data path: ..\\an2dl2526c2\\train_data\n",
      "Train labels path: ..\\an2dl2526c2\\train_labels.csv\n",
      "Test data path: ..\\an2dl2526c2\\test_data\n"
     ]
    }
   ],
   "source": [
    "datasets_path = os.path.join(os.path.pardir, \"an2dl2526c2\")\n",
    "\n",
    "train_data_path = os.path.join(datasets_path, \"train_data\")\n",
    "train_labels_path = os.path.join(datasets_path, \"train_labels.csv\")\n",
    "test_data_path = os.path.join(datasets_path, \"test_data\")\n",
    "\n",
    "CSV_PATH = train_labels_path                # Path to the CSV file with labels\n",
    "SOURCE_FOLDER = train_data_path\n",
    "\n",
    "print(f\"Dataset path: {datasets_path}\")\n",
    "print(f\"Train data path: {train_data_path}\")\n",
    "print(f\"Train labels path: {train_labels_path}\")\n",
    "print(f\"Test data path: {test_data_path}\")\n",
    "# preprocessing output paths\n",
    "#preprocessing step 1 output path\n",
    "GOO_REMOVAL_OUT = os.path.join(datasets_path, \"preprocessing_results_masked\",\"train_nogoo\")\n",
    "\n",
    "#preprocessing step 2 output path\n",
    "SHREK_REMOVAL_OUT = os.path.join(datasets_path, \"preprocessing_results_masked\",\"train_noshreks\")\n",
    "SHREKS_OUT = os.path.join(SHREK_REMOVAL_OUT, \"train_shreks\")\n",
    "TISSUE_OUT = os.path.join(SHREK_REMOVAL_OUT, \"train_tissue\")\n",
    "\n",
    "\n",
    "  # Where the resized unmasked images will be saved\n",
    "PATCHES_OUT = os.path.join(datasets_path, \"preprocessing_results_masked\",\"train_patches\")\n",
    "PATCHES_OUT_MASKED = os.path.join(datasets_path, \"preprocessing_results_masked\",\"train_patches_masked\")\n",
    "\n",
    "TARGET_SIZE = (224, 224)                    # Target size for the resized images and masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "54719952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning for images in: ..\\an2dl2526c2\\train_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing Goo from Images: 100%|██████████| 691/691 [00:00<00:00, 13458.70img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing complete. Processed 0 new images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Remove goo and do not resize images\n",
    "remove_goo(SOURCE_FOLDER,GOO_REMOVAL_OUT, target_size=None, remove_goo=True, save_masks=True, replacement_color=(195, 195, 195))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3c3bc574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 691 goo masks. Checking for existing and processing new masks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning External Masks: 100%|██████████| 691/691 [00:00<00:00, 18084.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing complete.\n",
      "  - Cleaned and saved: 0 masks to ..\\an2dl2526c2\\preprocessing_results_masked\\train_nogoo\\cleaned_masks\n",
      "  - Skipped: 691 masks that already existed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "clean_and_save_masks(\n",
    "    goo_masks_dir=os.path.join(GOO_REMOVAL_OUT, \"goo_masks\"), \n",
    "    external_masks_dir=SOURCE_FOLDER, \n",
    "    output_dir=os.path.join(GOO_REMOVAL_OUT, \"cleaned_masks\"), \n",
    "    target_size=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e6008bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 691 images in '..\\an2dl2526c2\\preprocessing_results_masked\\train_nogoo'. Analyzing for 'Shreks'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing for Shreks: 100%|██████████| 691/691 [00:46<00:00, 15.02it/s]\n",
      "Analyzing for Shreks: 100%|██████████| 691/691 [00:46<00:00, 15.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified 60 as Shrek\n",
      "Classified 631 as Tissue\n",
      "Saving 60 Shrek images to ..\\an2dl2526c2\\preprocessing_results_masked\\train_noshreks\\train_shreks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving Shrek Images: 100%|██████████| 60/60 [00:00<00:00, 25695.14it/s]\n",
      "Saving Shrek Images: 100%|██████████| 60/60 [00:00<00:00, 25695.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 631 Tissue images to ..\\an2dl2526c2\\preprocessing_results_masked\\train_noshreks\\train_tissue...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving Tissue Images: 100%|██████████| 631/631 [00:00<00:00, 27126.59it/s]\n",
      "Saving Tissue Images: 100%|██████████| 631/631 [00:00<00:00, 27126.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shrek removal visulization OFF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying Masks: 100%|██████████| 631/631 [00:00<00:00, 1476.40it/s]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 2: Discard Shrek Images\n",
    "shreks_list, tissue_list = analyze_dataset_for_shreks(GOO_REMOVAL_OUT, shrek_dir=SHREKS_OUT, ratio_threshold=0.0125, expected_count=150)\n",
    "\n",
    "process_classification_results(shreks_list, tissue_list, SHREKS_OUT, TISSUE_OUT, 0.0125, visualize=False)\n",
    "\n",
    "tissue_image_names = [item['name'] for item in tissue_list]\n",
    "copy_masks(tissue_image_names, SOURCE_FOLDER, TISSUE_OUT)\n",
    "\n",
    "# Clean up memory\n",
    "del shreks_list\n",
    "del tissue_list\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b7d8c886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting patch extraction from ..\\an2dl2526c2\\preprocessing_results_masked\\train_noshreks\\train_tissue to ..\\an2dl2526c2\\preprocessing_results_masked\\train_patches...\n",
      "Found 631 source images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|██████████| 631/631 [00:01<00:00, 452.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Extraction Summary ---\n",
      "Images Processed: 0\n",
      "Images Skipped:   631\n",
      "Total Patches Saved in this run: 0\n",
      "Patches are located in: ..\\an2dl2526c2\\preprocessing_results_masked\\train_patches\n",
      "Mask patches are located in: ..\\an2dl2526c2\\preprocessing_results_masked\\train_patches\\masks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "CLEANED_MASKS_DIR = os.path.join(GOO_REMOVAL_OUT, \"cleaned_masks\")\n",
    "\n",
    "create_patches_dataset(\n",
    "    TISSUE_OUT, \n",
    "    PATCHES_OUT, \n",
    "    mask_dir=CLEANED_MASKS_DIR,\n",
    "    patch_size=224, \n",
    "    stride=224, \n",
    "    threshold=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "700b798c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying mask patches: 100%|██████████| 2788/2788 [00:09<00:00, 280.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied masks to 2788 patches. Skipped 0 existing outputs. Results in: ..\\an2dl2526c2\\preprocessing_results_masked\\train_patches_masked\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "apply_patch_masks_to_images(PATCHES_OUT, output_dir=PATCHES_OUT_MASKED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879490b3",
   "metadata": {},
   "source": [
    "## **3.2 Preprocess the Submission Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "756b19c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting patch extraction from ..\\an2dl2526c2\\test_data to ..\\an2dl2526c2\\preprocessing_results_masked\\submission_patches...\n",
      "Found 477 source images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|██████████| 477/477 [00:00<00:00, 619.76it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Extraction Summary ---\n",
      "Images Processed: 0\n",
      "Images Skipped:   477\n",
      "Total Patches Saved in this run: 0\n",
      "Patches are located in: ..\\an2dl2526c2\\preprocessing_results_masked\\submission_patches\n",
      "Mask patches are located in: ..\\an2dl2526c2\\preprocessing_results_masked\\submission_patches\\masks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying mask patches: 100%|██████████| 2052/2052 [00:07<00:00, 274.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied masks to 2052 patches. Skipped 0 existing outputs. Results in: ..\\an2dl2526c2\\preprocessing_results_masked\\submission_patches_masked\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "SUBMISSION_PATCHES_OUT = os.path.join(datasets_path, \"preprocessing_results_masked\",\"submission_patches\")\n",
    "SUBMISSION_SOURCE_FOLDER = os.path.join(datasets_path, \"test_data\")\n",
    "\n",
    "create_patches_dataset(\n",
    "    SUBMISSION_SOURCE_FOLDER, \n",
    "    SUBMISSION_PATCHES_OUT, \n",
    "    mask_dir=SUBMISSION_SOURCE_FOLDER,\n",
    "    patch_size=224, \n",
    "    stride=224, \n",
    "    threshold=0.01\n",
    ")\n",
    "\n",
    "SUBMISSION_PATCHES_OUT_MASKED = os.path.join(datasets_path, \"preprocessing_results_masked\",\"submission_patches_masked\")\n",
    "\n",
    "apply_patch_masks_to_images(SUBMISSION_PATCHES_OUT, output_dir=SUBMISSION_PATCHES_OUT_MASKED)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
