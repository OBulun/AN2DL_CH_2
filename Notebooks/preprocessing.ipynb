{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "020adc77",
   "metadata": {},
   "source": [
    "## **I. Google Colab Initializtion (Only on Colab)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a81ad74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# cur_dir = \"/content/drive/Othercomputers/My laptop/POLIMI/AN2DL/AN2DL_CH_2/Notebooks\"\n",
    "# %cd $cur_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada10e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install torchview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4969644a",
   "metadata": {},
   "source": [
    "## **1. Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109a22c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "SEED = 42\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "\n",
    "# Set environment variables before importing modules\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "os.environ['MPLCONFIGDIR'] = os.getcwd() + '/configs/'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "# Import necessary modules\n",
    "import logging\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Set seeds for random number generators in NumPy and Python\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# Import PyTorch\n",
    "import torch\n",
    "torch.manual_seed(SEED)\n",
    "from torch import nn\n",
    "from torchsummary import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "from torchvision.transforms import v2 as transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchview import draw_graph\n",
    "\n",
    "# Configurazione di TensorBoard e directory\n",
    "logs_dir = \"tensorboard\"\n",
    "!pkill -f tensorboard\n",
    "%load_ext tensorboard\n",
    "!mkdir -p models\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Import other libraries\n",
    "import cv2\n",
    "import copy\n",
    "import shutil\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import matplotlib.gridspec as gridspec\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "# Configure plot display settings\n",
    "sns.set(font_scale=1.4)\n",
    "sns.set_style('white')\n",
    "plt.rc('font', size=14)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490fcb3f",
   "metadata": {},
   "source": [
    "## **2. Data Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd2d583",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_UNMASKED = False  # @param {type:\"boolean\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b5f384",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_path = os.path.join(os.path.pardir, \"an2dl2526c2\")\n",
    "\n",
    "train_data_path = os.path.join(datasets_path, \"train_data\")\n",
    "train_labels_path = os.path.join(datasets_path, \"train_labels.csv\")\n",
    "\n",
    "test_data_path = os.path.join(datasets_path, \"test_data\")\n",
    "\n",
    "output_path = os.path.join(datasets_path, \"train_masked_nogoo\")\n",
    "output_path_goo = os.path.join(datasets_path, \"train_masked_goo\")\n",
    "\n",
    "if USE_UNMASKED:\n",
    "    resized_path = os.path.join(datasets_path, \"train_resized\")\n",
    "\n",
    "print(f\"Dataset path: {datasets_path}\")\n",
    "print(f\"Train data path: {train_data_path}\")\n",
    "print(f\"Train labels path: {train_labels_path}\")\n",
    "print(f\"Test data path: {test_data_path}\")\n",
    "print(f\"Output path: {output_path}\")\n",
    "if USE_UNMASKED:\n",
    "    print(f\"Resized path: {resized_path}\")\n",
    "\n",
    "CSV_PATH = train_labels_path                # Path to the CSV file with labels\n",
    "SOURCE_FOLDER = train_data_path             # Folder containing img_xxxx and mask_xxxx\n",
    "OUTPUT_FOLDER = output_path\n",
    "if USE_UNMASKED:                   # Where the resized and masked images will be saved            \n",
    "    RESIZED_FOLDER = resized_path               # Where the resized unmasked images will be saved\n",
    "\n",
    "TARGET_SIZE = (224, 224)                    # Target size for the resized images and masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9df4948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_smart_goo_mask(img_bgr):\n",
    "    \"\"\"\n",
    "    Internal helper to detect goo using Core & Shell logic + 1px Nudge.\n",
    "    Returns a binary mask (White = Goo, Black = Safe).\n",
    "    \"\"\"\n",
    "    # 1. Convert to HSV\n",
    "    hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # 2. Define Ranges\n",
    "    # CORE: Solid Green (Strict)\n",
    "    core_lower = np.array([35, 100, 50])\n",
    "    core_upper = np.array([85, 255, 255])\n",
    "    \n",
    "    # SHELL: Faint Halo (Loose/Transparent)\n",
    "    shell_lower = np.array([30, 30, 30])\n",
    "    shell_upper = np.array([95, 255, 255])\n",
    "\n",
    "    # 3. Create initial masks\n",
    "    mask_core = cv2.inRange(hsv, core_lower, core_upper)\n",
    "    mask_shell = cv2.inRange(hsv, shell_lower, shell_upper)\n",
    "\n",
    "    # 4. Smart Combine (Connected Components)\n",
    "    # Keep 'Shell' blobs ONLY if they touch 'Core' blobs\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask_shell, connectivity=8)\n",
    "    smart_mask = np.zeros_like(mask_core)\n",
    "\n",
    "    for label_id in range(1, num_labels): # Skip background (0)\n",
    "        blob_mask = (labels == label_id).astype(np.uint8) * 255\n",
    "        \n",
    "        # Check overlap with Core\n",
    "        overlap = cv2.bitwise_and(blob_mask, mask_core)\n",
    "        \n",
    "        # If there is ANY overlap, keep the blob\n",
    "        if cv2.countNonZero(overlap) > 0:\n",
    "            smart_mask = cv2.bitwise_or(smart_mask, blob_mask)\n",
    "\n",
    "    # 5. Fill Holes (in case the goo has shiny reflections)\n",
    "    contours, _ = cv2.findContours(smart_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    final_filled_mask = np.zeros_like(smart_mask)\n",
    "    for contour in contours:\n",
    "        # Minimum area filter (200px) to remove tiny stray noise\n",
    "        if cv2.contourArea(contour) > 200:\n",
    "            cv2.drawContours(final_filled_mask, [contour], -1, (255), thickness=cv2.FILLED)\n",
    "\n",
    "    # 6. The \"1-Pixel Nudge\"\n",
    "    # Safely expand by 1 pixel to cover the final anti-aliased fringe\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    final_expanded_mask = cv2.dilate(final_filled_mask, kernel, iterations=1)\n",
    "\n",
    "    return final_expanded_mask\n",
    "\n",
    "def apply_mask(image_path, mask_path, output_path, target_size=(224, 224), remove_goo=True):\n",
    "    \"\"\"\n",
    "    Loads an image and a mask. \n",
    "    If remove_goo is True, it subtracts green pixels (using Smart Core/Shell logic) \n",
    "    from the valid mask area. Resizes and saves the result.\n",
    "    \"\"\"\n",
    "    # 1. Load Image\n",
    "    img = cv2.imread(str(image_path))\n",
    "    if img is None:\n",
    "        tqdm.write(f\"Error: Could not load image at {image_path}\")\n",
    "        return\n",
    "\n",
    "    # 2. Load External Mask (Read as grayscale)\n",
    "    mask = cv2.imread(str(mask_path), 0)\n",
    "    if mask is None:\n",
    "        tqdm.write(f\"Error: Could not load mask at {mask_path}\")\n",
    "        return\n",
    "\n",
    "    # 3. Resize both to target size\n",
    "    if target_size is not None:\n",
    "        img = cv2.resize(img, target_size)\n",
    "        mask = cv2.resize(mask, target_size)\n",
    "\n",
    "    # 4. Standardize External Mask (Binary 0 or 255)\n",
    "    _, binary_mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # 5. Determine Final Mask\n",
    "    if remove_goo:\n",
    "        # --- NEW SMART GOO LOGIC ---\n",
    "        # Get the smart mask (White = Goo)\n",
    "        goo_mask = _get_smart_goo_mask(img)\n",
    "        \n",
    "        # Invert Goo Mask (White = Safe)\n",
    "        not_goo_mask = cv2.bitwise_not(goo_mask)\n",
    "        \n",
    "        # Combine: Must be Tissue (binary_mask) AND Safe (not_goo_mask)\n",
    "        final_mask = cv2.bitwise_and(binary_mask, not_goo_mask)\n",
    "    else:\n",
    "        # --- ORIGINAL LOGIC ---\n",
    "        final_mask = binary_mask\n",
    "\n",
    "    # 6. Apply Final Mask\n",
    "    # Areas outside the final mask become Black (0)\n",
    "    masked_img = cv2.bitwise_and(img, img, mask=final_mask)\n",
    "\n",
    "    # 7. Save result\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(os.path.dirname(str(output_path)), exist_ok=True)\n",
    "    cv2.imwrite(str(output_path), masked_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfb7c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(input_dir, output_dir, target_size=(224, 224), remove_goo=True):\n",
    "    \"\"\"\n",
    "    Iterates through input_dir, finds pairs of 'img_xxxx' and 'mask_xxxx'.\n",
    "    Passes the remove_goo flag to the apply_mask function.\n",
    "    \"\"\"\n",
    "    input_dir = Path(input_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "    \n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    valid_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}\n",
    "    \n",
    "    print(f\"Scanning for images in: {input_dir}...\")\n",
    "    image_files = [\n",
    "        f for f in input_dir.iterdir() \n",
    "        if f.name.startswith('img_') and f.suffix.lower() in valid_extensions\n",
    "    ]\n",
    "    \n",
    "    if not image_files:\n",
    "        print(\"No images found starting with 'img_' in the directory.\")\n",
    "        return\n",
    "\n",
    "    count = 0\n",
    "    \n",
    "    for file_path in tqdm(image_files, desc=\"Processing Images\", unit=\"img\"):\n",
    "        # Construct mask filename\n",
    "        mask_name = file_path.name.replace('img_', 'mask_', 1)\n",
    "        mask_path = input_dir / mask_name\n",
    "        \n",
    "        if not mask_path.exists():\n",
    "            mask_stem = file_path.stem.replace('img_', 'mask_', 1)\n",
    "            mask_path = input_dir / (mask_stem + \".png\")\n",
    "        \n",
    "        if mask_path.exists():\n",
    "            output_path = output_dir / file_path.name\n",
    "            \n",
    "            if output_path.exists():\n",
    "                continue\n",
    "\n",
    "            # Pass the remove_goo flag here\n",
    "            apply_mask(file_path, mask_path, output_path, target_size=target_size, remove_goo=remove_goo)\n",
    "            count += 1\n",
    "        else:\n",
    "            tqdm.write(f\"Skipping {file_path.name}: No matching mask found.\")\n",
    "\n",
    "    print(f\"Batch processing complete. Processed {count} new images.\")\n",
    "\n",
    "def resize_batch(input_dir, output_dir, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Iterates through input_dir, finds 'img_xxxx', resizes them to target_size, \n",
    "    and saves the result to output_dir.\n",
    "    \"\"\"\n",
    "    input_dir = Path(input_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Extensions to look for\n",
    "    valid_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}\n",
    "    \n",
    "    # 1. Gather all valid image files first\n",
    "    print(f\"Scanning for images in: {input_dir}...\")\n",
    "    image_files = [\n",
    "        f for f in input_dir.iterdir() \n",
    "        if f.name.startswith('img_') and f.suffix.lower() in valid_extensions\n",
    "    ]\n",
    "    \n",
    "    if not image_files:\n",
    "        print(\"No images found starting with 'img_' in the directory.\")\n",
    "        return\n",
    "\n",
    "    # 2. Iterate with tqdm\n",
    "    count = 0\n",
    "    \n",
    "    for file_path in tqdm(image_files, desc=\"Resizing Images\", unit=\"img\"):\n",
    "        output_path = output_dir / file_path.name\n",
    "        \n",
    "        if output_path.exists():\n",
    "            # Skip silently\n",
    "            continue\n",
    "\n",
    "        img = cv2.imread(str(file_path))\n",
    "        if img is None:\n",
    "            continue\n",
    "            \n",
    "        if target_size is not None:\n",
    "            img = cv2.resize(img, target_size)\n",
    "            \n",
    "        cv2.imwrite(str(output_path), img)\n",
    "        count += 1\n",
    "\n",
    "    print(f\"Resizing complete. Processed {count} new images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecbf077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder, resize=None, filter_prefix=None):\n",
    "    \"\"\"\n",
    "    Load and preprocess images from a specified folder with a progress bar.\n",
    "\n",
    "    Args:\n",
    "        folder (str): Path to the folder containing images\n",
    "        resize (tuple): Target size (width, height) or None\n",
    "        filter_prefix (str): Prefix to filter filenames (e.g. 'img_')\n",
    "\n",
    "    Returns:\n",
    "        tuple: (np.ndarray of images, list of filenames)\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    loaded_filenames = []\n",
    "    \n",
    "    # Get the list of files to iterate over\n",
    "    file_list = sorted(os.listdir(folder))\n",
    "    \n",
    "    # Filter files before iterating to show correct progress\n",
    "    if filter_prefix:\n",
    "        file_list = [f for f in file_list if f.startswith(filter_prefix)]\n",
    "\n",
    "    # Iterate through files with a tqdm progress bar\n",
    "    for filename in tqdm(file_list, desc=f\"Loading images from {os.path.basename(folder)}\"):\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        # Check if image was loaded successfully right away\n",
    "        if img is None:\n",
    "            # print(f\"Warning: Failed to load image at {img_path}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Normalize image pixel values to a float range [0, 1]\n",
    "        img = (img / 255.0).astype(np.float32)\n",
    "\n",
    "        # Convert image from BGR to RGB\n",
    "        img = img[..., ::-1]\n",
    "\n",
    "        if resize:\n",
    "            img = cv2.resize(img, resize)\n",
    "\n",
    "        images.append(img)\n",
    "        loaded_filenames.append(filename)\n",
    "\n",
    "    return np.array(images), loaded_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8fdc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_batch(SOURCE_FOLDER, OUTPUT_FOLDER, target_size=TARGET_SIZE, remove_goo=True)\n",
    "\n",
    "process_batch(SOURCE_FOLDER, output_path_goo, target_size=TARGET_SIZE, remove_goo=False)\n",
    "\n",
    "MASKED_IMAGE_PATH = OUTPUT_FOLDER\n",
    "\n",
    "if USE_UNMASKED:\n",
    "    resize_batch(SOURCE_FOLDER, RESIZED_FOLDER, target_size=TARGET_SIZE)\n",
    "    RESIZED_IMAGE_PATH = RESIZED_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd395a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load masked images (already resized in process_batch)\n",
    "# We add filter_prefix='img_' to ensure we don't load any mask files that might be in the folder\n",
    "masked_images, masked_filenames = load_images_from_folder(MASKED_IMAGE_PATH, filter_prefix='img_')\n",
    "\n",
    "# Load original images (already resized in resize_batch)\n",
    "if USE_UNMASKED:\n",
    "    original_images, original_filenames = load_images_from_folder(RESIZED_IMAGE_PATH, filter_prefix='img_')\n",
    "    # Combine images\n",
    "    train_images = np.concatenate([masked_images, original_images], axis=0)\n",
    "    # Combine filenames\n",
    "    filenames = masked_filenames + original_filenames\n",
    "else:\n",
    "    original_images = []\n",
    "    train_images = masked_images\n",
    "    filenames = masked_filenames\n",
    "\n",
    "\n",
    "print(f\"Loaded {len(masked_images)} masked images and {len(original_images)} original images.\")\n",
    "print(f\"Total images: {len(train_images)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4255eb",
   "metadata": {},
   "source": [
    "## **3. Exploration and Data Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9577b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@ title Mask Verification\n",
    "# Select a few random images from the output folder to verify the process\n",
    "masked_files = os.listdir(OUTPUT_FOLDER)\n",
    "num_samples = 3\n",
    "selected_files = random.sample(masked_files, num_samples)\n",
    "\n",
    "fig, axes = plt.subplots(num_samples, 3, figsize=(15, 3 * num_samples))\n",
    "\n",
    "for i, filename in enumerate(selected_files):\n",
    "    # 1. Define paths\n",
    "    masked_image_path = os.path.join(OUTPUT_FOLDER, filename)\n",
    "    original_image_path = os.path.join(SOURCE_FOLDER, filename)\n",
    "    \n",
    "    # Logic to find the mask path (replicating logic from Cell 5)\n",
    "    mask_name = filename.replace('img_', 'mask_', 1)\n",
    "    mask_path = os.path.join(SOURCE_FOLDER, mask_name)\n",
    "    \n",
    "    # Check if mask exists, if not try .png fallback as per Cell 5 logic\n",
    "    if not os.path.exists(mask_path):\n",
    "        mask_stem = os.path.splitext(filename)[0].replace('img_', 'mask_', 1)\n",
    "        mask_path = os.path.join(SOURCE_FOLDER, mask_stem + \".png\")\n",
    "\n",
    "    # 2. Load images\n",
    "    # Original\n",
    "    orig_img = cv2.imread(original_image_path)\n",
    "    if orig_img is not None:\n",
    "        orig_img = cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Mask\n",
    "    mask_img = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Masked (Result)\n",
    "    masked_img = cv2.imread(masked_image_path)\n",
    "    if masked_img is not None:\n",
    "        masked_img = cv2.cvtColor(masked_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # 3. Plot\n",
    "    # Original\n",
    "    if orig_img is not None:\n",
    "        axes[i, 0].imshow(orig_img)\n",
    "        axes[i, 0].set_title(f\"Original\\n{filename}\")\n",
    "    else:\n",
    "        axes[i, 0].text(0.5, 0.5, \"Original Not Found\", ha='center')\n",
    "    axes[i, 0].axis('off')\n",
    "\n",
    "    # Mask\n",
    "    if mask_img is not None:\n",
    "        axes[i, 1].imshow(mask_img, cmap='gray')\n",
    "        axes[i, 1].set_title(f\"Mask\")\n",
    "    else:\n",
    "        axes[i, 1].text(0.5, 0.5, \"Mask Not Found\", ha='center')\n",
    "    axes[i, 1].axis('off')\n",
    "\n",
    "    # Masked\n",
    "    if masked_img is not None:\n",
    "        axes[i, 2].imshow(masked_img)\n",
    "        axes[i, 2].set_title(f\"Masked Result (Resized)\")\n",
    "    else:\n",
    "        axes[i, 2].text(0.5, 0.5, \"Result Not Found\", ha='center')\n",
    "    axes[i, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be9ae61",
   "metadata": {},
   "source": [
    "### 3.1 Show Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2800ac35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of images to display\n",
    "num_img = 10\n",
    "# Starting index\n",
    "start_img= random.randint(0, len(train_images) - num_img)\n",
    "# Create subplots for displaying items\n",
    "fig, axes = plt.subplots(2, num_img//2, figsize=(20, 9))\n",
    "for i in range(start_img, start_img+num_img):\n",
    "    ax = axes[i%2, i%num_img//2]\n",
    "    ax.imshow(np.clip(train_images[i], 0, 1))  # Display clipped item images\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6b5f0c",
   "metadata": {},
   "source": [
    "## **4. Train/Val Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b56890",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 1. Load the labels CSV\n",
    "labels_df = pd.read_csv(train_labels_path)\n",
    "# Create a dictionary mapping filename -> label for fast lookup\n",
    "labels_map = dict(zip(labels_df.iloc[:, 0], labels_df.iloc[:, 1]))\n",
    "\n",
    "# 2. Get the filenames corresponding to the images loaded in Cell 7\n",
    "# IMPORTANT: This must match the order used in 'load_images_from_folder' exactly.\n",
    "# We use the filenames list created in the previous cell.\n",
    "# filenames = os.listdir(MASKED_IMAGE_PATH)\n",
    "\n",
    "print(\"Aligning labels to loaded images...\")\n",
    "\n",
    "X_aligned = []\n",
    "y_aligned = []\n",
    "\n",
    "# 3. Iterate through the filenames to sync X (images) and y (labels)\n",
    "# We assume 'train_images' matches the order of 'filenames' because they rely on the same os.listdir call order\n",
    "# provided no files were added/deleted between Cell 7 and Cell 9.\n",
    "if len(filenames) != len(train_images):\n",
    "    raise ValueError(f\"Mismatch! Loaded images ({len(train_images)}) != Files found ({len(filenames)}).\")\n",
    "\n",
    "for i, filename in enumerate(filenames):\n",
    "    if filename in labels_map:\n",
    "        # If the file exists in our CSV, keep the image and the label\n",
    "        X_aligned.append(train_images[i])\n",
    "        y_aligned.append(labels_map[filename])\n",
    "    else:\n",
    "        # If image is in folder but NOT in CSV, we must discard the image\n",
    "        print(f\"Skipping {filename}: Image found but no label in CSV.\")\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = np.array(X_aligned)\n",
    "y = np.array(y_aligned)\n",
    "\n",
    "print(f\"Images aligned: {X.shape}\")\n",
    "print(f\"Labels aligned: {y.shape}\")\n",
    "\n",
    "# 4. Encode labels (String -> Integer)\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Print class mapping\n",
    "print(\"Classes:\", label_encoder.classes_)\n",
    "\n",
    "# 5. Train-Test Split (Stratified)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y_encoded, \n",
    "    test_size=0.2, \n",
    "    random_state=SEED, \n",
    "    stratify=y_encoded\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    test_size=0.5,\n",
    "    random_state=SEED,\n",
    "    stratify=y_temp\n",
    ")\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}, Labels: {y_train.shape}\")\n",
    "print(f\"Validation data shape: {X_val.shape}, Labels: {y_val.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}, Labels: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10b3ac2",
   "metadata": {},
   "source": [
    "### 4.1 Set Input Size and Number of Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e11a875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input shape based on the training data\n",
    "input_shape = (X_train.shape[3], X_train.shape[1], X_train.shape[2])\n",
    "\n",
    "# Define the number of classes\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "print(\"Input Shape:\", input_shape)\n",
    "print(\"Number of Classes:\", num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa63068c",
   "metadata": {},
   "source": [
    "### 4.2 Create Tensor Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa29695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numpy arrays to PyTorch datasets (without augmentation for now)\n",
    "train_ds = TensorDataset(\n",
    "    torch.from_numpy(X_train).permute(0, 3, 1, 2),\n",
    "    torch.from_numpy(y_train).squeeze().long()\n",
    ")\n",
    "val_ds = TensorDataset(\n",
    "    torch.from_numpy(X_val).permute(0, 3, 1, 2),\n",
    "    torch.from_numpy(y_val).squeeze().long()\n",
    ")\n",
    "test_ds = TensorDataset(\n",
    "    torch.from_numpy(X_test).permute(0, 3, 1, 2),\n",
    "    torch.from_numpy(y_test).squeeze().long()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e73892",
   "metadata": {},
   "source": [
    "### 4.3  Set Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9b9ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the batch size\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752230f4",
   "metadata": {},
   "source": [
    "### 4.4 make_loader Function Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f28dec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_loader(ds, batch_size, shuffle, drop_last):\n",
    "    \"\"\"\n",
    "    Create a PyTorch DataLoader with optimized settings.\n",
    "\n",
    "    Args:\n",
    "        ds (Dataset): PyTorch Dataset object\n",
    "        batch_size (int): Number of samples per batch\n",
    "        shuffle (bool): Whether to shuffle data at each epoch\n",
    "        drop_last (bool): Whether to drop last incomplete batch\n",
    "\n",
    "    Returns:\n",
    "        DataLoader: Configured DataLoader instance\n",
    "    \"\"\"\n",
    "    # Determine optimal number of worker processes for data loading\n",
    "    cpu_cores = os.cpu_count() or 2\n",
    "    num_workers = max(2, min(4, cpu_cores))\n",
    "\n",
    "    # Create DataLoader with performance optimizations\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,  # Faster GPU transfer\n",
    "        pin_memory_device=\"cuda\" if torch.cuda.is_available() else \"\",\n",
    "        prefetch_factor=4,  # Load 4 batches ahead\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9f1dab",
   "metadata": {},
   "source": [
    "### 4.5 Create Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f35e903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders with different settings for each phase\n",
    "train_loader = make_loader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "val_loader = make_loader(val_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "test_loader = make_loader(test_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f00022b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one batch from the training data loader\n",
    "for xb, yb in train_loader:\n",
    "    print(\"Features batch shape:\", xb.shape)\n",
    "    print(\"Labels batch shape:\", yb.shape)\n",
    "    break  # Stop after getting one batch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
