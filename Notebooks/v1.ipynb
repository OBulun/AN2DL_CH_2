{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4969644a",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "109a22c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pkill' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "A subdirectory or file -p already exists.\n",
      "Error occurred while processing: -p.\n",
      "A subdirectory or file models already exists.\n",
      "Error occurred while processing: models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.1+cu128\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set seed for reproducibility\n",
    "SEED = 42\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "\n",
    "# Set environment variables before importing modules\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "os.environ['MPLCONFIGDIR'] = os.getcwd() + '/configs/'\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "# Import necessary modules\n",
    "import logging\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Set seeds for random number generators in NumPy and Python\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# Import PyTorch\n",
    "import torch\n",
    "torch.manual_seed(SEED)\n",
    "from torch import nn\n",
    "from torchsummary import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "from torchvision.transforms import v2 as transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchview import draw_graph\n",
    "\n",
    "# Configurazione di TensorBoard e directory\n",
    "logs_dir = \"tensorboard\"\n",
    "!pkill -f tensorboard\n",
    "%load_ext tensorboard\n",
    "!mkdir -p models\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Import other libraries\n",
    "import cv2\n",
    "import copy\n",
    "import shutil\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import matplotlib.gridspec as gridspec\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "# Configure plot display settings\n",
    "sns.set(font_scale=1.4)\n",
    "sns.set_style('white')\n",
    "plt.rc('font', size=14)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490fcb3f",
   "metadata": {},
   "source": [
    "## **2. Data Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30b5f384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset path: ..\\an2dl2526c2\n",
      "Train data path: ..\\an2dl2526c2\\train_data\n",
      "Train labels path: ..\\an2dl2526c2\\train_labels.csv\n",
      "Test data path: ..\\an2dl2526c2\\test_data\n",
      "Output path: ..\\an2dl2526c2\\train_masked\n"
     ]
    }
   ],
   "source": [
    "datasets_path = os.path.join(os.path.pardir, \"an2dl2526c2\")\n",
    "\n",
    "train_data_path = os.path.join(datasets_path, \"train_data\")\n",
    "train_labels_path = os.path.join(datasets_path, \"train_labels.csv\")\n",
    "\n",
    "test_data_path = os.path.join(datasets_path, \"test_data\")\n",
    "\n",
    "output_path = os.path.join(datasets_path, \"train_masked\")\n",
    "\n",
    "print(f\"Dataset path: {datasets_path}\")\n",
    "print(f\"Train data path: {train_data_path}\")\n",
    "print(f\"Train labels path: {train_labels_path}\")\n",
    "print(f\"Test data path: {test_data_path}\")\n",
    "print(f\"Output path: {output_path}\")\n",
    "\n",
    "CSV_PATH = train_labels_path                # Path to the CSV file with labels\n",
    "SOURCE_FOLDER = train_data_path             # Folder containing img_xxxx and mask_xxxx\n",
    "OUTPUT_FOLDER = output_path                 # Where the resized and masked images will be saved            \n",
    "\n",
    "TARGET_SIZE = (224, 224)                    # Target size for the resized images and masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9df4948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mask(image_path, mask_path, output_path, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Loads an image and a mask, resizes them, applies the mask, and saves the result.\n",
    "    \"\"\"\n",
    "    # 1. Load Image\n",
    "    img = cv2.imread(str(image_path))\n",
    "    if img is None:\n",
    "        tqdm.write(f\"Error: Could not load image at {image_path}\")\n",
    "        return\n",
    "\n",
    "    # 2. Load Mask (Read as grayscale)\n",
    "    mask = cv2.imread(str(mask_path), 0)\n",
    "    if mask is None:\n",
    "        tqdm.write(f\"Error: Could not load mask at {mask_path}\")\n",
    "        return\n",
    "\n",
    "    # 3. Resize both to target size\n",
    "    if target_size is not None:\n",
    "        # Resize image using linear interpolation (better for photos)\n",
    "        img = cv2.resize(img, target_size)\n",
    "        # Resize mask using nearest neighbor to preserve sharp edges\n",
    "        mask = cv2.resize(mask, target_size)\n",
    "\n",
    "    # 4. Ensure mask is strictly binary (0 or 255)\n",
    "    # Values > 127 become 255 (White), others become 0 (Black)\n",
    "    _, binary_mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # 5. Apply the mask\n",
    "    # cv2.bitwise_and keeps the pixel where the mask is 255, and makes it 0 where mask is 0\n",
    "    masked_img = cv2.bitwise_and(img, img, mask=binary_mask)\n",
    "\n",
    "    # 6. Save result\n",
    "    cv2.imwrite(str(output_path), masked_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfb7c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(input_dir, output_dir, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Iterates through input_dir, finds pairs of 'img_xxxx' and 'mask_xxxx',\n",
    "    resizes them to target_size, and saves the masked result to output_dir.\n",
    "    \"\"\"\n",
    "    input_dir = Path(input_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Extensions to look for\n",
    "    valid_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}\n",
    "    \n",
    "    # 1. Gather all valid image files first\n",
    "    print(f\"Scanning for images in: {input_dir}...\")\n",
    "    image_files = [\n",
    "        f for f in input_dir.iterdir() \n",
    "        if f.name.startswith('img_') and f.suffix.lower() in valid_extensions\n",
    "    ]\n",
    "    \n",
    "    if not image_files:\n",
    "        print(\"No images found starting with 'img_' in the directory.\")\n",
    "        return\n",
    "\n",
    "    # 2. Iterate with tqdm\n",
    "    count = 0\n",
    "    \n",
    "    for file_path in tqdm(image_files, desc=\"Processing Images\", unit=\"img\"):\n",
    "        # Construct expected mask filename: img_123.jpg -> mask_123.jpg\n",
    "        mask_name = file_path.name.replace('img_', 'mask_', 1)\n",
    "        mask_path = input_dir / mask_name\n",
    "        \n",
    "        # Fallback: If mask_123.jpg doesn't exist, try mask_123.png\n",
    "        if not mask_path.exists():\n",
    "            mask_stem = file_path.stem.replace('img_', 'mask_', 1)\n",
    "            mask_path = input_dir / (mask_stem + \".png\")\n",
    "        \n",
    "        if mask_path.exists():\n",
    "            output_path = output_dir / file_path.name\n",
    "            \n",
    "            if output_path.exists():\n",
    "                # Skip silently\n",
    "                continue\n",
    "\n",
    "            apply_mask(file_path, mask_path, output_path, target_size=target_size)\n",
    "            count += 1\n",
    "        else:\n",
    "            # Use tqdm.write to log errors without breaking the progress bar\n",
    "            tqdm.write(f\"Skipping {file_path.name}: No matching mask found (looked for {mask_name})\")\n",
    "\n",
    "    print(f\"Batch processing complete. Processed {count} new images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecbf077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    \"\"\"\n",
    "    Load and preprocess images from a specified folder with a progress bar.\n",
    "\n",
    "    Args:\n",
    "        folder (str): Path to the folder containing images\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Array of preprocessed images with shape (N, H, W, C)\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    \n",
    "    # Get the list of files to iterate over\n",
    "    file_list = os.listdir(folder)\n",
    "\n",
    "    # Iterate through files with a tqdm progress bar\n",
    "    for filename in tqdm(file_list, desc=f\"Loading images from {os.path.basename(folder)}\"):\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        # Check if image was loaded successfully right away\n",
    "        if img is None:\n",
    "            print(f\"Warning: Failed to load image at {img_path}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Normalize image pixel values to a float range [0, 1]\n",
    "        img = (img / 255.0).astype(np.float32)\n",
    "\n",
    "        # Convert image from BGR to RGB\n",
    "        img = img[..., ::-1]\n",
    "\n",
    "        #NOTE: commented out because the images are already resized\n",
    "        # Crop the image to be square\n",
    "        # dim = min(img.shape[:2])\n",
    "        # start_y = (img.shape[0] - dim) // 2\n",
    "        # start_x = (img.shape[1] - dim) // 2\n",
    "        # img = img[start_y:start_y+dim, start_x:start_x+dim, :]\n",
    "\n",
    "        # NOTE: commented out because the images are already resized\n",
    "        # Resize the image to 224x224 pixels \n",
    "        # img = cv2.resize(img, (224, 224))\n",
    "\n",
    "        images.append(img)\n",
    "\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8fdc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_batch(SOURCE_FOLDER, OUTPUT_FOLDER, target_size=TARGET_SIZE)\n",
    "MASKED_IMAGE_PATH = OUTPUT_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd395a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = load_images_from_folder(MASKED_IMAGE_PATH)\n",
    "print(f\"Loaded {len(train_images)}  images\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4255eb",
   "metadata": {},
   "source": [
    "## **3. Exploration and Data Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2800ac35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of images to display\n",
    "num_img = 10\n",
    "start_img= 100\n",
    "# Create subplots for displaying items\n",
    "fig, axes = plt.subplots(2, num_img//2, figsize=(20, 9))\n",
    "for i in range(start_img, start_img+num_img):\n",
    "    ax = axes[i%2, i%num_img//2]\n",
    "    ax.imshow(np.clip(train_images[i], 0, 1))  # Display clipped item images\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b56890",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 1. Load the labels CSV\n",
    "labels_df = pd.read_csv(train_labels_path)\n",
    "# Create a dictionary mapping filename -> label for fast lookup\n",
    "labels_map = dict(zip(labels_df.iloc[:, 0], labels_df.iloc[:, 1]))\n",
    "\n",
    "# 2. Get the filenames corresponding to the images loaded in Cell 7\n",
    "# IMPORTANT: This must match the order used in 'load_images_from_folder' exactly.\n",
    "# We re-read the file list to ensure we have the specific names associated with the indices of 'train_images'\n",
    "filenames = os.listdir(MASKED_IMAGE_PATH)\n",
    "\n",
    "print(\"Aligning labels to loaded images...\")\n",
    "\n",
    "X_aligned = []\n",
    "y_aligned = []\n",
    "\n",
    "# 3. Iterate through the filenames to sync X (images) and y (labels)\n",
    "# We assume 'train_images' matches the order of 'filenames' because they rely on the same os.listdir call order\n",
    "# provided no files were added/deleted between Cell 7 and Cell 9.\n",
    "if len(filenames) != len(train_images):\n",
    "    raise ValueError(f\"Mismatch! Loaded images ({len(train_images)}) != Files found ({len(filenames)}).\")\n",
    "\n",
    "for i, filename in enumerate(filenames):\n",
    "    if filename in labels_map:\n",
    "        # If the file exists in our CSV, keep the image and the label\n",
    "        X_aligned.append(train_images[i])\n",
    "        y_aligned.append(labels_map[filename])\n",
    "    else:\n",
    "        # If image is in folder but NOT in CSV, we must discard the image\n",
    "        print(f\"Skipping {filename}: Image found but no label in CSV.\")\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = np.array(X_aligned)\n",
    "y = np.array(y_aligned)\n",
    "\n",
    "print(f\"Images aligned: {X.shape}\")\n",
    "print(f\"Labels aligned: {y.shape}\")\n",
    "\n",
    "# 4. Encode labels (String -> Integer)\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Print class mapping\n",
    "print(\"Classes:\", label_encoder.classes_)\n",
    "\n",
    "# 5. Train-Test Split (Stratified)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y_encoded, \n",
    "    test_size=0.2, \n",
    "    random_state=SEED, \n",
    "    stratify=y_encoded\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    test_size=0.5,\n",
    "    random_state=SEED,\n",
    "    stratify=y_temp\n",
    ")\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}, Labels: {y_train.shape}\")\n",
    "print(f\"Validation data shape: {X_val.shape}, Labels: {y_val.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}, Labels: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e11a875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input shape based on the training data\n",
    "input_shape = (X_train.shape[3], X_train.shape[1], X_train.shape[2])\n",
    "\n",
    "# Define the number of classes\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "print(\"Input Shape:\", input_shape)\n",
    "print(\"Number of Classes:\", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa29695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numpy arrays to PyTorch datasets (without augmentation for now)\n",
    "train_ds = TensorDataset(\n",
    "    torch.from_numpy(X_train).permute(0, 3, 1, 2),\n",
    "    torch.from_numpy(y_train).squeeze().long()\n",
    ")\n",
    "val_ds = TensorDataset(\n",
    "    torch.from_numpy(X_val).permute(0, 3, 1, 2),\n",
    "    torch.from_numpy(y_val).squeeze().long()\n",
    ")\n",
    "test_ds = TensorDataset(\n",
    "    torch.from_numpy(X_test).permute(0, 3, 1, 2),\n",
    "    torch.from_numpy(y_test).squeeze().long()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9b9ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the batch size\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f28dec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_loader(ds, batch_size, shuffle, drop_last):\n",
    "    \"\"\"\n",
    "    Create a PyTorch DataLoader with optimized settings.\n",
    "\n",
    "    Args:\n",
    "        ds (Dataset): PyTorch Dataset object\n",
    "        batch_size (int): Number of samples per batch\n",
    "        shuffle (bool): Whether to shuffle data at each epoch\n",
    "        drop_last (bool): Whether to drop last incomplete batch\n",
    "\n",
    "    Returns:\n",
    "        DataLoader: Configured DataLoader instance\n",
    "    \"\"\"\n",
    "    # Determine optimal number of worker processes for data loading\n",
    "    cpu_cores = os.cpu_count() or 2\n",
    "    num_workers = max(2, min(4, cpu_cores))\n",
    "\n",
    "    # Create DataLoader with performance optimizations\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,  # Faster GPU transfer\n",
    "        pin_memory_device=\"cuda\" if torch.cuda.is_available() else \"\",\n",
    "        prefetch_factor=4,  # Load 4 batches ahead\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f35e903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders with different settings for each phase\n",
    "train_loader = make_loader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "val_loader = make_loader(val_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "test_loader = make_loader(test_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f00022b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one batch from the training data loader\n",
    "for xb, yb in train_loader:\n",
    "    print(\"Features batch shape:\", xb.shape)\n",
    "    print(\"Labels batch shape:\", yb.shape)\n",
    "    break  # Stop after getting one batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d83fce4",
   "metadata": {},
   "source": [
    "## **4. Training Parameters**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
