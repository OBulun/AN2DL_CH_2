{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3293c812",
   "metadata": {
    "id": "3293c812"
   },
   "source": [
    "## **1. Google Drive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de8b7388",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edee15c7",
   "metadata": {
    "id": "edee15c7"
   },
   "source": [
    "## **2. Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "963c7403",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "963c7403",
    "outputId": "b6727f0e-41f8-4a6b-dea0-f74d54e6a861"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.8.0+cu128\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set seed for reproducibility\n",
    "SEED = 42\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "\n",
    "# Set environment variables before importing modules\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "os.environ['MPLCONFIGDIR'] = os.getcwd() + '/configs/'\n",
    "\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "# Import necessary modules\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from optuna.samplers import TPESampler\n",
    "# Set seeds for random number generators in NumPy and Python\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# Import PyTorch\n",
    "import torch\n",
    "torch.manual_seed(SEED)\n",
    "from torch import nn\n",
    "from torchvision.transforms import v2 as transforms\n",
    "from torch.utils.data import  DataLoader\n",
    "\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import GridSampler\n",
    "import torch.optim as optim\n",
    "\n",
    "# Import other libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Configure plot display settings\n",
    "sns.set(font_scale=1.4)\n",
    "sns.set_style('white')\n",
    "plt.rc('font', size=14)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5b1ee8",
   "metadata": {
    "id": "3b5b1ee8"
   },
   "source": [
    "## **3. Config**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d674a2d",
   "metadata": {
    "id": "7d674a2d"
   },
   "outputs": [],
   "source": [
    "USE_MASKED_PATCHES = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df3da911",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "df3da911",
    "outputId": "8f0365f9-913a-4b45-9039-d4b26ac59c53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset path: ../an2dl2526c2\n",
      "Train data path: ../an2dl2526c2/train_data\n",
      "Train labels path: ../an2dl2526c2/train_labels.csv\n",
      "Test data path: ../an2dl2526c2/test_data\n",
      "Patches output path: ../an2dl2526c2/preprocessing_results/train_patches\n",
      "Submission patches output path: ../an2dl2526c2/preprocessing_results/submission_patches\n"
     ]
    }
   ],
   "source": [
    "datasets_path = os.path.join(os.path.pardir, \"an2dl2526c2\")\n",
    "\n",
    "train_data_path = os.path.join(datasets_path, \"train_data\")\n",
    "train_labels_path = os.path.join(datasets_path, \"train_labels.csv\")\n",
    "test_data_path = os.path.join(datasets_path, \"test_data\")\n",
    "\n",
    "CSV_PATH = train_labels_path                # Path to the CSV file with labels\n",
    "SOURCE_FOLDER = train_data_path\n",
    "\n",
    "if USE_MASKED_PATCHES:\n",
    "  PATCHES_OUT = os.path.join(datasets_path, \"preprocessing_results_masked\",\"train_patches_masked\")\n",
    "  SUBMISSION_PATCHES_OUT = os.path.join(datasets_path, \"preprocessing_results_masked\",\"submission_patches_masked\")\n",
    "else:\n",
    "  PATCHES_OUT = os.path.join(datasets_path, \"preprocessing_results\",\"train_patches\")\n",
    "  SUBMISSION_PATCHES_OUT = os.path.join(datasets_path, \"preprocessing_results\",\"submission_patches\")\n",
    "\n",
    "print(f\"Dataset path: {datasets_path}\")\n",
    "print(f\"Train data path: {train_data_path}\")\n",
    "print(f\"Train labels path: {train_labels_path}\")\n",
    "print(f\"Test data path: {test_data_path}\")\n",
    "print(f\"Patches output path: {PATCHES_OUT}\")\n",
    "print(f\"Submission patches output path: {SUBMISSION_PATCHES_OUT}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "TARGET_SIZE = (224, 224)                    # Target size for the resized images and masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e427b09e",
   "metadata": {
    "id": "e427b09e"
   },
   "source": [
    "## **4. Train/Val Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cc7455a",
   "metadata": {
    "id": "7cc7455a"
   },
   "outputs": [],
   "source": [
    "def create_metadata_dataframe(patches_dir, labels_csv_path):\n",
    "    \"\"\"\n",
    "    Creates a DataFrame mapping patch filenames to their Bag IDs and Labels.\n",
    "    \"\"\"\n",
    "    # 1. Load the labels CSV\n",
    "    # Assuming CSV structure: [image_id, label] or similar\n",
    "    df_labels = pd.read_csv(labels_csv_path)\n",
    "\n",
    "    # Standardize column names for easier merging\n",
    "    # We assume the first column is the ID and the second is the Label\n",
    "    id_col = df_labels.columns[0]\n",
    "    label_col = df_labels.columns[1]\n",
    "\n",
    "    # Ensure IDs in CSV are strings (to match filenames)\n",
    "    df_labels[id_col] = df_labels[id_col].astype(str)\n",
    "\n",
    "    # If the CSV IDs contain extensions (e.g., 'img_001.png'), remove them\n",
    "    # because our parsed Bag IDs won't have them.\n",
    "    df_labels[id_col] = df_labels[id_col].apply(lambda x: os.path.splitext(x)[0])\n",
    "\n",
    "    # 2. List all patch files\n",
    "    patch_files = [f for f in os.listdir(patches_dir) if f.endswith('.png')]\n",
    "\n",
    "    # 3. Parse filenames to get Bag IDs\n",
    "    data = []\n",
    "    print(f\"Found {len(patch_files)} patches. Parsing metadata...\")\n",
    "\n",
    "    for filename in patch_files:\n",
    "        # Expected format from your preprocessing: {base_name}_p{i}.png\n",
    "        # Example: \"img_0015_p12.png\" -> Bag ID should be \"img_0015\"\n",
    "\n",
    "        # Split from the right on '_p' to separate Bag ID from Patch Index\n",
    "        # \"img_0015_p12.png\" -> [\"img_0015\", \"12.png\"]\n",
    "        try:\n",
    "            bag_id = filename.rsplit('_p', 1)[0]\n",
    "\n",
    "            data.append({\n",
    "                'filename': filename,\n",
    "                'sample_id': bag_id,\n",
    "                'path': os.path.join(patches_dir, filename)\n",
    "            })\n",
    "        except IndexError:\n",
    "            print(f\"Skipping malformed filename: {filename}\")\n",
    "\n",
    "    # Create temporary patches DataFrame\n",
    "    df_patches = pd.DataFrame(data)\n",
    "\n",
    "    # 4. Merge patches with labels\n",
    "    # This assigns the correct Bag Label to every Patch in that Bag\n",
    "    df = pd.merge(df_patches, df_labels, left_on='sample_id', right_on=id_col, how='inner')\n",
    "\n",
    "    # 5. Clean up and Rename\n",
    "    # Keep only required columns\n",
    "    df = df[['filename', label_col, 'sample_id', 'path']]\n",
    "\n",
    "    # Rename label column to standard 'label' if it isn't already\n",
    "    df = df.rename(columns={label_col: 'label'})\n",
    "\n",
    "    print(f\"Successfully created DataFrame with {len(df)} rows.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "633b8e05",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "633b8e05",
    "outputId": "7d671b8b-3e81-446b-d478-67847824bf41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3097 patches. Parsing metadata...\n",
      "Successfully created DataFrame with 3097 rows.\n",
      "\n",
      "First 5 rows:\n",
      "          filename      label sample_id\n",
      "0  img_0690_p2.png  Luminal A  img_0690\n",
      "1  img_0690_p1.png  Luminal A  img_0690\n",
      "2  img_0690_p0.png  Luminal A  img_0690\n",
      "3  img_0689_p3.png  Luminal A  img_0689\n",
      "4  img_0689_p2.png  Luminal A  img_0689\n",
      "\n",
      "Patches per Bag (Distribution):\n",
      "count    631.000000\n",
      "mean       4.908082\n",
      "std        2.913207\n",
      "min        1.000000\n",
      "25%        3.000000\n",
      "50%        4.000000\n",
      "75%        6.000000\n",
      "max       23.000000\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "patches_metadata_df = create_metadata_dataframe(PATCHES_OUT, CSV_PATH)\n",
    "\n",
    "# Verify the result\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(patches_metadata_df.head().drop(columns=['path']))\n",
    "print(\"\\nPatches per Bag (Distribution):\")\n",
    "print(patches_metadata_df['sample_id'].value_counts().describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc6c6cd3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bc6c6cd3",
    "outputId": "be243fc3-59b3-4318-ed4b-09eb2ce21d3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Label Encoding\n",
      "==================================================\n",
      "\n",
      "Original Labels: ['HER2(+)' 'Luminal A' 'Luminal B' 'Triple negative']\n",
      "Encoded as: [0, 1, 2, 3]\n",
      "\n",
      "Label Mapping:\n",
      "  HER2(+) -> 0\n",
      "  Luminal A -> 1\n",
      "  Luminal B -> 2\n",
      "  Triple negative -> 3\n"
     ]
    }
   ],
   "source": [
    "# Add Label Encoding\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Label Encoding\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "patches_metadata_df['label_encoded'] = label_encoder.fit_transform(patches_metadata_df['label'])\n",
    "\n",
    "print(f\"\\nOriginal Labels: {label_encoder.classes_}\")\n",
    "print(f\"Encoded as: {list(range(len(label_encoder.classes_)))}\")\n",
    "print(f\"\\nLabel Mapping:\")\n",
    "for orig, enc in zip(label_encoder.classes_, range(len(label_encoder.classes_))):\n",
    "    print(f\"  {orig} -> {enc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52314ae9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "52314ae9",
    "outputId": "ce81e6f4-f3fe-4311-ebd2-11946f50a08e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Train/Val Split on Original Images\n",
      "==================================================\n",
      "\n",
      "Total unique samples (original images): 631\n",
      "Train samples: 504\n",
      "Val samples: 127\n",
      "\n",
      "Train patches: 2445\n",
      "Val patches: 652\n",
      "\n",
      "Train label distribution:\n",
      "label\n",
      "Luminal B          852\n",
      "Luminal A          684\n",
      "HER2(+)            676\n",
      "Triple negative    233\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Val label distribution:\n",
      "label\n",
      "Luminal B          238\n",
      "HER2(+)            160\n",
      "Luminal A          159\n",
      "Triple negative     95\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==================================================\n",
      "Percentage Distribution\n",
      "==================================================\n",
      "\n",
      "Train label percentage:\n",
      "label\n",
      "Luminal B          34.846626\n",
      "Luminal A          27.975460\n",
      "HER2(+)            27.648262\n",
      "Triple negative     9.529652\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Val label percentage:\n",
      "label\n",
      "Luminal B          36.503067\n",
      "HER2(+)            24.539877\n",
      "Luminal A          24.386503\n",
      "Triple negative    14.570552\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Train/Val Split on Original Images (not patches)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Train/Val Split on Original Images\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Get unique sample IDs\n",
    "unique_samples = patches_metadata_df['sample_id'].unique()\n",
    "print(f\"\\nTotal unique samples (original images): {len(unique_samples)}\")\n",
    "\n",
    "# Split samples into train (80%) and val (20%)\n",
    "train_samples, val_samples = train_test_split(\n",
    "    unique_samples,\n",
    "    test_size=0.2,\n",
    "    random_state=SEED,\n",
    "    stratify=patches_metadata_df.drop_duplicates('sample_id').set_index('sample_id').loc[unique_samples, 'label_encoded'].values\n",
    ")\n",
    "\n",
    "print(f\"Train samples: {len(train_samples)}\")\n",
    "print(f\"Val samples: {len(val_samples)}\")\n",
    "\n",
    "# Create train and val DataFrames by filtering patches\n",
    "df_train = patches_metadata_df[patches_metadata_df['sample_id'].isin(train_samples)].reset_index(drop=True)\n",
    "df_val = patches_metadata_df[patches_metadata_df['sample_id'].isin(val_samples)].reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nTrain patches: {len(df_train)}\")\n",
    "print(f\"Val patches: {len(df_val)}\")\n",
    "print(f\"\\nTrain label distribution:\\n{df_train['label'].value_counts()}\")\n",
    "print(f\"\\nVal label distribution:\\n{df_val['label'].value_counts()}\")\n",
    "\n",
    "# Print percentage distribution\n",
    "print(f\"\\n\" + \"=\"*50)\n",
    "print(\"Percentage Distribution\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nTrain label percentage:\\n{df_train['label'].value_counts(normalize=True) * 100}\")\n",
    "print(f\"\\nVal label percentage:\\n{df_val['label'].value_counts(normalize=True) * 100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b797aff",
   "metadata": {
    "id": "4b797aff"
   },
   "source": [
    "## **5. Transformations & Augmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94459d26",
   "metadata": {
    "id": "94459d26"
   },
   "outputs": [],
   "source": [
    "# Define augmentation for training with enhanced transformations\n",
    "train_augmentation = transforms.Compose([\n",
    "    # Geometric transformations\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=15),  # Small rotations to handle orientation variations\n",
    "    transforms.RandomAffine(\n",
    "        degrees=0,\n",
    "        translate=(0.1, 0.1),  # Reduced from 0.2 for more conservative shifts\n",
    "        scale=None,  # Add scale variation\n",
    "        shear=10  # Add shear transformation\n",
    "    ),\n",
    "\n",
    "    # Color/appearance transformations\n",
    "    transforms.ColorJitter(\n",
    "        brightness=0.2,  # Adjust brightness\n",
    "        contrast=0.2,    # Adjust contrast\n",
    "        saturation=0.2,  # Adjust saturation\n",
    "        hue=0.1          # Slight hue variation\n",
    "    ),\n",
    "    #transforms.RandomGrayscale(p=0.1),  # Occasionally convert to grayscale to improve robustness\n",
    "\n",
    "    # Occlusion simulation\n",
    "    #transforms.RandomErasing(\n",
    "    #    p=0.3,  # Reduced probability for more balanced augmentation\n",
    "    #    scale=(0.02, 0.15),  # Reduced max scale\n",
    "    #    ratio=(0.3, 3.3)  # Aspect ratio range\n",
    "    #),\n",
    "\n",
    "    # Optional: Add Gaussian blur for noise robustness\n",
    "    # transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8cdd92",
   "metadata": {
    "id": "dc8cdd92"
   },
   "source": [
    "## **6. Custom Dataset Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29b69bba",
   "metadata": {
    "id": "29b69bba"
   },
   "outputs": [],
   "source": [
    "# ImageNet normalization statistics\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "class TissueDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, augmentation=None, normalize_imagenet=False, cache_images=True):\n",
    "        self.augmentation = augmentation\n",
    "        self.normalize_imagenet = normalize_imagenet\n",
    "        self.df = df\n",
    "        \n",
    "        # CRITICAL OPTIMIZATION: Pre-convert to lists\n",
    "        self.paths = df['path'].tolist()\n",
    "        self.labels = df['label_encoded'].tolist()\n",
    "        \n",
    "        # Define transforms\n",
    "        self.to_tensor = transforms.Compose([\n",
    "            transforms.Resize(TARGET_SIZE),\n",
    "            transforms.ToImage(),\n",
    "            transforms.ToDtype(torch.float32, scale=True)\n",
    "        ])\n",
    "        \n",
    "        if normalize_imagenet:\n",
    "            self.normalize = transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "        else:\n",
    "            self.normalize = None\n",
    "        \n",
    "        # For external use\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize(TARGET_SIZE),\n",
    "            transforms.ToImage(),\n",
    "            transforms.ToDtype(torch.float32, scale=True),\n",
    "            transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD) if normalize_imagenet else transforms.Identity()\n",
    "        ])\n",
    "        \n",
    "        # --- IMAGE CACHING (Pre-load all images) ---\n",
    "        self.image_cache = {}\n",
    "        if cache_images:\n",
    "            self._preload_images()\n",
    "    \n",
    "    def _preload_images(self):\n",
    "        \"\"\"Pre-load all images into memory for O(1) access during training.\"\"\"\n",
    "        total_images = len(self.paths)\n",
    "        \n",
    "        with tqdm(total=total_images, desc=\"Pre-loading images\", unit=\"img\") as pbar:\n",
    "            for img_path in self.paths:\n",
    "                if img_path not in self.image_cache:\n",
    "                    try:\n",
    "                        image = Image.open(img_path).convert(\"RGB\")\n",
    "                        image = self.to_tensor(image)\n",
    "                        self.image_cache[img_path] = image\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error loading image {img_path}: {e}\")\n",
    "                        self.image_cache[img_path] = None\n",
    "                \n",
    "                pbar.update(1)\n",
    "        \n",
    "        print(f\"Successfully cached {len(self.image_cache)} images.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Load image (from cache or disk)\n",
    "        if img_path in self.image_cache:\n",
    "            image = self.image_cache[img_path]\n",
    "            if image is None:\n",
    "                # Fallback for corrupted cached images\n",
    "                image = torch.ones((3, TARGET_SIZE[0], TARGET_SIZE[1]), dtype=torch.float32) * 0.5\n",
    "        else:\n",
    "            # Fallback: Load on-the-fly if not cached\n",
    "            try:\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                image = self.to_tensor(img)\n",
    "            except:\n",
    "                image = torch.ones((3, TARGET_SIZE[0], TARGET_SIZE[1]), dtype=torch.float32) * 0.5\n",
    "        \n",
    "        # Apply augmentation\n",
    "        if self.augmentation:\n",
    "            image = self.augmentation(image)\n",
    "        \n",
    "        # Apply normalization\n",
    "        if self.normalize:\n",
    "            image = self.normalize(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa4cb5a",
   "metadata": {
    "id": "ffa4cb5a"
   },
   "source": [
    "## **7. Data Loaders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7a923ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pre-loading images: 100%|██████████| 2445/2445 [00:10<00:00, 225.61img/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully cached 2445 images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pre-loading images: 100%|██████████| 652/652 [00:02<00:00, 232.03img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully cached 652 images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if LOCAL: \n",
    "    num_workers = 0\n",
    "    CACHE_IMAGES = False\n",
    "else:\n",
    "    num_workers = os.cpu_count()//2\n",
    "    CACHE_IMAGES = True\n",
    "\n",
    "# Instantiate Datasets\n",
    "train_dataset = TissueDataset(\n",
    "    df_train, \n",
    "    augmentation=train_augmentation, \n",
    "    normalize_imagenet=True,\n",
    "    cache_images=CACHE_IMAGES  # Enable image pre-loading\n",
    ")\n",
    "val_dataset = TissueDataset(\n",
    "    df_val, \n",
    "    augmentation=None, \n",
    "    normalize_imagenet=True,\n",
    "    cache_images=CACHE_IMAGES  # Enable image pre-loading\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1d978b",
   "metadata": {
    "id": "4f1d978b"
   },
   "source": [
    "## **9. Model Definition (Transfer Learning - MobileNetV3)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c6c4ec0",
   "metadata": {
    "id": "5c6c4ec0"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# IMPORTANT: this is RetCCL's ResNet implementation (copy ResNet.py from the RetCCL repo)\n",
    "import ResNet as RetCCLResNet\n",
    "\n",
    "\n",
    "def _clean_state_dict(sd: dict) -> dict:\n",
    "    \"\"\"Strip common prefixes (DataParallel, wrapper modules).\"\"\"\n",
    "    out = {}\n",
    "    for k, v in sd.items():\n",
    "        for p in (\"module.\", \"model.\", \"encoder.\", \"backbone.\"):\n",
    "            if k.startswith(p):\n",
    "                k = k[len(p):]\n",
    "        out[k] = v\n",
    "    return out\n",
    "\n",
    "\n",
    "class RetCCLResNet50(nn.Module):\n",
    "    \"\"\"\n",
    "    Drop-in replacement for your ResNet18 class, but using RetCCL (CNN) ResNet50 backbone.\n",
    "\n",
    "    Args match your original:\n",
    "      - num_classes\n",
    "      - dropout_rate\n",
    "      - freeze_backbone\n",
    "\n",
    "    Extra:\n",
    "      - ckpt_path: path to RetCCL checkpoint (e.g., best_ckpt.pth)\n",
    "      - unfreeze_last_block: often helps on small datasets\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes: int,\n",
    "        dropout_rate: float = 0.2,\n",
    "        freeze_backbone: bool = True,\n",
    "        ckpt_path: str = \"best_ckpt.pth\",\n",
    "        unfreeze_last_block: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # 1) Build RetCCL ResNet50 (their script uses num_classes=128 for the pretext head)\n",
    "        self.backbone = RetCCLResNet.resnet50(\n",
    "            num_classes=128, mlp=False, two_branch=False, normlinear=True\n",
    "        )\n",
    "\n",
    "        # 2) Load RetCCL pretrained weights\n",
    "        sd = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "        if isinstance(sd, dict) and \"state_dict\" in sd:\n",
    "            sd = sd[\"state_dict\"]\n",
    "        sd = _clean_state_dict(sd)\n",
    "\n",
    "        # Drop any fc keys from the checkpoint (we replace the head anyway)\n",
    "        sd = {k: v for k, v in sd.items() if not k.startswith(\"fc.\")}\n",
    "\n",
    "        msg = self.backbone.load_state_dict(sd, strict=False)\n",
    "        # Uncomment for debugging:\n",
    "        # print(\"Missing keys:\", msg.missing_keys)\n",
    "        # print(\"Unexpected keys:\", msg.unexpected_keys)\n",
    "\n",
    "        # 3) Replace fc with your custom multi-layer head\n",
    "        # RetCCL fc may not expose .in_features (e.g., NormLinear), so use weight shape\n",
    "        if hasattr(self.backbone.fc, \"in_features\"):\n",
    "            in_features = self.backbone.fc.in_features\n",
    "        elif hasattr(self.backbone.fc, \"weight\"):\n",
    "            in_features = self.backbone.fc.weight.shape[1]\n",
    "        else:\n",
    "            # ResNet50 default is 2048 if all else fails\n",
    "            in_features = 2048\n",
    "\n",
    "        self.backbone.fc = nn.Sequential(\n",
    "            nn.Linear(in_features, 1024),\n",
    "            nn.Hardswish(inplace=True),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "        # 4) Freeze backbone (optional) + optionally unfreeze last block\n",
    "        if freeze_backbone:\n",
    "            for p in self.backbone.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "            # always train the new head\n",
    "            for p in self.backbone.fc.parameters():\n",
    "                p.requires_grad = True\n",
    "\n",
    "            # often beneficial for small pathology datasets\n",
    "            if unfreeze_last_block and hasattr(self.backbone, \"layer4\"):\n",
    "                for p in self.backbone.layer4.parameters():\n",
    "                    p.requires_grad = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eee73770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import ResNet as RetCCLResNet # Ensure this matches your import\n",
    "\n",
    "class RetCCLResNet50_Flexible(RetCCLResNet50):\n",
    "    \"\"\"\n",
    "    Extends your original class to support dynamic MLP heads for Grid Search.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes: int,\n",
    "        dropout_rate: float = 0.2,\n",
    "        freeze_backbone: bool = True,\n",
    "        ckpt_path: str = \"best_ckpt.pth\",\n",
    "        unfreeze_last_block: bool = True,\n",
    "        # New parameters for head search\n",
    "        head_type: str = 'original', # 'linear', 'mlp_1_layer', 'original'\n",
    "        head_hidden_dim: int = 1024\n",
    "    ):\n",
    "        # Initialize the base model (loads weights, sets up backbone)\n",
    "        super().__init__(\n",
    "            num_classes=num_classes,\n",
    "            dropout_rate=dropout_rate,\n",
    "            freeze_backbone=freeze_backbone,\n",
    "            ckpt_path=ckpt_path,\n",
    "            unfreeze_last_block=unfreeze_last_block\n",
    "        )\n",
    "\n",
    "        # Detect input features (ResNet50 usually 2048)\n",
    "        # We look at the first layer of the head created by the parent class to find input size\n",
    "        if isinstance(self.backbone.fc, nn.Sequential):\n",
    "            in_features = self.backbone.fc[0].in_features\n",
    "        elif isinstance(self.backbone.fc, nn.Linear):\n",
    "            in_features = self.backbone.fc.in_features\n",
    "        else:\n",
    "            in_features = 2048 \n",
    "\n",
    "        # --- Re-define the Head based on 'head_type' ---\n",
    "        \n",
    "        # Variation 1: Simple Linear (Logistic Regression equivalent)\n",
    "        if head_type == 'linear':\n",
    "            self.backbone.fc = nn.Linear(in_features, num_classes)\n",
    "            \n",
    "        # Variation 2: 1 Hidden Layer (Standard MLP)\n",
    "        elif head_type == 'mlp_1_layer':\n",
    "            self.backbone.fc = nn.Sequential(\n",
    "                nn.Linear(in_features, head_hidden_dim),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(p=dropout_rate),\n",
    "                nn.Linear(head_hidden_dim, num_classes),\n",
    "            )\n",
    "            \n",
    "        # Variation 3: Your Original Complex Head (2 Hidden Layers + Hardswish)\n",
    "        elif head_type == 'original':\n",
    "            self.backbone.fc = nn.Sequential(\n",
    "                nn.Linear(in_features, 1024),\n",
    "                nn.Hardswish(inplace=True),\n",
    "                nn.Dropout(p=dropout_rate),\n",
    "                nn.Linear(1024, 256),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(p=dropout_rate),\n",
    "                nn.Linear(256, num_classes),\n",
    "            )\n",
    "            \n",
    "        # Ensure the new head is trainable\n",
    "        for p in self.backbone.fc.parameters():\n",
    "            p.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfb49a6",
   "metadata": {
    "id": "fcfb49a6"
   },
   "source": [
    "## **10. Loss and Optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "378cee23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            alpha (Tensor, optional): Weights for each class. Shape [C].\n",
    "            gamma (float): Focusing parameter. Higher value = more focus on hard examples.\n",
    "                           Default is 2.0 (standard from the paper).\n",
    "            reduction (str): 'mean', 'sum', or 'none'.\n",
    "        \"\"\"\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # inputs: [Batch, C] (Logits)\n",
    "        # targets: [Batch] (Class Indices)\n",
    "        \n",
    "        # 1. Standard Cross Entropy Loss (element-wise, no reduction yet)\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        \n",
    "        # 2. Get the probability of the true class (pt)\n",
    "        # pt = exp(-ce_loss) because ce_loss = -log(pt)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        \n",
    "        # 3. Calculate Focal Component: (1 - pt)^gamma\n",
    "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
    "        \n",
    "        # 4. Apply Class Weights (alpha) if provided\n",
    "        if self.alpha is not None:\n",
    "            # Gather the alpha value corresponding to the target class for each sample\n",
    "            if self.alpha.device != inputs.device:\n",
    "                self.alpha = self.alpha.to(inputs.device)\n",
    "            \n",
    "            alpha_t = self.alpha[targets]\n",
    "            focal_loss = alpha_t * focal_loss\n",
    "\n",
    "        # 5. Reduction\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7aa519",
   "metadata": {
    "id": "9c7aa519"
   },
   "source": [
    "## **11. Function: Training & Validation Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37abb343",
   "metadata": {
    "id": "37abb343"
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Lists to store all predictions and labels for F1 calculation\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Metrics accumulation\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # Move to CPU and convert to numpy for sklearn metrics\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "\n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "    # Calculate F1 Score (Macro for imbalanced data)\n",
    "    epoch_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "    return epoch_loss, epoch_f1\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "    epoch_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "    return epoch_loss, epoch_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52adc741",
   "metadata": {},
   "source": [
    "## **OPTUNA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7de10848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define explicit combinations to avoid redundant runs in Grid Search\n",
    "LOSS_CONFIGS = {\n",
    "    # --- Focal Loss Variations ---\n",
    "    'focal_g2_weighted':   {'type': 'Focal', 'gamma': 2.0, 'use_weights': True,  'smoothing': 0.0},\n",
    "    'focal_g5_weighted':   {'type': 'Focal', 'gamma': 5.0, 'use_weights': True,  'smoothing': 0.0},\n",
    "    'focal_g2_no_weight':  {'type': 'Focal', 'gamma': 2.0, 'use_weights': False, 'smoothing': 0.0},\n",
    "    \n",
    "    # --- CrossEntropy Variations ---\n",
    "    'ce_plain':            {'type': 'CE',    'gamma': None, 'use_weights': False, 'smoothing': 0.0},\n",
    "    'ce_weighted':         {'type': 'CE',    'gamma': None, 'use_weights': True,  'smoothing': 0.0},\n",
    "    'ce_smooth_0.1':       {'type': 'CE',    'gamma': None, 'use_weights': False, 'smoothing': 0.1},\n",
    "    'ce_weighted_smooth':  {'type': 'CE',    'gamma': None, 'use_weights': True,  'smoothing': 0.1},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67f02161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # --- 1. Clean Hyperparameters (TPE supports ranges) ---\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-3, log=True)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [64])\n",
    "    optimizer_name = trial.suggest_categorical('optimizer', ['AdamW', 'RAdam'])\n",
    "    l2_reg = trial.suggest_float('l2_reg', 1e-5, 1e-2, log=True)\n",
    "    \n",
    "    # Corrected Dropout (removed the duplicate)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.3, 0.5) \n",
    "    \n",
    "    # Head Params\n",
    "    head_type = trial.suggest_categorical('head_type', ['linear', 'mlp_1_layer', 'original'])\n",
    "    head_hidden_dim = trial.suggest_categorical('head_hidden_dim', [512, 1024])\n",
    "\n",
    "    # --- 2. Smart Weight Logic ---\n",
    "    # We select the Loss Config first\n",
    "    loss_config_name = trial.suggest_categorical('loss_config', list(LOSS_CONFIGS.keys()))\n",
    "    current_loss_params = LOSS_CONFIGS[loss_config_name]\n",
    "    \n",
    "    # Only suggest weights if the loss config actually USES them\n",
    "    # This prevents TPE from wasting time tuning w1..w4 for unweighted losses\n",
    "    if current_loss_params['use_weights']:\n",
    "        w1 = trial.suggest_float('w1', 0.5, 1.0)\n",
    "        w2 = trial.suggest_float('w2', 0.5, 1.0)\n",
    "        w3 = trial.suggest_float('w3', 0.5, 1.0)\n",
    "        w4 = trial.suggest_float('w4', 1.0, 1.5)\n",
    "        final_weights = torch.tensor([w1, w2, w3, w4], dtype=torch.float32).to(device)\n",
    "    else:\n",
    "        final_weights = None\n",
    "\n",
    "    # --- 3. Data Loaders ---\n",
    "    opt_train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=os.cpu_count()//2, pin_memory=True)\n",
    "    opt_val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=os.cpu_count()//2, pin_memory=True)\n",
    "\n",
    "    # --- 4. Model Setup ---\n",
    "    model = RetCCLResNet50_Flexible(\n",
    "        num_classes=4, \n",
    "        dropout_rate=dropout_rate,\n",
    "        freeze_backbone=True, \n",
    "        ckpt_path=os.path.join(\"models\", \"best_ckpt.pth\"), \n",
    "        unfreeze_last_block=False,\n",
    "        head_type=head_type,\n",
    "        head_hidden_dim=head_hidden_dim\n",
    "    ).to(device)\n",
    "\n",
    "    # --- 5. Loss Setup ---\n",
    "    if current_loss_params['type'] == 'Focal':\n",
    "        criterion = FocalLoss(alpha=final_weights, gamma=current_loss_params['gamma'])\n",
    "    elif current_loss_params['type'] == 'CE':\n",
    "        criterion = nn.CrossEntropyLoss(weight=final_weights, label_smoothing=current_loss_params['smoothing'])\n",
    "    \n",
    "    # --- 6. Optimizer ---\n",
    "    if optimizer_name == 'AdamW':\n",
    "        optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, weight_decay=l2_reg)\n",
    "    elif optimizer_name == 'SGD':\n",
    "        optimizer = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, momentum=0.9, weight_decay=l2_reg)\n",
    "    else:  # RAdam\n",
    "        optimizer = optim.RAdam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, weight_decay=l2_reg, eps=1e-8, betas=(0.9, 0.999))\n",
    "\n",
    "    # --- 7. Training Loop ---\n",
    "    SEARCH_EPOCHS = 10 \n",
    "    best_f1_in_trial = 0.0\n",
    "\n",
    "    for epoch in range(SEARCH_EPOCHS):\n",
    "        # 1. Run Train & Val (Silent functions, no tqdm)\n",
    "        train_loss, train_f1 = train_one_epoch(model, opt_train_loader, criterion, optimizer, device)\n",
    "        val_loss, val_f1 = validate(model, opt_val_loader, criterion, device)\n",
    "\n",
    "        # 2. Update Best Score\n",
    "        if val_f1 > best_f1_in_trial:\n",
    "            best_f1_in_trial = val_f1\n",
    "        \n",
    "        # 3. PRINT PROGRESS (The Solution)\n",
    "        # This prints ONE line per epoch. Clean and informative.\n",
    "        print(f\" Trial {trial.number} | Epoch {epoch+1}/{SEARCH_EPOCHS} | \"\n",
    "              f\"Train Loss: {train_loss:.4f} | Train F1: {train_f1:.4f} | \"\n",
    "              f\"Val Loss: {val_loss:.4f} | Val F1: {val_f1:.4f}\")\n",
    "\n",
    "        # 4. Pruning\n",
    "        trial.report(val_f1, epoch)\n",
    "        if trial.should_prune():\n",
    "            print(f\"Trial {trial.number} Pruned at Epoch {epoch+1}\")\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    return best_f1_in_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5de81c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-13 12:25:59,286] A new study created in memory with name: retccl_head_search\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting TPE Search with 100 trials...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f036c517f01a49879cf13d692d08d7c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 0 | Epoch 1/10 | Train Loss: 0.2416 | Train F1: 0.2347 | Val Loss: 0.2544 | Val F1: 0.2853\n",
      " Trial 0 | Epoch 2/10 | Train Loss: 0.2233 | Train F1: 0.3310 | Val Loss: 0.2501 | Val F1: 0.2759\n",
      " Trial 0 | Epoch 3/10 | Train Loss: 0.2127 | Train F1: 0.3537 | Val Loss: 0.2430 | Val F1: 0.3117\n",
      " Trial 0 | Epoch 4/10 | Train Loss: 0.2010 | Train F1: 0.4308 | Val Loss: 0.2448 | Val F1: 0.3313\n",
      " Trial 0 | Epoch 5/10 | Train Loss: 0.1947 | Train F1: 0.4503 | Val Loss: 0.2358 | Val F1: 0.3584\n",
      " Trial 0 | Epoch 6/10 | Train Loss: 0.1883 | Train F1: 0.4517 | Val Loss: 0.2462 | Val F1: 0.3756\n",
      " Trial 0 | Epoch 7/10 | Train Loss: 0.1852 | Train F1: 0.4800 | Val Loss: 0.2515 | Val F1: 0.3835\n",
      " Trial 0 | Epoch 8/10 | Train Loss: 0.1811 | Train F1: 0.4776 | Val Loss: 0.2353 | Val F1: 0.3896\n",
      " Trial 0 | Epoch 9/10 | Train Loss: 0.1777 | Train F1: 0.4976 | Val Loss: 0.2672 | Val F1: 0.3916\n",
      " Trial 0 | Epoch 10/10 | Train Loss: 0.1753 | Train F1: 0.5006 | Val Loss: 0.2353 | Val F1: 0.4012\n",
      "[I 2025-12-13 12:26:37,621] Trial 0 finished with value: 0.40124035760828214 and parameters: {'lr': 0.00023688639503640813, 'batch_size': 64, 'optimizer': 'AdamW', 'l2_reg': 0.0006251373574521745, 'dropout_rate': 0.3312037280884873, 'head_type': 'original', 'head_hidden_dim': 1024, 'loss_config': 'focal_g5_weighted', 'w1': 0.762378215816119, 'w2': 0.7159725093210578, 'w3': 0.645614570099021, 'w4': 1.3059264473611898}. Best is trial 0 with value: 0.40124035760828214.\n",
      " Trial 1 | Epoch 1/10 | Train Loss: 1.3825 | Train F1: 0.1371 | Val Loss: 1.3833 | Val F1: 0.0985\n",
      " Trial 1 | Epoch 2/10 | Train Loss: 1.3720 | Train F1: 0.1957 | Val Loss: 1.3733 | Val F1: 0.1879\n",
      " Trial 1 | Epoch 3/10 | Train Loss: 1.3548 | Train F1: 0.2302 | Val Loss: 1.3578 | Val F1: 0.1337\n",
      " Trial 1 | Epoch 4/10 | Train Loss: 1.3295 | Train F1: 0.1400 | Val Loss: 1.3437 | Val F1: 0.1337\n",
      " Trial 1 | Epoch 5/10 | Train Loss: 1.3091 | Train F1: 0.1376 | Val Loss: 1.3416 | Val F1: 0.1337\n",
      " Trial 1 | Epoch 6/10 | Train Loss: 1.2961 | Train F1: 0.1394 | Val Loss: 1.3422 | Val F1: 0.1337\n",
      " Trial 1 | Epoch 7/10 | Train Loss: 1.2904 | Train F1: 0.1438 | Val Loss: 1.3400 | Val F1: 0.1337\n",
      " Trial 1 | Epoch 8/10 | Train Loss: 1.2852 | Train F1: 0.1759 | Val Loss: 1.3352 | Val F1: 0.1523\n",
      " Trial 1 | Epoch 9/10 | Train Loss: 1.2704 | Train F1: 0.2145 | Val Loss: 1.3293 | Val F1: 0.1761\n",
      " Trial 1 | Epoch 10/10 | Train Loss: 1.2574 | Train F1: 0.2579 | Val Loss: 1.3217 | Val F1: 0.2315\n",
      "[I 2025-12-13 12:27:14,845] Trial 1 finished with value: 0.23153577306119677 and parameters: {'lr': 0.00013787764619353784, 'batch_size': 64, 'optimizer': 'RAdam', 'l2_reg': 0.00023345864076016249, 'dropout_rate': 0.45703519227860273, 'head_type': 'original', 'head_hidden_dim': 1024, 'loss_config': 'ce_plain'}. Best is trial 0 with value: 0.40124035760828214.\n",
      " Trial 2 | Epoch 1/10 | Train Loss: 0.7268 | Train F1: 0.1354 | Val Loss: 0.7406 | Val F1: 0.1370\n",
      " Trial 2 | Epoch 2/10 | Train Loss: 0.6875 | Train F1: 0.1416 | Val Loss: 0.7378 | Val F1: 0.1868\n",
      " Trial 2 | Epoch 3/10 | Train Loss: 0.6746 | Train F1: 0.2898 | Val Loss: 0.7318 | Val F1: 0.2174\n",
      " Trial 2 | Epoch 4/10 | Train Loss: 0.6641 | Train F1: 0.2879 | Val Loss: 0.7246 | Val F1: 0.2589\n",
      " Trial 2 | Epoch 5/10 | Train Loss: 0.6528 | Train F1: 0.3417 | Val Loss: 0.7218 | Val F1: 0.2598\n",
      " Trial 2 | Epoch 6/10 | Train Loss: 0.6459 | Train F1: 0.3336 | Val Loss: 0.7171 | Val F1: 0.2738\n",
      " Trial 2 | Epoch 7/10 | Train Loss: 0.6415 | Train F1: 0.3549 | Val Loss: 0.7177 | Val F1: 0.2835\n",
      " Trial 2 | Epoch 8/10 | Train Loss: 0.6319 | Train F1: 0.3592 | Val Loss: 0.7109 | Val F1: 0.2777\n",
      " Trial 2 | Epoch 9/10 | Train Loss: 0.6277 | Train F1: 0.3595 | Val Loss: 0.7090 | Val F1: 0.2720\n",
      " Trial 2 | Epoch 10/10 | Train Loss: 0.6246 | Train F1: 0.3564 | Val Loss: 0.7077 | Val F1: 0.2709\n",
      "[I 2025-12-13 12:27:51,911] Trial 2 finished with value: 0.2835318912308744 and parameters: {'lr': 0.0004833180632488466, 'batch_size': 64, 'optimizer': 'AdamW', 'l2_reg': 0.0003058656666978527, 'dropout_rate': 0.30687770422304367, 'head_type': 'linear', 'head_hidden_dim': 1024, 'loss_config': 'focal_g2_no_weight'}. Best is trial 0 with value: 0.40124035760828214.\n",
      " Trial 3 | Epoch 1/10 | Train Loss: 1.3794 | Train F1: 0.2087 | Val Loss: 1.3679 | Val F1: 0.1497\n",
      " Trial 3 | Epoch 2/10 | Train Loss: 1.3225 | Train F1: 0.1643 | Val Loss: 1.3571 | Val F1: 0.1337\n",
      " Trial 3 | Epoch 3/10 | Train Loss: 1.2891 | Train F1: 0.2234 | Val Loss: 1.3219 | Val F1: 0.1743\n",
      " Trial 3 | Epoch 4/10 | Train Loss: 1.2488 | Train F1: 0.2465 | Val Loss: 1.3105 | Val F1: 0.2265\n",
      " Trial 3 | Epoch 5/10 | Train Loss: 1.2071 | Train F1: 0.3214 | Val Loss: 1.2861 | Val F1: 0.2963\n",
      " Trial 3 | Epoch 6/10 | Train Loss: 1.1879 | Train F1: 0.3472 | Val Loss: 1.2807 | Val F1: 0.2955\n",
      " Trial 3 | Epoch 7/10 | Train Loss: 1.1664 | Train F1: 0.3698 | Val Loss: 1.2833 | Val F1: 0.2915\n",
      " Trial 3 | Epoch 8/10 | Train Loss: 1.1353 | Train F1: 0.3729 | Val Loss: 1.2814 | Val F1: 0.3418\n",
      " Trial 3 | Epoch 9/10 | Train Loss: 1.1153 | Train F1: 0.4179 | Val Loss: 1.2828 | Val F1: 0.3161\n",
      " Trial 3 | Epoch 10/10 | Train Loss: 1.0946 | Train F1: 0.4236 | Val Loss: 1.2978 | Val F1: 0.3156\n",
      "[I 2025-12-13 12:28:29,234] Trial 3 finished with value: 0.3418246950649823 and parameters: {'lr': 0.0008353610755311764, 'batch_size': 64, 'optimizer': 'RAdam', 'l2_reg': 1.3667272915456215e-05, 'dropout_rate': 0.36506606615265286, 'head_type': 'original', 'head_hidden_dim': 512, 'loss_config': 'ce_weighted', 'w1': 0.5027610585618012, 'w2': 0.9077307142274171, 'w3': 0.8534286719238086, 'w4': 1.3645035840204938}. Best is trial 0 with value: 0.40124035760828214.\n",
      " Trial 4 | Epoch 1/10 | Train Loss: 0.7844 | Train F1: 0.1278 | Val Loss: 0.7760 | Val F1: 0.2069\n",
      " Trial 4 | Epoch 2/10 | Train Loss: 0.7570 | Train F1: 0.1409 | Val Loss: 0.7566 | Val F1: 0.1613\n",
      " Trial 4 | Epoch 3/10 | Train Loss: 0.7301 | Train F1: 0.1292 | Val Loss: 0.7440 | Val F1: 0.1337\n",
      " Trial 4 | Epoch 4/10 | Train Loss: 0.7106 | Train F1: 0.1292 | Val Loss: 0.7396 | Val F1: 0.1366\n",
      " Trial 4 | Epoch 5/10 | Train Loss: 0.6986 | Train F1: 0.1365 | Val Loss: 0.7376 | Val F1: 0.1514\n",
      " Trial 4 | Epoch 6/10 | Train Loss: 0.6897 | Train F1: 0.1647 | Val Loss: 0.7369 | Val F1: 0.1823\n",
      " Trial 4 | Epoch 7/10 | Train Loss: 0.6823 | Train F1: 0.1898 | Val Loss: 0.7355 | Val F1: 0.2001\n",
      " Trial 4 | Epoch 8/10 | Train Loss: 0.6765 | Train F1: 0.2179 | Val Loss: 0.7346 | Val F1: 0.2400\n",
      " Trial 4 | Epoch 9/10 | Train Loss: 0.6706 | Train F1: 0.2645 | Val Loss: 0.7338 | Val F1: 0.2655\n",
      " Trial 4 | Epoch 10/10 | Train Loss: 0.6656 | Train F1: 0.3237 | Val Loss: 0.7293 | Val F1: 0.2640\n",
      "[I 2025-12-13 12:29:06,332] Trial 4 finished with value: 0.2655309148682643 and parameters: {'lr': 0.0005905685925060639, 'batch_size': 64, 'optimizer': 'RAdam', 'l2_reg': 2.2264204303769678e-05, 'dropout_rate': 0.4726206851751187, 'head_type': 'linear', 'head_hidden_dim': 1024, 'loss_config': 'focal_g2_no_weight'}. Best is trial 0 with value: 0.40124035760828214.\n",
      " Trial 5 | Epoch 1/10 | Train Loss: 0.2427 | Train F1: 0.1443 | Val Loss: 0.2573 | Val F1: 0.1337\n",
      " Trial 5 | Epoch 2/10 | Train Loss: 0.2237 | Train F1: 0.1992 | Val Loss: 0.2501 | Val F1: 0.1964\n",
      " Trial 5 | Epoch 3/10 | Train Loss: 0.2139 | Train F1: 0.2800 | Val Loss: 0.2423 | Val F1: 0.2619\n",
      " Trial 5 | Epoch 4/10 | Train Loss: 0.2071 | Train F1: 0.3521 | Val Loss: 0.2479 | Val F1: 0.2878\n",
      " Trial 5 | Epoch 5/10 | Train Loss: 0.2009 | Train F1: 0.3740 | Val Loss: 0.2516 | Val F1: 0.2910\n",
      " Trial 5 | Epoch 6/10 | Train Loss: 0.1951 | Train F1: 0.4234 | Val Loss: 0.2454 | Val F1: 0.3233\n",
      " Trial 5 | Epoch 7/10 | Train Loss: 0.1918 | Train F1: 0.4277 | Val Loss: 0.2440 | Val F1: 0.3279\n",
      " Trial 5 | Epoch 8/10 | Train Loss: 0.1906 | Train F1: 0.4350 | Val Loss: 0.2409 | Val F1: 0.2948\n",
      " Trial 5 | Epoch 9/10 | Train Loss: 0.1859 | Train F1: 0.4663 | Val Loss: 0.2333 | Val F1: 0.3352\n",
      " Trial 5 | Epoch 10/10 | Train Loss: 0.1812 | Train F1: 0.4630 | Val Loss: 0.2371 | Val F1: 0.3439\n",
      "[I 2025-12-13 12:29:43,636] Trial 5 finished with value: 0.3438856748924979 and parameters: {'lr': 0.00036414738668149937, 'batch_size': 64, 'optimizer': 'AdamW', 'l2_reg': 0.0003699972431463808, 'dropout_rate': 0.3855082036717099, 'head_type': 'mlp_1_layer', 'head_hidden_dim': 512, 'loss_config': 'focal_g5_weighted', 'w1': 0.6448757264568841, 'w2': 0.5806106436270022, 'w3': 0.9648488261712865, 'w4': 1.4040601897822085}. Best is trial 0 with value: 0.40124035760828214.\n",
      " Trial 6 | Epoch 1/10 | Train Loss: 1.3188 | Train F1: 0.2314 | Val Loss: 1.3322 | Val F1: 0.1775\n",
      " Trial 6 | Epoch 2/10 | Train Loss: 1.2570 | Train F1: 0.2794 | Val Loss: 1.3076 | Val F1: 0.2855\n",
      " Trial 6 | Epoch 3/10 | Train Loss: 1.2057 | Train F1: 0.3340 | Val Loss: 1.2935 | Val F1: 0.2701\n",
      " Trial 6 | Epoch 4/10 | Train Loss: 1.1761 | Train F1: 0.3667 | Val Loss: 1.3010 | Val F1: 0.2803\n",
      " Trial 6 | Epoch 5/10 | Train Loss: 1.1632 | Train F1: 0.4131 | Val Loss: 1.2940 | Val F1: 0.3014\n",
      " Trial 6 | Epoch 6/10 | Train Loss: 1.1287 | Train F1: 0.4388 | Val Loss: 1.3009 | Val F1: 0.3219\n",
      " Trial 6 | Epoch 7/10 | Train Loss: 1.1010 | Train F1: 0.4757 | Val Loss: 1.3157 | Val F1: 0.3172\n",
      " Trial 6 | Epoch 8/10 | Train Loss: 1.0926 | Train F1: 0.4810 | Val Loss: 1.3406 | Val F1: 0.2998\n",
      " Trial 6 | Epoch 9/10 | Train Loss: 1.0739 | Train F1: 0.5037 | Val Loss: 1.3213 | Val F1: 0.3449\n",
      " Trial 6 | Epoch 10/10 | Train Loss: 1.0689 | Train F1: 0.5167 | Val Loss: 1.2995 | Val F1: 0.3704\n",
      "[I 2025-12-13 12:30:20,903] Trial 6 finished with value: 0.37037836240201083 and parameters: {'lr': 0.00042993594547314416, 'batch_size': 64, 'optimizer': 'AdamW', 'l2_reg': 3.6283583803549155e-05, 'dropout_rate': 0.47851179969799557, 'head_type': 'original', 'head_hidden_dim': 512, 'loss_config': 'ce_plain'}. Best is trial 0 with value: 0.40124035760828214.\n",
      " Trial 7 | Epoch 1/10 | Train Loss: 1.3889 | Train F1: 0.1318 | Val Loss: 1.3863 | Val F1: 0.0985\n",
      " Trial 7 | Epoch 2/10 | Train Loss: 1.3742 | Train F1: 0.1527 | Val Loss: 1.3738 | Val F1: 0.1647\n",
      " Trial 7 | Epoch 3/10 | Train Loss: 1.3543 | Train F1: 0.1728 | Val Loss: 1.3603 | Val F1: 0.1334\n",
      " Trial 7 | Epoch 4/10 | Train Loss: 1.3363 | Train F1: 0.1291 | Val Loss: 1.3524 | Val F1: 0.1337\n",
      "Trial 7 Pruned at Epoch 4\n",
      "[I 2025-12-13 12:30:36,015] Trial 7 pruned. \n",
      " Trial 8 | Epoch 1/10 | Train Loss: 0.2424 | Train F1: 0.1945 | Val Loss: 0.2445 | Val F1: 0.2127\n",
      " Trial 8 | Epoch 2/10 | Train Loss: 0.2351 | Train F1: 0.2071 | Val Loss: 0.2424 | Val F1: 0.1081\n",
      " Trial 8 | Epoch 3/10 | Train Loss: 0.2284 | Train F1: 0.1291 | Val Loss: 0.2425 | Val F1: 0.1227\n",
      " Trial 8 | Epoch 4/10 | Train Loss: 0.2235 | Train F1: 0.1913 | Val Loss: 0.2423 | Val F1: 0.1699\n",
      "Trial 8 Pruned at Epoch 4\n",
      "[I 2025-12-13 12:30:51,879] Trial 8 pruned. \n",
      " Trial 9 | Epoch 1/10 | Train Loss: 1.3089 | Train F1: 0.2267 | Val Loss: 1.3318 | Val F1: 0.2404\n",
      " Trial 9 | Epoch 2/10 | Train Loss: 1.2453 | Train F1: 0.2813 | Val Loss: 1.3188 | Val F1: 0.2835\n",
      " Trial 9 | Epoch 3/10 | Train Loss: 1.1997 | Train F1: 0.3388 | Val Loss: 1.3005 | Val F1: 0.2731\n",
      " Trial 9 | Epoch 4/10 | Train Loss: 1.1691 | Train F1: 0.3685 | Val Loss: 1.2795 | Val F1: 0.3113\n",
      " Trial 9 | Epoch 5/10 | Train Loss: 1.1386 | Train F1: 0.4060 | Val Loss: 1.2658 | Val F1: 0.3398\n",
      " Trial 9 | Epoch 6/10 | Train Loss: 1.1281 | Train F1: 0.4323 | Val Loss: 1.2587 | Val F1: 0.3788\n",
      " Trial 9 | Epoch 7/10 | Train Loss: 1.1086 | Train F1: 0.4588 | Val Loss: 1.2771 | Val F1: 0.3736\n",
      " Trial 9 | Epoch 8/10 | Train Loss: 1.0807 | Train F1: 0.5041 | Val Loss: 1.2640 | Val F1: 0.3735\n",
      " Trial 9 | Epoch 9/10 | Train Loss: 1.0663 | Train F1: 0.4984 | Val Loss: 1.3222 | Val F1: 0.3260\n",
      " Trial 9 | Epoch 10/10 | Train Loss: 1.0861 | Train F1: 0.4997 | Val Loss: 1.2824 | Val F1: 0.3817\n",
      "[I 2025-12-13 12:31:30,539] Trial 9 finished with value: 0.3816731357485135 and parameters: {'lr': 0.0003898458749305196, 'batch_size': 64, 'optimizer': 'AdamW', 'l2_reg': 0.0003437788661779579, 'dropout_rate': 0.3452991550395876, 'head_type': 'original', 'head_hidden_dim': 1024, 'loss_config': 'ce_plain'}. Best is trial 0 with value: 0.40124035760828214.\n",
      " Trial 10 | Epoch 1/10 | Train Loss: 0.5888 | Train F1: 0.1842 | Val Loss: 0.6272 | Val F1: 0.1972\n",
      " Trial 10 | Epoch 2/10 | Train Loss: 0.5610 | Train F1: 0.2458 | Val Loss: 0.5945 | Val F1: 0.2009\n",
      " Trial 10 | Epoch 3/10 | Train Loss: 0.5309 | Train F1: 0.2914 | Val Loss: 0.5948 | Val F1: 0.2253\n",
      " Trial 10 | Epoch 4/10 | Train Loss: 0.5170 | Train F1: 0.3451 | Val Loss: 0.5876 | Val F1: 0.2680\n",
      "Trial 10 Pruned at Epoch 4\n",
      "[I 2025-12-13 12:31:46,015] Trial 10 pruned. \n",
      " Trial 11 | Epoch 1/10 | Train Loss: 1.3808 | Train F1: 0.1507 | Val Loss: 1.3936 | Val F1: 0.2095\n",
      " Trial 11 | Epoch 2/10 | Train Loss: 1.3433 | Train F1: 0.2523 | Val Loss: 1.3594 | Val F1: 0.2790\n",
      " Trial 11 | Epoch 3/10 | Train Loss: 1.3029 | Train F1: 0.3524 | Val Loss: 1.3521 | Val F1: 0.3261\n",
      " Trial 11 | Epoch 4/10 | Train Loss: 1.2833 | Train F1: 0.3961 | Val Loss: 1.3470 | Val F1: 0.3443\n",
      " Trial 11 | Epoch 5/10 | Train Loss: 1.2561 | Train F1: 0.4408 | Val Loss: 1.3302 | Val F1: 0.3710\n",
      " Trial 11 | Epoch 6/10 | Train Loss: 1.2438 | Train F1: 0.4600 | Val Loss: 1.3386 | Val F1: 0.3714\n",
      " Trial 11 | Epoch 7/10 | Train Loss: 1.2275 | Train F1: 0.4725 | Val Loss: 1.3326 | Val F1: 0.3913\n",
      " Trial 11 | Epoch 8/10 | Train Loss: 1.2127 | Train F1: 0.4842 | Val Loss: 1.3403 | Val F1: 0.3934\n",
      " Trial 11 | Epoch 9/10 | Train Loss: 1.2016 | Train F1: 0.4976 | Val Loss: 1.3481 | Val F1: 0.3913\n",
      " Trial 11 | Epoch 10/10 | Train Loss: 1.1841 | Train F1: 0.5095 | Val Loss: 1.3321 | Val F1: 0.3581\n",
      "[I 2025-12-13 12:32:25,158] Trial 11 finished with value: 0.3934442454633423 and parameters: {'lr': 0.00025222634530777617, 'batch_size': 64, 'optimizer': 'AdamW', 'l2_reg': 0.0012550562475506077, 'dropout_rate': 0.3339786557616442, 'head_type': 'original', 'head_hidden_dim': 1024, 'loss_config': 'ce_weighted_smooth', 'w1': 0.7142007482935182, 'w2': 0.7549028507040043, 'w3': 0.7137566656216701, 'w4': 1.263889446515016}. Best is trial 0 with value: 0.40124035760828214.\n",
      " Trial 12 | Epoch 1/10 | Train Loss: 1.3815 | Train F1: 0.2106 | Val Loss: 1.3944 | Val F1: 0.1370\n",
      " Trial 12 | Epoch 2/10 | Train Loss: 1.3468 | Train F1: 0.2424 | Val Loss: 1.3635 | Val F1: 0.2445\n",
      " Trial 12 | Epoch 3/10 | Train Loss: 1.3093 | Train F1: 0.3232 | Val Loss: 1.3528 | Val F1: 0.2909\n",
      " Trial 12 | Epoch 4/10 | Train Loss: 1.2893 | Train F1: 0.4142 | Val Loss: 1.3395 | Val F1: 0.3472\n",
      " Trial 12 | Epoch 5/10 | Train Loss: 1.2655 | Train F1: 0.4306 | Val Loss: 1.3376 | Val F1: 0.3792\n",
      " Trial 12 | Epoch 6/10 | Train Loss: 1.2410 | Train F1: 0.4511 | Val Loss: 1.3401 | Val F1: 0.3659\n",
      " Trial 12 | Epoch 7/10 | Train Loss: 1.2198 | Train F1: 0.4801 | Val Loss: 1.3389 | Val F1: 0.3756\n",
      " Trial 12 | Epoch 8/10 | Train Loss: 1.2172 | Train F1: 0.4827 | Val Loss: 1.3294 | Val F1: 0.3741\n",
      " Trial 12 | Epoch 9/10 | Train Loss: 1.2137 | Train F1: 0.4785 | Val Loss: 1.3650 | Val F1: 0.3734\n",
      " Trial 12 | Epoch 10/10 | Train Loss: 1.1848 | Train F1: 0.5133 | Val Loss: 1.3384 | Val F1: 0.3905\n",
      "[I 2025-12-13 12:33:05,259] Trial 12 finished with value: 0.3904884389007476 and parameters: {'lr': 0.00023310948705755852, 'batch_size': 64, 'optimizer': 'AdamW', 'l2_reg': 0.0013477429954315207, 'dropout_rate': 0.30671717698689444, 'head_type': 'original', 'head_hidden_dim': 1024, 'loss_config': 'ce_weighted_smooth', 'w1': 0.7159385181728962, 'w2': 0.7340027538893085, 'w3': 0.7146815040890725, 'w4': 1.2532665572573536}. Best is trial 0 with value: 0.40124035760828214.\n",
      " Trial 13 | Epoch 1/10 | Train Loss: 1.3800 | Train F1: 0.1830 | Val Loss: 1.3895 | Val F1: 0.1665\n",
      " Trial 13 | Epoch 2/10 | Train Loss: 1.3455 | Train F1: 0.2585 | Val Loss: 1.3649 | Val F1: 0.2874\n",
      " Trial 13 | Epoch 3/10 | Train Loss: 1.3054 | Train F1: 0.3308 | Val Loss: 1.3532 | Val F1: 0.2943\n",
      " Trial 13 | Epoch 4/10 | Train Loss: 1.2810 | Train F1: 0.3897 | Val Loss: 1.3494 | Val F1: 0.3248\n",
      " Trial 13 | Epoch 5/10 | Train Loss: 1.2813 | Train F1: 0.4139 | Val Loss: 1.3355 | Val F1: 0.3724\n",
      " Trial 13 | Epoch 6/10 | Train Loss: 1.2536 | Train F1: 0.4483 | Val Loss: 1.3421 | Val F1: 0.3758\n",
      " Trial 13 | Epoch 7/10 | Train Loss: 1.2377 | Train F1: 0.4520 | Val Loss: 1.3295 | Val F1: 0.3723\n",
      " Trial 13 | Epoch 8/10 | Train Loss: 1.2174 | Train F1: 0.4754 | Val Loss: 1.3466 | Val F1: 0.3504\n",
      " Trial 13 | Epoch 9/10 | Train Loss: 1.2088 | Train F1: 0.4942 | Val Loss: 1.3325 | Val F1: 0.3681\n",
      " Trial 13 | Epoch 10/10 | Train Loss: 1.2026 | Train F1: 0.5107 | Val Loss: 1.3532 | Val F1: 0.3538\n",
      "[I 2025-12-13 12:33:45,252] Trial 13 finished with value: 0.37583884906731146 and parameters: {'lr': 0.00024373868874985252, 'batch_size': 64, 'optimizer': 'AdamW', 'l2_reg': 0.0012738288106627985, 'dropout_rate': 0.4092100414323442, 'head_type': 'original', 'head_hidden_dim': 1024, 'loss_config': 'ce_weighted_smooth', 'w1': 0.7626696154846466, 'w2': 0.7391685708265656, 'w3': 0.726752985693656, 'w4': 1.2718677337816662}. Best is trial 0 with value: 0.40124035760828214.\n",
      " Trial 14 | Epoch 1/10 | Train Loss: 1.4114 | Train F1: 0.2459 | Val Loss: 1.3962 | Val F1: 0.2002\n",
      " Trial 14 | Epoch 2/10 | Train Loss: 1.3874 | Train F1: 0.2816 | Val Loss: 1.3740 | Val F1: 0.2806\n",
      " Trial 14 | Epoch 3/10 | Train Loss: 1.3530 | Train F1: 0.3688 | Val Loss: 1.3562 | Val F1: 0.3500\n",
      " Trial 14 | Epoch 4/10 | Train Loss: 1.3253 | Train F1: 0.3998 | Val Loss: 1.3415 | Val F1: 0.3463\n",
      " Trial 14 | Epoch 5/10 | Train Loss: 1.3076 | Train F1: 0.4208 | Val Loss: 1.3426 | Val F1: 0.3276\n",
      " Trial 14 | Epoch 6/10 | Train Loss: 1.2847 | Train F1: 0.4318 | Val Loss: 1.3307 | Val F1: 0.3471\n",
      " Trial 14 | Epoch 7/10 | Train Loss: 1.2678 | Train F1: 0.4436 | Val Loss: 1.3579 | Val F1: 0.3220\n",
      " Trial 14 | Epoch 8/10 | Train Loss: 1.2613 | Train F1: 0.4485 | Val Loss: 1.3453 | Val F1: 0.3485\n",
      " Trial 14 | Epoch 9/10 | Train Loss: 1.2461 | Train F1: 0.4853 | Val Loss: 1.3234 | Val F1: 0.3307\n",
      " Trial 14 | Epoch 10/10 | Train Loss: 1.2341 | Train F1: 0.4694 | Val Loss: 1.3241 | Val F1: 0.3530\n",
      "Trial 14 Pruned at Epoch 10\n",
      "[I 2025-12-13 12:34:29,346] Trial 14 pruned. \n",
      " Trial 15 | Epoch 1/10 | Train Loss: 0.2659 | Train F1: 0.1849 | Val Loss: 0.2827 | Val F1: 0.1745\n",
      " Trial 15 | Epoch 2/10 | Train Loss: 0.2544 | Train F1: 0.1673 | Val Loss: 0.2802 | Val F1: 0.2402\n",
      " Trial 15 | Epoch 3/10 | Train Loss: 0.2495 | Train F1: 0.3455 | Val Loss: 0.2749 | Val F1: 0.2385\n",
      " Trial 15 | Epoch 4/10 | Train Loss: 0.2446 | Train F1: 0.2920 | Val Loss: 0.2739 | Val F1: 0.2665\n",
      "Trial 15 Pruned at Epoch 4\n",
      "[I 2025-12-13 12:34:47,009] Trial 15 pruned. \n",
      " Trial 16 | Epoch 1/10 | Train Loss: 1.3626 | Train F1: 0.1163 | Val Loss: 1.3828 | Val F1: 0.0985\n",
      " Trial 16 | Epoch 2/10 | Train Loss: 1.3287 | Train F1: 0.1570 | Val Loss: 1.3651 | Val F1: 0.1730\n",
      " Trial 16 | Epoch 3/10 | Train Loss: 1.2925 | Train F1: 0.2726 | Val Loss: 1.3520 | Val F1: 0.2303\n",
      " Trial 16 | Epoch 4/10 | Train Loss: 1.2613 | Train F1: 0.3137 | Val Loss: 1.3307 | Val F1: 0.2542\n",
      "Trial 16 Pruned at Epoch 4\n",
      "[I 2025-12-13 12:35:04,820] Trial 16 pruned. \n",
      " Trial 17 | Epoch 1/10 | Train Loss: 0.5988 | Train F1: 0.1880 | Val Loss: 0.6387 | Val F1: 0.2048\n",
      " Trial 17 | Epoch 2/10 | Train Loss: 0.5669 | Train F1: 0.2293 | Val Loss: 0.6196 | Val F1: 0.2193\n",
      " Trial 17 | Epoch 3/10 | Train Loss: 0.5398 | Train F1: 0.2969 | Val Loss: 0.6031 | Val F1: 0.2686\n",
      " Trial 17 | Epoch 4/10 | Train Loss: 0.5232 | Train F1: 0.3774 | Val Loss: 0.5890 | Val F1: 0.3425\n",
      " Trial 17 | Epoch 5/10 | Train Loss: 0.5047 | Train F1: 0.4091 | Val Loss: 0.5803 | Val F1: 0.3476\n",
      " Trial 17 | Epoch 6/10 | Train Loss: 0.4891 | Train F1: 0.4391 | Val Loss: 0.5914 | Val F1: 0.3748\n",
      " Trial 17 | Epoch 7/10 | Train Loss: 0.4819 | Train F1: 0.4519 | Val Loss: 0.5886 | Val F1: 0.3774\n",
      " Trial 17 | Epoch 8/10 | Train Loss: 0.4642 | Train F1: 0.4871 | Val Loss: 0.5756 | Val F1: 0.3799\n",
      " Trial 17 | Epoch 9/10 | Train Loss: 0.4581 | Train F1: 0.4838 | Val Loss: 0.5813 | Val F1: 0.3962\n",
      " Trial 17 | Epoch 10/10 | Train Loss: 0.4535 | Train F1: 0.5024 | Val Loss: 0.5677 | Val F1: 0.3708\n",
      "[I 2025-12-13 12:35:48,565] Trial 17 finished with value: 0.3962182085751677 and parameters: {'lr': 0.00029656683009624115, 'batch_size': 64, 'optimizer': 'AdamW', 'l2_reg': 0.0006123606233275672, 'dropout_rate': 0.434633811628221, 'head_type': 'original', 'head_hidden_dim': 1024, 'loss_config': 'focal_g2_weighted', 'w1': 0.6715160797353724, 'w2': 0.8096541667564223, 'w3': 0.8423877967059843, 'w4': 1.1363270683904247}. Best is trial 0 with value: 0.40124035760828214.\n",
      " Trial 18 | Epoch 1/10 | Train Loss: 0.6011 | Train F1: 0.2107 | Val Loss: 0.6295 | Val F1: 0.2215\n",
      " Trial 18 | Epoch 2/10 | Train Loss: 0.5567 | Train F1: 0.2490 | Val Loss: 0.6225 | Val F1: 0.2119\n",
      " Trial 18 | Epoch 3/10 | Train Loss: 0.5385 | Train F1: 0.2972 | Val Loss: 0.6168 | Val F1: 0.2550\n",
      " Trial 18 | Epoch 4/10 | Train Loss: 0.5280 | Train F1: 0.3597 | Val Loss: 0.6170 | Val F1: 0.2448\n",
      "Trial 18 Pruned at Epoch 4\n",
      "[I 2025-12-13 12:36:06,197] Trial 18 pruned. \n",
      " Trial 19 | Epoch 1/10 | Train Loss: 0.6284 | Train F1: 0.1495 | Val Loss: 0.6471 | Val F1: 0.1337\n",
      " Trial 19 | Epoch 2/10 | Train Loss: 0.6024 | Train F1: 0.1617 | Val Loss: 0.6488 | Val F1: 0.1900\n",
      " Trial 19 | Epoch 3/10 | Train Loss: 0.5920 | Train F1: 0.2250 | Val Loss: 0.6446 | Val F1: 0.2388\n",
      " Trial 19 | Epoch 4/10 | Train Loss: 0.5850 | Train F1: 0.3270 | Val Loss: 0.6419 | Val F1: 0.2751\n",
      "Trial 19 Pruned at Epoch 4\n",
      "[I 2025-12-13 12:36:23,910] Trial 19 pruned. \n",
      " Trial 20 | Epoch 1/10 | Train Loss: 1.3129 | Train F1: 0.2424 | Val Loss: 1.3498 | Val F1: 0.2720\n",
      " Trial 20 | Epoch 2/10 | Train Loss: 1.2470 | Train F1: 0.3295 | Val Loss: 1.3197 | Val F1: 0.2900\n",
      " Trial 20 | Epoch 3/10 | Train Loss: 1.2255 | Train F1: 0.3820 | Val Loss: 1.3040 | Val F1: 0.3062\n",
      " Trial 20 | Epoch 4/10 | Train Loss: 1.1899 | Train F1: 0.4453 | Val Loss: 1.3146 | Val F1: 0.3524\n",
      " Trial 20 | Epoch 5/10 | Train Loss: 1.1828 | Train F1: 0.4603 | Val Loss: 1.3143 | Val F1: 0.3610\n",
      " Trial 20 | Epoch 6/10 | Train Loss: 1.1591 | Train F1: 0.4718 | Val Loss: 1.3195 | Val F1: 0.3491\n",
      " Trial 20 | Epoch 7/10 | Train Loss: 1.1591 | Train F1: 0.4747 | Val Loss: 1.3448 | Val F1: 0.3510\n",
      " Trial 20 | Epoch 8/10 | Train Loss: 1.1419 | Train F1: 0.4941 | Val Loss: 1.3340 | Val F1: 0.3533\n",
      " Trial 20 | Epoch 9/10 | Train Loss: 1.1277 | Train F1: 0.5148 | Val Loss: 1.3595 | Val F1: 0.3342\n",
      " Trial 20 | Epoch 10/10 | Train Loss: 1.1153 | Train F1: 0.5307 | Val Loss: 1.2942 | Val F1: 0.4273\n",
      "[I 2025-12-13 12:37:03,124] Trial 20 finished with value: 0.42733525497261327 and parameters: {'lr': 0.0009663298837650214, 'batch_size': 64, 'optimizer': 'AdamW', 'l2_reg': 0.0006185789536353959, 'dropout_rate': 0.49420036841332404, 'head_type': 'original', 'head_hidden_dim': 1024, 'loss_config': 'ce_smooth_0.1'}. Best is trial 20 with value: 0.42733525497261327.\n",
      " Trial 21 | Epoch 1/10 | Train Loss: 1.3407 | Train F1: 0.1355 | Val Loss: 1.3540 | Val F1: 0.1337\n",
      " Trial 21 | Epoch 2/10 | Train Loss: 1.3057 | Train F1: 0.1927 | Val Loss: 1.3373 | Val F1: 0.2757\n",
      " Trial 21 | Epoch 3/10 | Train Loss: 1.2782 | Train F1: 0.3014 | Val Loss: 1.3257 | Val F1: 0.2770\n",
      " Trial 21 | Epoch 4/10 | Train Loss: 1.2511 | Train F1: 0.3377 | Val Loss: 1.3197 | Val F1: 0.2827\n",
      "Trial 21 Pruned at Epoch 4\n",
      "[I 2025-12-13 12:37:18,968] Trial 21 pruned. \n",
      " Trial 22 | Epoch 1/10 | Train Loss: 1.3143 | Train F1: 0.2572 | Val Loss: 1.3208 | Val F1: 0.2267\n",
      " Trial 22 | Epoch 2/10 | Train Loss: 1.2503 | Train F1: 0.3226 | Val Loss: 1.3173 | Val F1: 0.2890\n",
      " Trial 22 | Epoch 3/10 | Train Loss: 1.2141 | Train F1: 0.3995 | Val Loss: 1.3129 | Val F1: 0.3665\n",
      " Trial 22 | Epoch 4/10 | Train Loss: 1.1980 | Train F1: 0.4560 | Val Loss: 1.3057 | Val F1: 0.3602\n",
      " Trial 22 | Epoch 5/10 | Train Loss: 1.1803 | Train F1: 0.4518 | Val Loss: 1.3148 | Val F1: 0.3479\n",
      " Trial 22 | Epoch 6/10 | Train Loss: 1.1507 | Train F1: 0.5030 | Val Loss: 1.3056 | Val F1: 0.3848\n",
      " Trial 22 | Epoch 7/10 | Train Loss: 1.1379 | Train F1: 0.5186 | Val Loss: 1.3507 | Val F1: 0.3422\n",
      " Trial 22 | Epoch 8/10 | Train Loss: 1.1234 | Train F1: 0.5259 | Val Loss: 1.3298 | Val F1: 0.3656\n",
      " Trial 22 | Epoch 9/10 | Train Loss: 1.1220 | Train F1: 0.5265 | Val Loss: 1.2858 | Val F1: 0.4301\n",
      " Trial 22 | Epoch 10/10 | Train Loss: 1.1025 | Train F1: 0.5417 | Val Loss: 1.3203 | Val F1: 0.3924\n",
      "[I 2025-12-13 12:37:57,872] Trial 22 finished with value: 0.43010175589593114 and parameters: {'lr': 0.0009064376191781115, 'batch_size': 64, 'optimizer': 'AdamW', 'l2_reg': 0.00013995835693670367, 'dropout_rate': 0.44285376432559154, 'head_type': 'original', 'head_hidden_dim': 1024, 'loss_config': 'ce_smooth_0.1'}. Best is trial 22 with value: 0.43010175589593114.\n",
      " Trial 23 | Epoch 1/10 | Train Loss: 1.3115 | Train F1: 0.2393 | Val Loss: 1.3305 | Val F1: 0.2473\n",
      " Trial 23 | Epoch 2/10 | Train Loss: 1.2508 | Train F1: 0.3314 | Val Loss: 1.3241 | Val F1: 0.3082\n",
      " Trial 23 | Epoch 3/10 | Train Loss: 1.2275 | Train F1: 0.3805 | Val Loss: 1.3283 | Val F1: 0.3166\n",
      " Trial 23 | Epoch 4/10 | Train Loss: 1.2007 | Train F1: 0.4286 | Val Loss: 1.3285 | Val F1: 0.3341\n",
      " Trial 23 | Epoch 5/10 | Train Loss: 1.1868 | Train F1: 0.4543 | Val Loss: 1.2930 | Val F1: 0.3624\n",
      " Trial 23 | Epoch 6/10 | Train Loss: 1.1614 | Train F1: 0.4936 | Val Loss: 1.3203 | Val F1: 0.3614\n",
      " Trial 23 | Epoch 7/10 | Train Loss: 1.1440 | Train F1: 0.4918 | Val Loss: 1.3286 | Val F1: 0.3860\n",
      " Trial 23 | Epoch 8/10 | Train Loss: 1.1401 | Train F1: 0.5111 | Val Loss: 1.3347 | Val F1: 0.3749\n",
      " Trial 23 | Epoch 9/10 | Train Loss: 1.1364 | Train F1: 0.5055 | Val Loss: 1.3139 | Val F1: 0.4153\n",
      " Trial 23 | Epoch 10/10 | Train Loss: 1.1169 | Train F1: 0.5320 | Val Loss: 1.3530 | Val F1: 0.3730\n",
      "[I 2025-12-13 12:38:36,851] Trial 23 finished with value: 0.41527063937456604 and parameters: {'lr': 0.0009703041432704931, 'batch_size': 64, 'optimizer': 'AdamW', 'l2_reg': 0.000147834880628853, 'dropout_rate': 0.493976956961806, 'head_type': 'original', 'head_hidden_dim': 1024, 'loss_config': 'ce_smooth_0.1'}. Best is trial 22 with value: 0.43010175589593114.\n",
      " Trial 24 | Epoch 1/10 | Train Loss: 1.3188 | Train F1: 0.2285 | Val Loss: 1.3295 | Val F1: 0.2593\n",
      " Trial 24 | Epoch 2/10 | Train Loss: 1.2687 | Train F1: 0.3131 | Val Loss: 1.3100 | Val F1: 0.2738\n",
      " Trial 24 | Epoch 3/10 | Train Loss: 1.2218 | Train F1: 0.3808 | Val Loss: 1.3243 | Val F1: 0.2787\n",
      " Trial 24 | Epoch 4/10 | Train Loss: 1.1938 | Train F1: 0.4253 | Val Loss: 1.3244 | Val F1: 0.3168\n",
      "Trial 24 Pruned at Epoch 4\n",
      "[I 2025-12-13 12:38:52,393] Trial 24 pruned. \n",
      " Trial 25 | Epoch 1/10 | Train Loss: 1.3102 | Train F1: 0.2031 | Val Loss: 1.3338 | Val F1: 0.2173\n",
      " Trial 25 | Epoch 2/10 | Train Loss: 1.2559 | Train F1: 0.3268 | Val Loss: 1.3270 | Val F1: 0.2764\n",
      " Trial 25 | Epoch 3/10 | Train Loss: 1.2156 | Train F1: 0.3651 | Val Loss: 1.3024 | Val F1: 0.3727\n",
      " Trial 25 | Epoch 4/10 | Train Loss: 1.1923 | Train F1: 0.4490 | Val Loss: 1.3434 | Val F1: 0.2833\n",
      " Trial 25 | Epoch 5/10 | Train Loss: 1.1871 | Train F1: 0.4434 | Val Loss: 1.3216 | Val F1: 0.3088\n",
      " Trial 25 | Epoch 6/10 | Train Loss: 1.1607 | Train F1: 0.4871 | Val Loss: 1.2947 | Val F1: 0.3782\n",
      " Trial 25 | Epoch 7/10 | Train Loss: 1.1554 | Train F1: 0.5046 | Val Loss: 1.3092 | Val F1: 0.3821\n",
      " Trial 25 | Epoch 8/10 | Train Loss: 1.1502 | Train F1: 0.4946 | Val Loss: 1.3044 | Val F1: 0.3801\n",
      " Trial 25 | Epoch 9/10 | Train Loss: 1.1079 | Train F1: 0.5258 | Val Loss: 1.3269 | Val F1: 0.3435\n",
      " Trial 25 | Epoch 10/10 | Train Loss: 1.1198 | Train F1: 0.5213 | Val Loss: 1.3120 | Val F1: 0.3860\n",
      "[I 2025-12-13 12:39:30,713] Trial 25 finished with value: 0.38604365741796914 and parameters: {'lr': 0.0007671705261005499, 'batch_size': 64, 'optimizer': 'AdamW', 'l2_reg': 5.9728019898772254e-05, 'dropout_rate': 0.4620380825735033, 'head_type': 'original', 'head_hidden_dim': 1024, 'loss_config': 'ce_smooth_0.1'}. Best is trial 22 with value: 0.43010175589593114.\n",
      " Trial 26 | Epoch 1/10 | Train Loss: 1.3751 | Train F1: 0.1923 | Val Loss: 1.3591 | Val F1: 0.1337\n",
      " Trial 26 | Epoch 2/10 | Train Loss: 1.3262 | Train F1: 0.1454 | Val Loss: 1.3510 | Val F1: 0.1337\n",
      " Trial 26 | Epoch 3/10 | Train Loss: 1.2994 | Train F1: 0.2361 | Val Loss: 1.3339 | Val F1: 0.1880\n",
      " Trial 26 | Epoch 4/10 | Train Loss: 1.2712 | Train F1: 0.3005 | Val Loss: 1.3151 | Val F1: 0.2463\n",
      "Trial 26 Pruned at Epoch 4\n",
      "[I 2025-12-13 12:39:46,431] Trial 26 pruned. \n",
      " Trial 27 | Epoch 1/10 | Train Loss: 1.3210 | Train F1: 0.2171 | Val Loss: 1.3280 | Val F1: 0.1768\n",
      " Trial 27 | Epoch 2/10 | Train Loss: 1.2606 | Train F1: 0.3304 | Val Loss: 1.3143 | Val F1: 0.2939\n",
      " Trial 27 | Epoch 3/10 | Train Loss: 1.2271 | Train F1: 0.3508 | Val Loss: 1.3201 | Val F1: 0.3011\n",
      " Trial 27 | Epoch 4/10 | Train Loss: 1.2136 | Train F1: 0.4088 | Val Loss: 1.2984 | Val F1: 0.3478\n",
      " Trial 27 | Epoch 5/10 | Train Loss: 1.1873 | Train F1: 0.4352 | Val Loss: 1.3527 | Val F1: 0.2734\n",
      " Trial 27 | Epoch 6/10 | Train Loss: 1.1588 | Train F1: 0.4677 | Val Loss: 1.3085 | Val F1: 0.3455\n",
      "Trial 27 Pruned at Epoch 6\n",
      "[I 2025-12-13 12:40:09,658] Trial 27 pruned. \n",
      " Trial 28 | Epoch 1/10 | Train Loss: 1.3312 | Train F1: 0.1502 | Val Loss: 1.3496 | Val F1: 0.1398\n",
      " Trial 28 | Epoch 2/10 | Train Loss: 1.2957 | Train F1: 0.1833 | Val Loss: 1.3404 | Val F1: 0.1908\n",
      " Trial 28 | Epoch 3/10 | Train Loss: 1.2807 | Train F1: 0.2634 | Val Loss: 1.3329 | Val F1: 0.2630\n",
      " Trial 28 | Epoch 4/10 | Train Loss: 1.2687 | Train F1: 0.3032 | Val Loss: 1.3260 | Val F1: 0.2787\n",
      "Trial 28 Pruned at Epoch 4\n",
      "[I 2025-12-13 12:40:25,345] Trial 28 pruned. \n",
      " Trial 29 | Epoch 1/10 | Train Loss: 1.2962 | Train F1: 0.2663 | Val Loss: 1.3308 | Val F1: 0.2880\n",
      " Trial 29 | Epoch 2/10 | Train Loss: 1.2315 | Train F1: 0.3542 | Val Loss: 1.3193 | Val F1: 0.2756\n",
      " Trial 29 | Epoch 3/10 | Train Loss: 1.2095 | Train F1: 0.3768 | Val Loss: 1.3163 | Val F1: 0.2583\n",
      " Trial 29 | Epoch 4/10 | Train Loss: 1.1939 | Train F1: 0.3976 | Val Loss: 1.3258 | Val F1: 0.2697\n",
      "Trial 29 Pruned at Epoch 4\n",
      "[I 2025-12-13 12:40:41,021] Trial 29 pruned. \n",
      " Trial 30 | Epoch 1/10 | Train Loss: 1.3275 | Train F1: 0.2382 | Val Loss: 1.3329 | Val F1: 0.2297\n",
      " Trial 30 | Epoch 2/10 | Train Loss: 1.2706 | Train F1: 0.3027 | Val Loss: 1.3218 | Val F1: 0.2885\n",
      " Trial 30 | Epoch 3/10 | Train Loss: 1.2395 | Train F1: 0.3376 | Val Loss: 1.3011 | Val F1: 0.2864\n",
      " Trial 30 | Epoch 4/10 | Train Loss: 1.2154 | Train F1: 0.3975 | Val Loss: 1.3065 | Val F1: 0.3157\n",
      "Trial 30 Pruned at Epoch 4\n",
      "[I 2025-12-13 12:40:56,539] Trial 30 pruned. \n",
      " Trial 31 | Epoch 1/10 | Train Loss: 0.2002 | Train F1: 0.3180 | Val Loss: 0.2110 | Val F1: 0.2547\n",
      " Trial 31 | Epoch 2/10 | Train Loss: 0.1849 | Train F1: 0.3467 | Val Loss: 0.2174 | Val F1: 0.3396\n",
      " Trial 31 | Epoch 3/10 | Train Loss: 0.1786 | Train F1: 0.3951 | Val Loss: 0.2303 | Val F1: 0.3564\n",
      " Trial 31 | Epoch 4/10 | Train Loss: 0.1685 | Train F1: 0.4242 | Val Loss: 0.2086 | Val F1: 0.3753\n",
      " Trial 31 | Epoch 5/10 | Train Loss: 0.1669 | Train F1: 0.4402 | Val Loss: 0.1956 | Val F1: 0.3563\n",
      " Trial 31 | Epoch 6/10 | Train Loss: 0.1568 | Train F1: 0.4635 | Val Loss: 0.2078 | Val F1: 0.3478\n",
      " Trial 31 | Epoch 7/10 | Train Loss: 0.1500 | Train F1: 0.4692 | Val Loss: 0.2246 | Val F1: 0.3649\n",
      " Trial 31 | Epoch 8/10 | Train Loss: 0.1470 | Train F1: 0.4808 | Val Loss: 0.2012 | Val F1: 0.3441\n",
      " Trial 31 | Epoch 9/10 | Train Loss: 0.1497 | Train F1: 0.4757 | Val Loss: 0.2060 | Val F1: 0.3296\n",
      " Trial 31 | Epoch 10/10 | Train Loss: 0.1468 | Train F1: 0.4843 | Val Loss: 0.2066 | Val F1: 0.3833\n",
      "[I 2025-12-13 12:41:34,864] Trial 31 finished with value: 0.3833417260835231 and parameters: {'lr': 0.000800346098388946, 'batch_size': 64, 'optimizer': 'AdamW', 'l2_reg': 0.00019137119404518988, 'dropout_rate': 0.4693102103606831, 'head_type': 'original', 'head_hidden_dim': 1024, 'loss_config': 'focal_g5_weighted', 'w1': 0.5417176108691886, 'w2': 0.6407176061020254, 'w3': 0.5004385644504841, 'w4': 1.4763551405686437}. Best is trial 22 with value: 0.43010175589593114.\n",
      " Trial 32 | Epoch 1/10 | Train Loss: 0.7044 | Train F1: 0.2592 | Val Loss: 0.7351 | Val F1: 0.2298\n",
      " Trial 32 | Epoch 2/10 | Train Loss: 0.6524 | Train F1: 0.3296 | Val Loss: 0.7064 | Val F1: 0.2825\n",
      " Trial 32 | Epoch 3/10 | Train Loss: 0.6080 | Train F1: 0.3924 | Val Loss: 0.6936 | Val F1: 0.3579\n",
      " Trial 32 | Epoch 4/10 | Train Loss: 0.5895 | Train F1: 0.4292 | Val Loss: 0.6874 | Val F1: 0.3737\n",
      " Trial 32 | Epoch 5/10 | Train Loss: 0.5741 | Train F1: 0.4572 | Val Loss: 0.6864 | Val F1: 0.3806\n",
      " Trial 32 | Epoch 6/10 | Train Loss: 0.5521 | Train F1: 0.4765 | Val Loss: 0.6889 | Val F1: 0.3867\n",
      " Trial 32 | Epoch 7/10 | Train Loss: 0.5551 | Train F1: 0.4881 | Val Loss: 0.7250 | Val F1: 0.3475\n",
      " Trial 32 | Epoch 8/10 | Train Loss: 0.5280 | Train F1: 0.5102 | Val Loss: 0.6932 | Val F1: 0.4141\n",
      " Trial 32 | Epoch 9/10 | Train Loss: 0.5205 | Train F1: 0.5119 | Val Loss: 0.6714 | Val F1: 0.4064\n",
      " Trial 32 | Epoch 10/10 | Train Loss: 0.5127 | Train F1: 0.5441 | Val Loss: 0.6696 | Val F1: 0.4157\n",
      "[I 2025-12-13 12:42:13,513] Trial 32 finished with value: 0.4156745248127839 and parameters: {'lr': 0.0006942889508657831, 'batch_size': 64, 'optimizer': 'AdamW', 'l2_reg': 0.00024373628248505638, 'dropout_rate': 0.4215442777061863, 'head_type': 'original', 'head_hidden_dim': 1024, 'loss_config': 'focal_g2_no_weight'}. Best is trial 22 with value: 0.43010175589593114.\n",
      " Trial 33 | Epoch 1/10 | Train Loss: 0.7046 | Train F1: 0.2362 | Val Loss: 0.7341 | Val F1: 0.2959\n",
      " Trial 33 | Epoch 2/10 | Train Loss: 0.6398 | Train F1: 0.3278 | Val Loss: 0.7182 | Val F1: 0.2582\n",
      " Trial 33 | Epoch 3/10 | Train Loss: 0.6123 | Train F1: 0.4044 | Val Loss: 0.7074 | Val F1: 0.3451\n",
      " Trial 33 | Epoch 4/10 | Train Loss: 0.5827 | Train F1: 0.4545 | Val Loss: 0.6958 | Val F1: 0.3627\n",
      " Trial 33 | Epoch 5/10 | Train Loss: 0.5609 | Train F1: 0.4737 | Val Loss: 0.6961 | Val F1: 0.3694\n",
      " Trial 33 | Epoch 6/10 | Train Loss: 0.5525 | Train F1: 0.4969 | Val Loss: 0.6961 | Val F1: 0.3892\n",
      " Trial 33 | Epoch 7/10 | Train Loss: 0.5439 | Train F1: 0.5023 | Val Loss: 0.7101 | Val F1: 0.3463\n",
      " Trial 33 | Epoch 8/10 | Train Loss: 0.5176 | Train F1: 0.5147 | Val Loss: 0.6839 | Val F1: 0.4152\n",
      " Trial 33 | Epoch 9/10 | Train Loss: 0.5286 | Train F1: 0.5200 | Val Loss: 0.7145 | Val F1: 0.3604\n",
      " Trial 33 | Epoch 10/10 | Train Loss: 0.5172 | Train F1: 0.5132 | Val Loss: 0.6842 | Val F1: 0.4281\n",
      "[I 2025-12-13 12:42:52,060] Trial 33 finished with value: 0.4281428015274605 and parameters: {'lr': 0.0007003405604370721, 'batch_size': 64, 'optimizer': 'AdamW', 'l2_reg': 8.81014913582204e-05, 'dropout_rate': 0.4027464363666293, 'head_type': 'original', 'head_hidden_dim': 1024, 'loss_config': 'focal_g2_no_weight'}. Best is trial 22 with value: 0.43010175589593114.\n",
      " Trial 34 | Epoch 1/10 | Train Loss: 0.7726 | Train F1: 0.2136 | Val Loss: 0.7629 | Val F1: 0.1818\n",
      " Trial 34 | Epoch 2/10 | Train Loss: 0.7236 | Train F1: 0.2083 | Val Loss: 0.7473 | Val F1: 0.1337\n",
      " Trial 34 | Epoch 3/10 | Train Loss: 0.6972 | Train F1: 0.1606 | Val Loss: 0.7443 | Val F1: 0.1528\n",
      " Trial 34 | Epoch 4/10 | Train Loss: 0.6761 | Train F1: 0.2440 | Val Loss: 0.7219 | Val F1: 0.2692\n",
      "Trial 34 Pruned at Epoch 4\n",
      "[I 2025-12-13 12:43:07,387] Trial 34 pruned. \n",
      " Trial 35 | Epoch 1/10 | Train Loss: 0.7047 | Train F1: 0.2499 | Val Loss: 0.7276 | Val F1: 0.2484\n",
      " Trial 35 | Epoch 2/10 | Train Loss: 0.6371 | Train F1: 0.3300 | Val Loss: 0.7079 | Val F1: 0.2630\n",
      " Trial 35 | Epoch 3/10 | Train Loss: 0.6143 | Train F1: 0.4058 | Val Loss: 0.7116 | Val F1: 0.2780\n",
      " Trial 35 | Epoch 4/10 | Train Loss: 0.5866 | Train F1: 0.4326 | Val Loss: 0.7400 | Val F1: 0.3048\n",
      "Trial 35 Pruned at Epoch 4\n",
      "[I 2025-12-13 12:43:22,892] Trial 35 pruned. \n",
      " Trial 36 | Epoch 1/10 | Train Loss: 0.7019 | Train F1: 0.2419 | Val Loss: 0.7462 | Val F1: 0.2316\n",
      " Trial 36 | Epoch 2/10 | Train Loss: 0.6388 | Train F1: 0.3273 | Val Loss: 0.7464 | Val F1: 0.2633\n",
      " Trial 36 | Epoch 3/10 | Train Loss: 0.6088 | Train F1: 0.4128 | Val Loss: 0.6851 | Val F1: 0.3634\n",
      " Trial 36 | Epoch 4/10 | Train Loss: 0.5733 | Train F1: 0.4679 | Val Loss: 0.7220 | Val F1: 0.2892\n",
      " Trial 36 | Epoch 5/10 | Train Loss: 0.5682 | Train F1: 0.4719 | Val Loss: 0.6825 | Val F1: 0.3883\n",
      " Trial 36 | Epoch 6/10 | Train Loss: 0.5540 | Train F1: 0.4964 | Val Loss: 0.7467 | Val F1: 0.3321\n",
      " Trial 36 | Epoch 7/10 | Train Loss: 0.5288 | Train F1: 0.5112 | Val Loss: 0.7158 | Val F1: 0.3539\n",
      " Trial 36 | Epoch 8/10 | Train Loss: 0.5210 | Train F1: 0.5267 | Val Loss: 0.6692 | Val F1: 0.3994\n",
      " Trial 36 | Epoch 9/10 | Train Loss: 0.5191 | Train F1: 0.5183 | Val Loss: 0.6775 | Val F1: 0.4135\n",
      " Trial 36 | Epoch 10/10 | Train Loss: 0.5007 | Train F1: 0.5348 | Val Loss: 0.6546 | Val F1: 0.4486\n",
      "[I 2025-12-13 12:44:01,165] Trial 36 finished with value: 0.44862375808471944 and parameters: {'lr': 0.0008367433034670895, 'batch_size': 64, 'optimizer': 'AdamW', 'l2_reg': 0.00023922618482545056, 'dropout_rate': 0.39563913357721187, 'head_type': 'original', 'head_hidden_dim': 1024, 'loss_config': 'focal_g2_no_weight'}. Best is trial 36 with value: 0.44862375808471944.\n",
      " Trial 37 | Epoch 1/10 | Train Loss: 0.7755 | Train F1: 0.1863 | Val Loss: 0.7642 | Val F1: 0.1580\n",
      " Trial 37 | Epoch 2/10 | Train Loss: 0.7425 | Train F1: 0.1407 | Val Loss: 0.7449 | Val F1: 0.1337\n",
      " Trial 37 | Epoch 3/10 | Train Loss: 0.7153 | Train F1: 0.1298 | Val Loss: 0.7377 | Val F1: 0.1370\n",
      " Trial 37 | Epoch 4/10 | Train Loss: 0.6993 | Train F1: 0.1327 | Val Loss: 0.7356 | Val F1: 0.1436\n",
      "Trial 37 Pruned at Epoch 4\n",
      "[I 2025-12-13 12:44:16,530] Trial 37 pruned. \n",
      " Trial 38 | Epoch 1/10 | Train Loss: 0.6912 | Train F1: 0.2758 | Val Loss: 0.7463 | Val F1: 0.2171\n",
      " Trial 38 | Epoch 2/10 | Train Loss: 0.6381 | Train F1: 0.3322 | Val Loss: 0.7069 | Val F1: 0.2881\n",
      " Trial 38 | Epoch 3/10 | Train Loss: 0.6014 | Train F1: 0.4099 | Val Loss: 0.6856 | Val F1: 0.3639\n",
      " Trial 38 | Epoch 4/10 | Train Loss: 0.5723 | Train F1: 0.4600 | Val Loss: 0.7175 | Val F1: 0.3317\n",
      " Trial 38 | Epoch 5/10 | Train Loss: 0.5524 | Train F1: 0.4881 | Val Loss: 0.7336 | Val F1: 0.3090\n",
      " Trial 38 | Epoch 6/10 | Train Loss: 0.5372 | Train F1: 0.4997 | Val Loss: 0.6956 | Val F1: 0.3703\n",
      " Trial 38 | Epoch 7/10 | Train Loss: 0.5349 | Train F1: 0.5357 | Val Loss: 0.7033 | Val F1: 0.4013\n",
      " Trial 38 | Epoch 8/10 | Train Loss: 0.5117 | Train F1: 0.5388 | Val Loss: 0.7290 | Val F1: 0.3675\n",
      " Trial 38 | Epoch 9/10 | Train Loss: 0.5072 | Train F1: 0.5349 | Val Loss: 0.6619 | Val F1: 0.4058\n",
      " Trial 38 | Epoch 10/10 | Train Loss: 0.5002 | Train F1: 0.5390 | Val Loss: 0.6780 | Val F1: 0.4068\n",
      "[I 2025-12-13 12:44:55,062] Trial 38 finished with value: 0.40683128700192456 and parameters: {'lr': 0.0008327700778548699, 'batch_size': 64, 'optimizer': 'AdamW', 'l2_reg': 0.0003966840679292991, 'dropout_rate': 0.3759924996562828, 'head_type': 'original', 'head_hidden_dim': 1024, 'loss_config': 'focal_g2_no_weight'}. Best is trial 36 with value: 0.44862375808471944.\n",
      " Trial 39 | Epoch 1/10 | Train Loss: 1.3819 | Train F1: 0.1868 | Val Loss: 1.3742 | Val F1: 0.1337\n",
      " Trial 39 | Epoch 2/10 | Train Loss: 1.3465 | Train F1: 0.1315 | Val Loss: 1.3623 | Val F1: 0.1337\n",
      " Trial 39 | Epoch 3/10 | Train Loss: 1.3197 | Train F1: 0.1436 | Val Loss: 1.3596 | Val F1: 0.1466\n",
      " Trial 39 | Epoch 4/10 | Train Loss: 1.2987 | Train F1: 0.2180 | Val Loss: 1.3484 | Val F1: 0.2498\n",
      "Trial 39 Pruned at Epoch 4\n",
      "[I 2025-12-13 12:45:10,446] Trial 39 pruned. \n",
      " Trial 40 | Epoch 1/10 | Train Loss: 0.7056 | Train F1: 0.2179 | Val Loss: 0.7279 | Val F1: 0.2533\n",
      " Trial 40 | Epoch 2/10 | Train Loss: 0.6436 | Train F1: 0.3172 | Val Loss: 0.7058 | Val F1: 0.2822\n",
      " Trial 40 | Epoch 3/10 | Train Loss: 0.6079 | Train F1: 0.3796 | Val Loss: 0.6989 | Val F1: 0.3243\n",
      " Trial 40 | Epoch 4/10 | Train Loss: 0.5928 | Train F1: 0.4052 | Val Loss: 0.6887 | Val F1: 0.3638\n",
      " Trial 40 | Epoch 5/10 | Train Loss: 0.5678 | Train F1: 0.4564 | Val Loss: 0.7036 | Val F1: 0.3430\n",
      " Trial 40 | Epoch 6/10 | Train Loss: 0.5599 | Train F1: 0.4731 | Val Loss: 0.6939 | Val F1: 0.3746\n",
      " Trial 40 | Epoch 7/10 | Train Loss: 0.5421 | Train F1: 0.4938 | Val Loss: 0.6971 | Val F1: 0.3779\n",
      " Trial 40 | Epoch 8/10 | Train Loss: 0.5381 | Train F1: 0.5169 | Val Loss: 0.7029 | Val F1: 0.3685\n",
      " Trial 40 | Epoch 9/10 | Train Loss: 0.5166 | Train F1: 0.5237 | Val Loss: 0.7248 | Val F1: 0.3717\n",
      " Trial 40 | Epoch 10/10 | Train Loss: 0.5081 | Train F1: 0.5321 | Val Loss: 0.7005 | Val F1: 0.4166\n",
      "[I 2025-12-13 12:45:48,748] Trial 40 finished with value: 0.416634482365978 and parameters: {'lr': 0.0005929917835677809, 'batch_size': 64, 'optimizer': 'AdamW', 'l2_reg': 3.887840599078158e-05, 'dropout_rate': 0.39827428558039735, 'head_type': 'original', 'head_hidden_dim': 1024, 'loss_config': 'focal_g2_no_weight'}. Best is trial 36 with value: 0.44862375808471944.\n",
      " Trial 41 | Epoch 1/10 | Train Loss: 0.7084 | Train F1: 0.2433 | Val Loss: 0.7257 | Val F1: 0.2624\n",
      " Trial 41 | Epoch 2/10 | Train Loss: 0.6499 | Train F1: 0.3302 | Val Loss: 0.7027 | Val F1: 0.2731\n",
      " Trial 41 | Epoch 3/10 | Train Loss: 0.6094 | Train F1: 0.3944 | Val Loss: 0.7146 | Val F1: 0.2903\n",
      " Trial 41 | Epoch 4/10 | Train Loss: 0.5927 | Train F1: 0.4253 | Val Loss: 0.7047 | Val F1: 0.3221\n",
      "Trial 41 Pruned at Epoch 4\n",
      "[I 2025-12-13 12:46:04,404] Trial 41 pruned. \n",
      " Trial 42 | Epoch 1/10 | Train Loss: 0.7017 | Train F1: 0.2325 | Val Loss: 0.7262 | Val F1: 0.2838\n",
      " Trial 42 | Epoch 2/10 | Train Loss: 0.6353 | Train F1: 0.3373 | Val Loss: 0.7377 | Val F1: 0.2873\n",
      " Trial 42 | Epoch 3/10 | Train Loss: 0.6113 | Train F1: 0.3983 | Val Loss: 0.7317 | Val F1: 0.2828\n",
      " Trial 42 | Epoch 4/10 | Train Loss: 0.5945 | Train F1: 0.4305 | Val Loss: 0.6760 | Val F1: 0.3755\n",
      " Trial 42 | Epoch 5/10 | Train Loss: 0.5630 | Train F1: 0.4632 | Val Loss: 0.7052 | Val F1: 0.3541\n",
      " Trial 42 | Epoch 6/10 | Train Loss: 0.5447 | Train F1: 0.5038 | Val Loss: 0.6835 | Val F1: 0.3697\n",
      " Trial 42 | Epoch 7/10 | Train Loss: 0.5333 | Train F1: 0.5040 | Val Loss: 0.6642 | Val F1: 0.4120\n",
      " Trial 42 | Epoch 8/10 | Train Loss: 0.5313 | Train F1: 0.5125 | Val Loss: 0.6695 | Val F1: 0.4192\n",
      " Trial 42 | Epoch 9/10 | Train Loss: 0.5260 | Train F1: 0.5170 | Val Loss: 0.6701 | Val F1: 0.4283\n",
      " Trial 42 | Epoch 10/10 | Train Loss: 0.5056 | Train F1: 0.5439 | Val Loss: 0.7009 | Val F1: 0.4039\n",
      "[I 2025-12-13 12:46:43,493] Trial 42 finished with value: 0.42828031515197484 and parameters: {'lr': 0.000857727617982196, 'batch_size': 64, 'optimizer': 'AdamW', 'l2_reg': 3.8759940941857206e-05, 'dropout_rate': 0.38619342118748096, 'head_type': 'original', 'head_hidden_dim': 1024, 'loss_config': 'focal_g2_no_weight'}. Best is trial 36 with value: 0.44862375808471944.\n",
      " Trial 43 | Epoch 1/10 | Train Loss: 0.6969 | Train F1: 0.2723 | Val Loss: 0.7222 | Val F1: 0.2648\n",
      " Trial 43 | Epoch 2/10 | Train Loss: 0.6355 | Train F1: 0.3453 | Val Loss: 0.7320 | Val F1: 0.2797\n",
      " Trial 43 | Epoch 3/10 | Train Loss: 0.6094 | Train F1: 0.4011 | Val Loss: 0.6856 | Val F1: 0.2871\n",
      " Trial 43 | Epoch 4/10 | Train Loss: 0.5846 | Train F1: 0.4558 | Val Loss: 0.7247 | Val F1: 0.2841\n",
      "Trial 43 Pruned at Epoch 4\n",
      "[I 2025-12-13 12:46:59,079] Trial 43 pruned. \n",
      " Trial 44 | Epoch 1/10 | Train Loss: 1.2919 | Train F1: 0.2621 | Val Loss: 1.3115 | Val F1: 0.2661\n",
      " Trial 44 | Epoch 2/10 | Train Loss: 1.2127 | Train F1: 0.3356 | Val Loss: 1.3223 | Val F1: 0.2941\n",
      " Trial 44 | Epoch 3/10 | Train Loss: 1.1750 | Train F1: 0.3869 | Val Loss: 1.2887 | Val F1: 0.3437\n",
      " Trial 44 | Epoch 4/10 | Train Loss: 1.1285 | Train F1: 0.4571 | Val Loss: 1.3219 | Val F1: 0.3201\n",
      " Trial 44 | Epoch 5/10 | Train Loss: 1.1147 | Train F1: 0.4684 | Val Loss: 1.3324 | Val F1: 0.3028\n",
      "Trial 44 Pruned at Epoch 5\n",
      "[I 2025-12-13 12:47:18,534] Trial 44 pruned. \n",
      " Trial 45 | Epoch 1/10 | Train Loss: 0.7116 | Train F1: 0.2532 | Val Loss: 0.7307 | Val F1: 0.2721\n",
      " Trial 45 | Epoch 2/10 | Train Loss: 0.6380 | Train F1: 0.3322 | Val Loss: 0.7250 | Val F1: 0.2596\n",
      " Trial 45 | Epoch 3/10 | Train Loss: 0.6072 | Train F1: 0.4137 | Val Loss: 0.6906 | Val F1: 0.3554\n",
      " Trial 45 | Epoch 4/10 | Train Loss: 0.5829 | Train F1: 0.4398 | Val Loss: 0.7721 | Val F1: 0.2857\n",
      " Trial 45 | Epoch 5/10 | Train Loss: 0.5749 | Train F1: 0.4504 | Val Loss: 0.7021 | Val F1: 0.3107\n",
      " Trial 45 | Epoch 6/10 | Train Loss: 0.5486 | Train F1: 0.4970 | Val Loss: 0.6761 | Val F1: 0.4163\n",
      " Trial 45 | Epoch 7/10 | Train Loss: 0.5287 | Train F1: 0.5051 | Val Loss: 0.6874 | Val F1: 0.4052\n",
      " Trial 45 | Epoch 8/10 | Train Loss: 0.5101 | Train F1: 0.5350 | Val Loss: 0.7297 | Val F1: 0.3375\n",
      " Trial 45 | Epoch 9/10 | Train Loss: 0.5077 | Train F1: 0.5319 | Val Loss: 0.6930 | Val F1: 0.4313\n",
      " Trial 45 | Epoch 10/10 | Train Loss: 0.5001 | Train F1: 0.5461 | Val Loss: 0.6908 | Val F1: 0.4245\n",
      "[I 2025-12-13 12:47:56,848] Trial 45 finished with value: 0.4313205407640663 and parameters: {'lr': 0.0008686603021150002, 'batch_size': 64, 'optimizer': 'AdamW', 'l2_reg': 0.0002634910234206946, 'dropout_rate': 0.35863080322023067, 'head_type': 'original', 'head_hidden_dim': 1024, 'loss_config': 'focal_g2_no_weight'}. Best is trial 36 with value: 0.44862375808471944.\n",
      " Trial 46 | Epoch 1/10 | Train Loss: 0.7067 | Train F1: 0.2262 | Val Loss: 0.7268 | Val F1: 0.2833\n",
      " Trial 46 | Epoch 2/10 | Train Loss: 0.6382 | Train F1: 0.3368 | Val Loss: 0.7110 | Val F1: 0.2842\n",
      " Trial 46 | Epoch 3/10 | Train Loss: 0.6033 | Train F1: 0.3788 | Val Loss: 0.6770 | Val F1: 0.3567\n",
      " Trial 46 | Epoch 4/10 | Train Loss: 0.5738 | Train F1: 0.4526 | Val Loss: 0.7130 | Val F1: 0.3337\n",
      " Trial 46 | Epoch 5/10 | Train Loss: 0.5582 | Train F1: 0.4832 | Val Loss: 0.6848 | Val F1: 0.3886\n",
      " Trial 46 | Epoch 6/10 | Train Loss: 0.5464 | Train F1: 0.5027 | Val Loss: 0.6684 | Val F1: 0.3954\n",
      " Trial 46 | Epoch 7/10 | Train Loss: 0.5452 | Train F1: 0.4986 | Val Loss: 0.6795 | Val F1: 0.3981\n",
      " Trial 46 | Epoch 8/10 | Train Loss: 0.5239 | Train F1: 0.5174 | Val Loss: 0.6958 | Val F1: 0.3920\n",
      " Trial 46 | Epoch 9/10 | Train Loss: 0.5079 | Train F1: 0.5364 | Val Loss: 0.7214 | Val F1: 0.3417\n",
      " Trial 46 | Epoch 10/10 | Train Loss: 0.4968 | Train F1: 0.5345 | Val Loss: 0.7082 | Val F1: 0.3765\n",
      "[I 2025-12-13 12:48:35,282] Trial 46 finished with value: 0.3980784108839932 and parameters: {'lr': 0.0006698444592919088, 'batch_size': 64, 'optimizer': 'AdamW', 'l2_reg': 4.526773908172394e-05, 'dropout_rate': 0.3601479241822084, 'head_type': 'original', 'head_hidden_dim': 1024, 'loss_config': 'focal_g2_no_weight'}. Best is trial 36 with value: 0.44862375808471944.\n",
      " Trial 47 | Epoch 1/10 | Train Loss: 0.6926 | Train F1: 0.2615 | Val Loss: 0.7217 | Val F1: 0.2751\n",
      " Trial 47 | Epoch 2/10 | Train Loss: 0.6338 | Train F1: 0.3425 | Val Loss: 0.7465 | Val F1: 0.2634\n",
      " Trial 47 | Epoch 3/10 | Train Loss: 0.6143 | Train F1: 0.3634 | Val Loss: 0.7211 | Val F1: 0.2814\n",
      " Trial 47 | Epoch 4/10 | Train Loss: 0.5963 | Train F1: 0.4005 | Val Loss: 0.7452 | Val F1: 0.2942\n",
      "Trial 47 Pruned at Epoch 4\n",
      "[I 2025-12-13 12:48:50,763] Trial 47 pruned. \n",
      " Trial 48 | Epoch 1/10 | Train Loss: 0.7770 | Train F1: 0.1861 | Val Loss: 0.7700 | Val F1: 0.1540\n",
      " Trial 48 | Epoch 2/10 | Train Loss: 0.7549 | Train F1: 0.1323 | Val Loss: 0.7547 | Val F1: 0.1337\n",
      " Trial 48 | Epoch 3/10 | Train Loss: 0.7326 | Train F1: 0.1292 | Val Loss: 0.7443 | Val F1: 0.1337\n",
      " Trial 48 | Epoch 4/10 | Train Loss: 0.7155 | Train F1: 0.1292 | Val Loss: 0.7393 | Val F1: 0.1337\n",
      "Trial 48 Pruned at Epoch 4\n",
      "[I 2025-12-13 12:49:06,806] Trial 48 pruned. \n",
      " Trial 49 | Epoch 1/10 | Train Loss: 0.7004 | Train F1: 0.2503 | Val Loss: 0.7305 | Val F1: 0.2471\n",
      " Trial 49 | Epoch 2/10 | Train Loss: 0.6383 | Train F1: 0.3457 | Val Loss: 0.6949 | Val F1: 0.3482\n",
      " Trial 49 | Epoch 3/10 | Train Loss: 0.6117 | Train F1: 0.4052 | Val Loss: 0.6990 | Val F1: 0.3049\n",
      " Trial 49 | Epoch 4/10 | Train Loss: 0.5727 | Train F1: 0.4565 | Val Loss: 0.6756 | Val F1: 0.3722\n",
      " Trial 49 | Epoch 5/10 | Train Loss: 0.5675 | Train F1: 0.4737 | Val Loss: 0.6813 | Val F1: 0.3957\n",
      " Trial 49 | Epoch 6/10 | Train Loss: 0.5543 | Train F1: 0.4863 | Val Loss: 0.7193 | Val F1: 0.3622\n",
      " Trial 49 | Epoch 7/10 | Train Loss: 0.5404 | Train F1: 0.5038 | Val Loss: 0.7406 | Val F1: 0.3384\n",
      " Trial 49 | Epoch 8/10 | Train Loss: 0.5354 | Train F1: 0.4919 | Val Loss: 0.6818 | Val F1: 0.3986\n",
      " Trial 49 | Epoch 9/10 | Train Loss: 0.5120 | Train F1: 0.5525 | Val Loss: 0.7467 | Val F1: 0.3461\n",
      " Trial 49 | Epoch 10/10 | Train Loss: 0.4919 | Train F1: 0.5558 | Val Loss: 0.7091 | Val F1: 0.4091\n",
      "[I 2025-12-13 12:49:45,476] Trial 49 finished with value: 0.4090983571625766 and parameters: {'lr': 0.0007457006508665564, 'batch_size': 64, 'optimizer': 'AdamW', 'l2_reg': 0.00011409113025695484, 'dropout_rate': 0.38059171002820663, 'head_type': 'original', 'head_hidden_dim': 1024, 'loss_config': 'focal_g2_no_weight'}. Best is trial 36 with value: 0.44862375808471944.\n",
      " Trial 50 | Epoch 1/10 | Train Loss: 0.7484 | Train F1: 0.1298 | Val Loss: 0.7424 | Val F1: 0.1337\n",
      " Trial 50 | Epoch 2/10 | Train Loss: 0.6980 | Train F1: 0.1607 | Val Loss: 0.7502 | Val F1: 0.1688\n",
      " Trial 50 | Epoch 3/10 | Train Loss: 0.6851 | Train F1: 0.2312 | Val Loss: 0.7333 | Val F1: 0.1617\n",
      " Trial 50 | Epoch 4/10 | Train Loss: 0.6681 | Train F1: 0.2551 | Val Loss: 0.7186 | Val F1: 0.2844\n",
      "Trial 50 Pruned at Epoch 4\n",
      "[I 2025-12-13 12:50:00,978] Trial 50 pruned. \n",
      " Trial 51 | Epoch 1/10 | Train Loss: 1.2933 | Train F1: 0.2360 | Val Loss: 1.3513 | Val F1: 0.2529\n",
      " Trial 51 | Epoch 2/10 | Train Loss: 1.2072 | Train F1: 0.3470 | Val Loss: 1.3012 | Val F1: 0.2919\n",
      " Trial 51 | Epoch 3/10 | Train Loss: 1.1613 | Train F1: 0.3891 | Val Loss: 1.3249 | Val F1: 0.2749\n",
      " Trial 51 | Epoch 4/10 | Train Loss: 1.1514 | Train F1: 0.4507 | Val Loss: 1.2656 | Val F1: 0.3703\n",
      " Trial 51 | Epoch 5/10 | Train Loss: 1.1095 | Train F1: 0.4677 | Val Loss: 1.2968 | Val F1: 0.3806\n",
      " Trial 51 | Epoch 6/10 | Train Loss: 1.0915 | Train F1: 0.4903 | Val Loss: 1.2794 | Val F1: 0.3894\n",
      " Trial 51 | Epoch 7/10 | Train Loss: 1.0572 | Train F1: 0.5154 | Val Loss: 1.3098 | Val F1: 0.3704\n",
      " Trial 51 | Epoch 8/10 | Train Loss: 1.0593 | Train F1: 0.5128 | Val Loss: 1.3043 | Val F1: 0.3705\n",
      " Trial 51 | Epoch 9/10 | Train Loss: 1.0436 | Train F1: 0.5403 | Val Loss: 1.3471 | Val F1: 0.3401\n",
      " Trial 51 | Epoch 10/10 | Train Loss: 1.0399 | Train F1: 0.5241 | Val Loss: 1.3250 | Val F1: 0.3685\n",
      "[I 2025-12-13 12:50:39,491] Trial 51 finished with value: 0.3894017576047503 and parameters: {'lr': 0.000880308880620528, 'batch_size': 64, 'optimizer': 'AdamW', 'l2_reg': 0.0008931269092718014, 'dropout_rate': 0.4101578723145954, 'head_type': 'original', 'head_hidden_dim': 1024, 'loss_config': 'ce_plain'}. Best is trial 36 with value: 0.44862375808471944.\n",
      " Trial 52 | Epoch 1/10 | Train Loss: 1.2947 | Train F1: 0.1798 | Val Loss: 1.3460 | Val F1: 0.1964\n",
      " Trial 52 | Epoch 2/10 | Train Loss: 1.2232 | Train F1: 0.2993 | Val Loss: 1.3144 | Val F1: 0.2681\n",
      " Trial 52 | Epoch 3/10 | Train Loss: 1.1635 | Train F1: 0.4062 | Val Loss: 1.2859 | Val F1: 0.3282\n",
      " Trial 52 | Epoch 4/10 | Train Loss: 1.1258 | Train F1: 0.4299 | Val Loss: 1.2919 | Val F1: 0.3493\n",
      " Trial 52 | Epoch 5/10 | Train Loss: 1.1000 | Train F1: 0.4712 | Val Loss: 1.2534 | Val F1: 0.3688\n",
      " Trial 52 | Epoch 6/10 | Train Loss: 1.0907 | Train F1: 0.4682 | Val Loss: 1.2451 | Val F1: 0.3886\n",
      " Trial 52 | Epoch 7/10 | Train Loss: 1.0410 | Train F1: 0.5173 | Val Loss: 1.2546 | Val F1: 0.3701\n",
      " Trial 52 | Epoch 8/10 | Train Loss: 1.0454 | Train F1: 0.5036 | Val Loss: 1.2371 | Val F1: 0.3782\n",
      " Trial 52 | Epoch 9/10 | Train Loss: 1.0146 | Train F1: 0.5250 | Val Loss: 1.3140 | Val F1: 0.3635\n",
      " Trial 52 | Epoch 10/10 | Train Loss: 1.0049 | Train F1: 0.5269 | Val Loss: 1.3340 | Val F1: 0.3831\n",
      "[I 2025-12-13 12:51:17,975] Trial 52 finished with value: 0.38855884534918794 and parameters: {'lr': 0.0009936377888541137, 'batch_size': 64, 'optimizer': 'AdamW', 'l2_reg': 0.0004829472930830217, 'dropout_rate': 0.39332660381666834, 'head_type': 'original', 'head_hidden_dim': 1024, 'loss_config': 'ce_weighted', 'w1': 0.9356976690324332, 'w2': 0.5156434439922856, 'w3': 0.9228129601328928, 'w4': 1.1851067707435634}. Best is trial 36 with value: 0.44862375808471944.\n",
      " Trial 53 | Epoch 1/10 | Train Loss: 0.7091 | Train F1: 0.2604 | Val Loss: 0.7398 | Val F1: 0.2081\n",
      " Trial 53 | Epoch 2/10 | Train Loss: 0.6497 | Train F1: 0.3223 | Val Loss: 0.6901 | Val F1: 0.3278\n",
      " Trial 53 | Epoch 3/10 | Train Loss: 0.6087 | Train F1: 0.4047 | Val Loss: 0.6772 | Val F1: 0.3769\n",
      " Trial 53 | Epoch 4/10 | Train Loss: 0.5946 | Train F1: 0.4387 | Val Loss: 0.6761 | Val F1: 0.3493\n",
      " Trial 53 | Epoch 5/10 | Train Loss: 0.5691 | Train F1: 0.4746 | Val Loss: 0.7187 | Val F1: 0.3377\n",
      " Trial 53 | Epoch 6/10 | Train Loss: 0.5388 | Train F1: 0.4919 | Val Loss: 0.6704 | Val F1: 0.4019\n",
      " Trial 53 | Epoch 7/10 | Train Loss: 0.5418 | Train F1: 0.4999 | Val Loss: 0.7185 | Val F1: 0.3689\n",
      " Trial 53 | Epoch 8/10 | Train Loss: 0.5245 | Train F1: 0.5159 | Val Loss: 0.7051 | Val F1: 0.3850\n",
      " Trial 53 | Epoch 9/10 | Train Loss: 0.5076 | Train F1: 0.5318 | Val Loss: 0.7185 | Val F1: 0.3816\n",
      " Trial 53 | Epoch 10/10 | Train Loss: 0.5032 | Train F1: 0.5367 | Val Loss: 0.7379 | Val F1: 0.3853\n",
      "[I 2025-12-13 12:51:56,410] Trial 53 finished with value: 0.4019356262824868 and parameters: {'lr': 0.0008878444590539903, 'batch_size': 64, 'optimizer': 'AdamW', 'l2_reg': 0.00033288937841227233, 'dropout_rate': 0.3581457949621001, 'head_type': 'original', 'head_hidden_dim': 1024, 'loss_config': 'focal_g2_no_weight'}. Best is trial 36 with value: 0.44862375808471944.\n",
      " Trial 54 | Epoch 1/10 | Train Loss: 0.2400 | Train F1: 0.2103 | Val Loss: 0.2516 | Val F1: 0.1885\n",
      " Trial 54 | Epoch 2/10 | Train Loss: 0.2168 | Train F1: 0.3204 | Val Loss: 0.2591 | Val F1: 0.3027\n",
      " Trial 54 | Epoch 3/10 | Train Loss: 0.2057 | Train F1: 0.3887 | Val Loss: 0.2481 | Val F1: 0.3513\n",
      " Trial 54 | Epoch 4/10 | Train Loss: 0.1946 | Train F1: 0.4253 | Val Loss: 0.2569 | Val F1: 0.2778\n",
      " Trial 54 | Epoch 5/10 | Train Loss: 0.1908 | Train F1: 0.4475 | Val Loss: 0.2266 | Val F1: 0.3866\n",
      " Trial 54 | Epoch 6/10 | Train Loss: 0.1889 | Train F1: 0.4557 | Val Loss: 0.2277 | Val F1: 0.3941\n",
      " Trial 54 | Epoch 7/10 | Train Loss: 0.1767 | Train F1: 0.4753 | Val Loss: 0.2485 | Val F1: 0.3671\n",
      " Trial 54 | Epoch 8/10 | Train Loss: 0.1743 | Train F1: 0.4881 | Val Loss: 0.2351 | Val F1: 0.4160\n",
      " Trial 54 | Epoch 9/10 | Train Loss: 0.1714 | Train F1: 0.5177 | Val Loss: 0.2329 | Val F1: 0.3888\n",
      " Trial 54 | Epoch 10/10 | Train Loss: 0.1733 | Train F1: 0.4976 | Val Loss: 0.2385 | Val F1: 0.4011\n",
      "[I 2025-12-13 12:52:34,968] Trial 54 finished with value: 0.41595871349556 and parameters: {'lr': 0.0006612660075906285, 'batch_size': 64, 'optimizer': 'AdamW', 'l2_reg': 0.008346573289835476, 'dropout_rate': 0.40528476890240633, 'head_type': 'original', 'head_hidden_dim': 1024, 'loss_config': 'focal_g5_weighted', 'w1': 0.9137143384605635, 'w2': 0.8943233107659394, 'w3': 0.5622338388686031, 'w4': 1.0591898334299397}. Best is trial 36 with value: 0.44862375808471944.\n",
      " Trial 55 | Epoch 1/10 | Train Loss: 1.3569 | Train F1: 0.1437 | Val Loss: 1.3575 | Val F1: 0.1770\n",
      " Trial 55 | Epoch 2/10 | Train Loss: 1.2922 | Train F1: 0.3210 | Val Loss: 1.3398 | Val F1: 0.2248\n",
      " Trial 55 | Epoch 3/10 | Train Loss: 1.2673 | Train F1: 0.3587 | Val Loss: 1.3429 | Val F1: 0.2782\n",
      " Trial 55 | Epoch 4/10 | Train Loss: 1.2367 | Train F1: 0.3963 | Val Loss: 1.3337 | Val F1: 0.3216\n",
      "Trial 55 Pruned at Epoch 4\n",
      "[I 2025-12-13 12:52:50,626] Trial 55 pruned. \n",
      " Trial 56 | Epoch 1/10 | Train Loss: 0.7104 | Train F1: 0.2198 | Val Loss: 0.7372 | Val F1: 0.1337\n",
      " Trial 56 | Epoch 2/10 | Train Loss: 0.6646 | Train F1: 0.2948 | Val Loss: 0.7212 | Val F1: 0.2466\n",
      " Trial 56 | Epoch 3/10 | Train Loss: 0.6334 | Train F1: 0.3321 | Val Loss: 0.7125 | Val F1: 0.2597\n",
      " Trial 56 | Epoch 4/10 | Train Loss: 0.6084 | Train F1: 0.3820 | Val Loss: 0.6830 | Val F1: 0.3514\n",
      " Trial 56 | Epoch 5/10 | Train Loss: 0.5938 | Train F1: 0.4249 | Val Loss: 0.6896 | Val F1: 0.3433\n",
      "Trial 56 Pruned at Epoch 5\n",
      "[I 2025-12-13 12:53:09,903] Trial 56 pruned. \n",
      " Trial 57 | Epoch 1/10 | Train Loss: 0.5758 | Train F1: 0.2785 | Val Loss: 0.6354 | Val F1: 0.2961\n",
      " Trial 57 | Epoch 2/10 | Train Loss: 0.5274 | Train F1: 0.3748 | Val Loss: 0.5918 | Val F1: 0.3396\n",
      " Trial 57 | Epoch 3/10 | Train Loss: 0.4956 | Train F1: 0.4253 | Val Loss: 0.5692 | Val F1: 0.3173\n",
      " Trial 57 | Epoch 4/10 | Train Loss: 0.4868 | Train F1: 0.4339 | Val Loss: 0.6499 | Val F1: 0.3266\n",
      " Trial 57 | Epoch 5/10 | Train Loss: 0.4703 | Train F1: 0.4592 | Val Loss: 0.6039 | Val F1: 0.3730\n",
      " Trial 57 | Epoch 6/10 | Train Loss: 0.4579 | Train F1: 0.4707 | Val Loss: 0.5751 | Val F1: 0.3308\n",
      " Trial 57 | Epoch 7/10 | Train Loss: 0.4276 | Train F1: 0.5120 | Val Loss: 0.5919 | Val F1: 0.3570\n",
      " Trial 57 | Epoch 8/10 | Train Loss: 0.4262 | Train F1: 0.4996 | Val Loss: 0.6012 | Val F1: 0.3899\n",
      " Trial 57 | Epoch 9/10 | Train Loss: 0.4109 | Train F1: 0.5274 | Val Loss: 0.6402 | Val F1: 0.3978\n",
      " Trial 57 | Epoch 10/10 | Train Loss: 0.3906 | Train F1: 0.5372 | Val Loss: 0.6724 | Val F1: 0.3893\n",
      "[I 2025-12-13 12:53:48,371] Trial 57 finished with value: 0.397823850983603 and parameters: {'lr': 0.000894423542502915, 'batch_size': 64, 'optimizer': 'AdamW', 'l2_reg': 0.00018247364263648474, 'dropout_rate': 0.3828645496384041, 'head_type': 'original', 'head_hidden_dim': 1024, 'loss_config': 'focal_g2_weighted', 'w1': 0.5940437298024008, 'w2': 0.9105460154288381, 'w3': 0.6558591613600282, 'w4': 1.4992901519334427}. Best is trial 36 with value: 0.44862375808471944.\n",
      " Trial 58 | Epoch 1/10 | Train Loss: 1.3507 | Train F1: 0.1883 | Val Loss: 1.3513 | Val F1: 0.1337\n",
      " Trial 58 | Epoch 2/10 | Train Loss: 1.3141 | Train F1: 0.1744 | Val Loss: 1.3514 | Val F1: 0.1337\n",
      " Trial 58 | Epoch 3/10 | Train Loss: 1.2994 | Train F1: 0.1698 | Val Loss: 1.3391 | Val F1: 0.2368\n",
      " Trial 58 | Epoch 4/10 | Train Loss: 1.2791 | Train F1: 0.3130 | Val Loss: 1.3302 | Val F1: 0.2451\n",
      "Trial 58 Pruned at Epoch 4\n",
      "[I 2025-12-13 12:54:03,757] Trial 58 pruned. \n",
      " Trial 59 | Epoch 1/10 | Train Loss: 1.2810 | Train F1: 0.2694 | Val Loss: 1.3081 | Val F1: 0.2401\n",
      " Trial 59 | Epoch 2/10 | Train Loss: 1.2083 | Train F1: 0.3439 | Val Loss: 1.3084 | Val F1: 0.2823\n",
      " Trial 59 | Epoch 3/10 | Train Loss: 1.1762 | Train F1: 0.3575 | Val Loss: 1.3267 | Val F1: 0.2576\n",
      " Trial 59 | Epoch 4/10 | Train Loss: 1.1594 | Train F1: 0.3739 | Val Loss: 1.2999 | Val F1: 0.2870\n",
      "Trial 59 Pruned at Epoch 4\n",
      "[I 2025-12-13 12:54:19,350] Trial 59 pruned. \n",
      " Trial 60 | Epoch 1/10 | Train Loss: 0.7708 | Train F1: 0.2191 | Val Loss: 0.7622 | Val F1: 0.1499\n",
      " Trial 60 | Epoch 2/10 | Train Loss: 0.7372 | Train F1: 0.1366 | Val Loss: 0.7444 | Val F1: 0.1337\n",
      " Trial 60 | Epoch 3/10 | Train Loss: 0.7114 | Train F1: 0.1292 | Val Loss: 0.7384 | Val F1: 0.1337\n",
      " Trial 60 | Epoch 4/10 | Train Loss: 0.6950 | Train F1: 0.1363 | Val Loss: 0.7378 | Val F1: 0.1370\n",
      "Trial 60 Pruned at Epoch 4\n",
      "[I 2025-12-13 12:54:35,048] Trial 60 pruned. \n",
      " Trial 61 | Epoch 1/10 | Train Loss: 0.7097 | Train F1: 0.2217 | Val Loss: 0.7314 | Val F1: 0.2840\n",
      " Trial 61 | Epoch 2/10 | Train Loss: 0.6466 | Train F1: 0.3244 | Val Loss: 0.7073 | Val F1: 0.2861\n",
      " Trial 61 | Epoch 3/10 | Train Loss: 0.6212 | Train F1: 0.3682 | Val Loss: 0.7033 | Val F1: 0.2578\n",
      " Trial 61 | Epoch 4/10 | Train Loss: 0.5865 | Train F1: 0.4151 | Val Loss: 0.6882 | Val F1: 0.3441\n",
      " Trial 61 | Epoch 5/10 | Train Loss: 0.5737 | Train F1: 0.4442 | Val Loss: 0.7080 | Val F1: 0.3155\n",
      "Trial 61 Pruned at Epoch 5\n",
      "[I 2025-12-13 12:54:54,373] Trial 61 pruned. \n",
      " Trial 62 | Epoch 1/10 | Train Loss: 0.6879 | Train F1: 0.2556 | Val Loss: 0.7335 | Val F1: 0.2426\n",
      " Trial 62 | Epoch 2/10 | Train Loss: 0.6314 | Train F1: 0.3450 | Val Loss: 0.7174 | Val F1: 0.2951\n",
      " Trial 62 | Epoch 3/10 | Train Loss: 0.6023 | Train F1: 0.4087 | Val Loss: 0.7315 | Val F1: 0.2885\n",
      " Trial 62 | Epoch 4/10 | Train Loss: 0.5856 | Train F1: 0.4489 | Val Loss: 0.6914 | Val F1: 0.3375\n",
      " Trial 62 | Epoch 5/10 | Train Loss: 0.5567 | Train F1: 0.4724 | Val Loss: 0.7294 | Val F1: 0.3180\n",
      "Trial 62 Pruned at Epoch 5\n",
      "[I 2025-12-13 12:55:13,766] Trial 62 pruned. \n",
      " Trial 63 | Epoch 1/10 | Train Loss: 0.6964 | Train F1: 0.2580 | Val Loss: 0.7351 | Val F1: 0.1855\n",
      " Trial 63 | Epoch 2/10 | Train Loss: 0.6434 | Train F1: 0.3412 | Val Loss: 0.7278 | Val F1: 0.2933\n",
      " Trial 63 | Epoch 3/10 | Train Loss: 0.6136 | Train F1: 0.3803 | Val Loss: 0.6951 | Val F1: 0.3633\n",
      " Trial 63 | Epoch 4/10 | Train Loss: 0.5800 | Train F1: 0.4480 | Val Loss: 0.7475 | Val F1: 0.2916\n",
      " Trial 63 | Epoch 5/10 | Train Loss: 0.5846 | Train F1: 0.4295 | Val Loss: 0.6915 | Val F1: 0.3959\n",
      " Trial 63 | Epoch 6/10 | Train Loss: 0.5504 | Train F1: 0.5036 | Val Loss: 0.7309 | Val F1: 0.3550\n",
      " Trial 63 | Epoch 7/10 | Train Loss: 0.5341 | Train F1: 0.4938 | Val Loss: 0.7074 | Val F1: 0.3807\n",
      " Trial 63 | Epoch 8/10 | Train Loss: 0.5337 | Train F1: 0.5063 | Val Loss: 0.7191 | Val F1: 0.3917\n",
      " Trial 63 | Epoch 9/10 | Train Loss: 0.5207 | Train F1: 0.5024 | Val Loss: 0.6965 | Val F1: 0.3575\n",
      " Trial 63 | Epoch 10/10 | Train Loss: 0.5166 | Train F1: 0.5265 | Val Loss: 0.7225 | Val F1: 0.3744\n",
      "[I 2025-12-13 12:55:52,322] Trial 63 finished with value: 0.39588816390563775 and parameters: {'lr': 0.0008284141053690886, 'batch_size': 64, 'optimizer': 'AdamW', 'l2_reg': 3.9677582512019116e-05, 'dropout_rate': 0.43108317264960394, 'head_type': 'original', 'head_hidden_dim': 1024, 'loss_config': 'focal_g2_no_weight'}. Best is trial 36 with value: 0.44862375808471944.\n",
      " Trial 64 | Epoch 1/10 | Train Loss: 1.3121 | Train F1: 0.2258 | Val Loss: 1.3336 | Val F1: 0.2608\n",
      " Trial 64 | Epoch 2/10 | Train Loss: 1.2607 | Train F1: 0.3224 | Val Loss: 1.3070 | Val F1: 0.3224\n",
      " Trial 64 | Epoch 3/10 | Train Loss: 1.2181 | Train F1: 0.3926 | Val Loss: 1.3231 | Val F1: 0.2831\n",
      " Trial 64 | Epoch 4/10 | Train Loss: 1.1799 | Train F1: 0.4547 | Val Loss: 1.3463 | Val F1: 0.2667\n",
      "Trial 64 Pruned at Epoch 4\n",
      "[I 2025-12-13 12:56:07,899] Trial 64 pruned. \n",
      " Trial 65 | Epoch 1/10 | Train Loss: 1.3318 | Train F1: 0.1932 | Val Loss: 1.3541 | Val F1: 0.1337\n",
      " Trial 65 | Epoch 2/10 | Train Loss: 1.2817 | Train F1: 0.2992 | Val Loss: 1.3327 | Val F1: 0.2190\n",
      " Trial 65 | Epoch 3/10 | Train Loss: 1.2444 | Train F1: 0.3609 | Val Loss: 1.3029 | Val F1: 0.3604\n",
      " Trial 65 | Epoch 4/10 | Train Loss: 1.2186 | Train F1: 0.4312 | Val Loss: 1.3328 | Val F1: 0.2678\n",
      " Trial 65 | Epoch 5/10 | Train Loss: 1.1975 | Train F1: 0.4386 | Val Loss: 1.3387 | Val F1: 0.2998\n",
      " Trial 65 | Epoch 6/10 | Train Loss: 1.1907 | Train F1: 0.4592 | Val Loss: 1.3326 | Val F1: 0.3093\n",
      "Trial 65 Pruned at Epoch 6\n",
      "[I 2025-12-13 12:56:31,248] Trial 65 pruned. \n",
      " Trial 66 | Epoch 1/10 | Train Loss: 0.7077 | Train F1: 0.2318 | Val Loss: 0.7250 | Val F1: 0.2413\n",
      " Trial 66 | Epoch 2/10 | Train Loss: 0.6454 | Train F1: 0.3329 | Val Loss: 0.6957 | Val F1: 0.2836\n",
      " Trial 66 | Epoch 3/10 | Train Loss: 0.6144 | Train F1: 0.4036 | Val Loss: 0.7198 | Val F1: 0.3017\n",
      " Trial 66 | Epoch 4/10 | Train Loss: 0.5923 | Train F1: 0.4254 | Val Loss: 0.7128 | Val F1: 0.3727\n",
      " Trial 66 | Epoch 5/10 | Train Loss: 0.5689 | Train F1: 0.4654 | Val Loss: 0.7085 | Val F1: 0.3472\n",
      " Trial 66 | Epoch 6/10 | Train Loss: 0.5537 | Train F1: 0.4938 | Val Loss: 0.6896 | Val F1: 0.4062\n",
      " Trial 66 | Epoch 7/10 | Train Loss: 0.5483 | Train F1: 0.4911 | Val Loss: 0.6750 | Val F1: 0.4132\n",
      " Trial 66 | Epoch 8/10 | Train Loss: 0.5325 | Train F1: 0.5141 | Val Loss: 0.6940 | Val F1: 0.4025\n",
      " Trial 66 | Epoch 9/10 | Train Loss: 0.5219 | Train F1: 0.5223 | Val Loss: 0.6991 | Val F1: 0.4136\n",
      " Trial 66 | Epoch 10/10 | Train Loss: 0.5140 | Train F1: 0.5449 | Val Loss: 0.6945 | Val F1: 0.4024\n",
      "[I 2025-12-13 12:57:09,852] Trial 66 finished with value: 0.41356533116447847 and parameters: {'lr': 0.0006911583681572731, 'batch_size': 64, 'optimizer': 'AdamW', 'l2_reg': 0.00010936826457119617, 'dropout_rate': 0.4453105768027802, 'head_type': 'original', 'head_hidden_dim': 1024, 'loss_config': 'focal_g2_no_weight'}. Best is trial 36 with value: 0.44862375808471944.\n",
      " Trial 67 | Epoch 1/10 | Train Loss: 1.3172 | Train F1: 0.2740 | Val Loss: 1.3326 | Val F1: 0.2802\n",
      " Trial 67 | Epoch 2/10 | Train Loss: 1.2630 | Train F1: 0.3151 | Val Loss: 1.3289 | Val F1: 0.2694\n",
      " Trial 67 | Epoch 3/10 | Train Loss: 1.2243 | Train F1: 0.3749 | Val Loss: 1.3016 | Val F1: 0.3286\n",
      " Trial 67 | Epoch 4/10 | Train Loss: 1.2102 | Train F1: 0.4140 | Val Loss: 1.3205 | Val F1: 0.2931\n",
      "Trial 67 Pruned at Epoch 4\n",
      "[I 2025-12-13 12:57:25,422] Trial 67 pruned. \n",
      " Trial 68 | Epoch 1/10 | Train Loss: 1.3064 | Train F1: 0.2105 | Val Loss: 1.3340 | Val F1: 0.2526\n",
      " Trial 68 | Epoch 2/10 | Train Loss: 1.2121 | Train F1: 0.3329 | Val Loss: 1.3115 | Val F1: 0.2734\n",
      " Trial 68 | Epoch 3/10 | Train Loss: 1.1800 | Train F1: 0.3556 | Val Loss: 1.3347 | Val F1: 0.2837\n",
      " Trial 68 | Epoch 4/10 | Train Loss: 1.1268 | Train F1: 0.3791 | Val Loss: 1.2823 | Val F1: 0.3409\n",
      " Trial 68 | Epoch 5/10 | Train Loss: 1.0949 | Train F1: 0.4130 | Val Loss: 1.3445 | Val F1: 0.3491\n",
      "Trial 68 Pruned at Epoch 5\n",
      "[I 2025-12-13 12:57:44,732] Trial 68 pruned. \n",
      " Trial 69 | Epoch 1/10 | Train Loss: 0.2620 | Train F1: 0.1880 | Val Loss: 0.2887 | Val F1: 0.2188\n",
      " Trial 69 | Epoch 2/10 | Train Loss: 0.2384 | Train F1: 0.3480 | Val Loss: 0.2765 | Val F1: 0.3201\n",
      " Trial 69 | Epoch 3/10 | Train Loss: 0.2266 | Train F1: 0.4108 | Val Loss: 0.2889 | Val F1: 0.2765\n",
      " Trial 69 | Epoch 4/10 | Train Loss: 0.2159 | Train F1: 0.4238 | Val Loss: 0.2605 | Val F1: 0.3722\n",
      " Trial 69 | Epoch 5/10 | Train Loss: 0.2061 | Train F1: 0.4618 | Val Loss: 0.2939 | Val F1: 0.2829\n",
      " Trial 69 | Epoch 6/10 | Train Loss: 0.2017 | Train F1: 0.4624 | Val Loss: 0.3022 | Val F1: 0.3247\n",
      " Trial 69 | Epoch 7/10 | Train Loss: 0.1982 | Train F1: 0.4838 | Val Loss: 0.2727 | Val F1: 0.3521\n",
      " Trial 69 | Epoch 8/10 | Train Loss: 0.1916 | Train F1: 0.4971 | Val Loss: 0.2504 | Val F1: 0.3595\n",
      "Trial 69 Pruned at Epoch 8\n",
      "[I 2025-12-13 12:58:15,977] Trial 69 pruned. \n",
      " Trial 70 | Epoch 1/10 | Train Loss: 0.6955 | Train F1: 0.2763 | Val Loss: 0.7177 | Val F1: 0.2533\n",
      " Trial 70 | Epoch 2/10 | Train Loss: 0.6316 | Train F1: 0.3582 | Val Loss: 0.6856 | Val F1: 0.3333\n",
      " Trial 70 | Epoch 3/10 | Train Loss: 0.6008 | Train F1: 0.4100 | Val Loss: 0.7166 | Val F1: 0.3437\n",
      " Trial 70 | Epoch 4/10 | Train Loss: 0.5805 | Train F1: 0.4381 | Val Loss: 0.6813 | Val F1: 0.3828\n",
      " Trial 70 | Epoch 5/10 | Train Loss: 0.5630 | Train F1: 0.4839 | Val Loss: 0.7110 | Val F1: 0.3645\n",
      " Trial 70 | Epoch 6/10 | Train Loss: 0.5343 | Train F1: 0.5102 | Val Loss: 0.6833 | Val F1: 0.4105\n",
      " Trial 70 | Epoch 7/10 | Train Loss: 0.5237 | Train F1: 0.5226 | Val Loss: 0.7250 | Val F1: 0.3865\n",
      " Trial 70 | Epoch 8/10 | Train Loss: 0.5192 | Train F1: 0.5242 | Val Loss: 0.7145 | Val F1: 0.3722\n",
      " Trial 70 | Epoch 9/10 | Train Loss: 0.5231 | Train F1: 0.5063 | Val Loss: 0.7152 | Val F1: 0.3874\n",
      " Trial 70 | Epoch 10/10 | Train Loss: 0.4961 | Train F1: 0.5431 | Val Loss: 0.7096 | Val F1: 0.4277\n",
      "[I 2025-12-13 12:58:56,070] Trial 70 finished with value: 0.4276640435785529 and parameters: {'lr': 0.0008608493354209996, 'batch_size': 64, 'optimizer': 'AdamW', 'l2_reg': 5.536671936979175e-05, 'dropout_rate': 0.33240984036654775, 'head_type': 'original', 'head_hidden_dim': 1024, 'loss_config': 'focal_g2_no_weight'}. Best is trial 36 with value: 0.44862375808471944.\n",
      " Trial 71 | Epoch 1/10 | Train Loss: 0.6927 | Train F1: 0.2718 | Val Loss: 0.7186 | Val F1: 0.2492\n",
      " Trial 71 | Epoch 2/10 | Train Loss: 0.6230 | Train F1: 0.3491 | Val Loss: 0.6911 | Val F1: 0.3667\n",
      " Trial 71 | Epoch 3/10 | Train Loss: 0.5905 | Train F1: 0.4274 | Val Loss: 0.6962 | Val F1: 0.3443\n",
      " Trial 71 | Epoch 4/10 | Train Loss: 0.5879 | Train F1: 0.4388 | Val Loss: 0.6667 | Val F1: 0.4044\n",
      " Trial 71 | Epoch 5/10 | Train Loss: 0.5743 | Train F1: 0.4542 | Val Loss: 0.7240 | Val F1: 0.3062\n",
      " Trial 71 | Epoch 6/10 | Train Loss: 0.5500 | Train F1: 0.4970 | Val Loss: 0.7339 | Val F1: 0.3149\n",
      " Trial 71 | Epoch 7/10 | Train Loss: 0.5201 | Train F1: 0.5153 | Val Loss: 0.7036 | Val F1: 0.3740\n",
      " Trial 71 | Epoch 8/10 | Train Loss: 0.5193 | Train F1: 0.5286 | Val Loss: 0.7074 | Val F1: 0.3805\n",
      " Trial 71 | Epoch 9/10 | Train Loss: 0.5059 | Train F1: 0.5315 | Val Loss: 0.6886 | Val F1: 0.3765\n",
      " Trial 71 | Epoch 10/10 | Train Loss: 0.5131 | Train F1: 0.5249 | Val Loss: 0.7183 | Val F1: 0.3917\n",
      "[I 2025-12-13 12:59:36,018] Trial 71 finished with value: 0.40439928458518914 and parameters: {'lr': 0.0008532206996803726, 'batch_size': 64, 'optimizer': 'AdamW', 'l2_reg': 5.8525266079549574e-05, 'dropout_rate': 0.33195867133141516, 'head_type': 'original', 'head_hidden_dim': 1024, 'loss_config': 'focal_g2_no_weight'}. Best is trial 36 with value: 0.44862375808471944.\n",
      " Trial 72 | Epoch 1/10 | Train Loss: 0.7000 | Train F1: 0.2336 | Val Loss: 0.7398 | Val F1: 0.2576\n",
      " Trial 72 | Epoch 2/10 | Train Loss: 0.6341 | Train F1: 0.3537 | Val Loss: 0.6917 | Val F1: 0.3268\n",
      " Trial 72 | Epoch 3/10 | Train Loss: 0.6097 | Train F1: 0.4071 | Val Loss: 0.6828 | Val F1: 0.3724\n",
      " Trial 72 | Epoch 4/10 | Train Loss: 0.5872 | Train F1: 0.4347 | Val Loss: 0.6949 | Val F1: 0.3588\n",
      " Trial 72 | Epoch 5/10 | Train Loss: 0.5532 | Train F1: 0.4742 | Val Loss: 0.6920 | Val F1: 0.3666\n",
      " Trial 72 | Epoch 6/10 | Train Loss: 0.5497 | Train F1: 0.4983 | Val Loss: 0.6908 | Val F1: 0.3431\n",
      " Trial 72 | Epoch 7/10 | Train Loss: 0.5231 | Train F1: 0.5099 | Val Loss: 0.6688 | Val F1: 0.4204\n",
      " Trial 72 | Epoch 8/10 | Train Loss: 0.5171 | Train F1: 0.5149 | Val Loss: 0.6793 | Val F1: 0.4305\n",
      " Trial 72 | Epoch 9/10 | Train Loss: 0.5050 | Train F1: 0.5329 | Val Loss: 0.6944 | Val F1: 0.4089\n",
      " Trial 72 | Epoch 10/10 | Train Loss: 0.5116 | Train F1: 0.5228 | Val Loss: 0.6661 | Val F1: 0.4282\n",
      "[I 2025-12-13 13:00:16,455] Trial 72 finished with value: 0.4304659185213488 and parameters: {'lr': 0.0007723501274256295, 'batch_size': 64, 'optimizer': 'AdamW', 'l2_reg': 0.00022153991503363326, 'dropout_rate': 0.3367693554727541, 'head_type': 'original', 'head_hidden_dim': 1024, 'loss_config': 'focal_g2_no_weight'}. Best is trial 36 with value: 0.44862375808471944.\n",
      " Trial 73 | Epoch 1/10 | Train Loss: 0.6846 | Train F1: 0.2746 | Val Loss: 0.7262 | Val F1: 0.2717\n",
      " Trial 73 | Epoch 2/10 | Train Loss: 0.6334 | Train F1: 0.3558 | Val Loss: 0.6969 | Val F1: 0.2737\n",
      " Trial 73 | Epoch 3/10 | Train Loss: 0.5935 | Train F1: 0.4388 | Val Loss: 0.6945 | Val F1: 0.3475\n",
      " Trial 73 | Epoch 4/10 | Train Loss: 0.5764 | Train F1: 0.4411 | Val Loss: 0.6927 | Val F1: 0.3824\n",
      " Trial 73 | Epoch 5/10 | Train Loss: 0.5530 | Train F1: 0.5001 | Val Loss: 0.6939 | Val F1: 0.3658\n",
      " Trial 73 | Epoch 6/10 | Train Loss: 0.5363 | Train F1: 0.5085 | Val Loss: 0.7343 | Val F1: 0.2764\n",
      " Trial 73 | Epoch 7/10 | Train Loss: 0.5240 | Train F1: 0.5162 | Val Loss: 0.7118 | Val F1: 0.4353\n",
      " Trial 73 | Epoch 8/10 | Train Loss: 0.5192 | Train F1: 0.5258 | Val Loss: 0.7894 | Val F1: 0.2904\n",
      " Trial 73 | Epoch 9/10 | Train Loss: 0.5038 | Train F1: 0.5249 | Val Loss: 0.7211 | Val F1: 0.3999\n",
      " Trial 73 | Epoch 10/10 | Train Loss: 0.4974 | Train F1: 0.5353 | Val Loss: 0.7336 | Val F1: 0.3272\n",
      "[I 2025-12-13 13:00:56,861] Trial 73 finished with value: 0.43526683128661803 and parameters: {'lr': 0.00093728585095452, 'batch_size': 64, 'optimizer': 'AdamW', 'l2_reg': 0.00021150830344114367, 'dropout_rate': 0.33791810750951184, 'head_type': 'original', 'head_hidden_dim': 1024, 'loss_config': 'focal_g2_no_weight'}. Best is trial 36 with value: 0.44862375808471944.\n",
      " Trial 74 | Epoch 1/10 | Train Loss: 0.6988 | Train F1: 0.2530 | Val Loss: 0.7114 | Val F1: 0.2058\n",
      " Trial 74 | Epoch 2/10 | Train Loss: 0.6367 | Train F1: 0.3372 | Val Loss: 0.7013 | Val F1: 0.2894\n",
      " Trial 74 | Epoch 3/10 | Train Loss: 0.6023 | Train F1: 0.4129 | Val Loss: 0.7378 | Val F1: 0.3101\n",
      " Trial 74 | Epoch 4/10 | Train Loss: 0.5857 | Train F1: 0.4380 | Val Loss: 0.6786 | Val F1: 0.3865\n",
      " Trial 74 | Epoch 5/10 | Train Loss: 0.5629 | Train F1: 0.4845 | Val Loss: 0.6682 | Val F1: 0.3770\n",
      " Trial 74 | Epoch 6/10 | Train Loss: 0.5354 | Train F1: 0.5131 | Val Loss: 0.6940 | Val F1: 0.4067\n",
      " Trial 74 | Epoch 7/10 | Train Loss: 0.5194 | Train F1: 0.5153 | Val Loss: 0.6768 | Val F1: 0.4359\n",
      " Trial 74 | Epoch 8/10 | Train Loss: 0.5086 | Train F1: 0.5477 | Val Loss: 0.6920 | Val F1: 0.4271\n",
      " Trial 74 | Epoch 9/10 | Train Loss: 0.4990 | Train F1: 0.5365 | Val Loss: 0.6824 | Val F1: 0.4292\n",
      " Trial 74 | Epoch 10/10 | Train Loss: 0.4811 | Train F1: 0.5586 | Val Loss: 0.7152 | Val F1: 0.4173\n",
      "[I 2025-12-13 13:01:37,943] Trial 74 finished with value: 0.43592104834582523 and parameters: {'lr': 0.0007719695267829555, 'batch_size': 64, 'optimizer': 'AdamW', 'l2_reg': 0.00020083470770254391, 'dropout_rate': 0.3368703714904333, 'head_type': 'original', 'head_hidden_dim': 1024, 'loss_config': 'focal_g2_no_weight'}. Best is trial 36 with value: 0.44862375808471944.\n",
      " Trial 75 | Epoch 1/10 | Train Loss: 0.7042 | Train F1: 0.2485 | Val Loss: 0.7397 | Val F1: 0.2122\n",
      " Trial 75 | Epoch 2/10 | Train Loss: 0.6365 | Train F1: 0.3324 | Val Loss: 0.7217 | Val F1: 0.2895\n",
      " Trial 75 | Epoch 3/10 | Train Loss: 0.6212 | Train F1: 0.3984 | Val Loss: 0.7333 | Val F1: 0.2437\n",
      " Trial 75 | Epoch 4/10 | Train Loss: 0.5852 | Train F1: 0.4307 | Val Loss: 0.7040 | Val F1: 0.3790\n",
      " Trial 75 | Epoch 5/10 | Train Loss: 0.5525 | Train F1: 0.4807 | Val Loss: 0.6788 | Val F1: 0.3903\n",
      " Trial 75 | Epoch 6/10 | Train Loss: 0.5572 | Train F1: 0.4820 | Val Loss: 0.6750 | Val F1: 0.3866\n",
      " Trial 75 | Epoch 7/10 | Train Loss: 0.5329 | Train F1: 0.5089 | Val Loss: 0.6924 | Val F1: 0.4066\n",
      " Trial 75 | Epoch 8/10 | Train Loss: 0.5152 | Train F1: 0.5159 | Val Loss: 0.7261 | Val F1: 0.3830\n",
      " Trial 75 | Epoch 9/10 | Train Loss: 0.5073 | Train F1: 0.5312 | Val Loss: 0.7068 | Val F1: 0.3965\n",
      " Trial 75 | Epoch 10/10 | Train Loss: 0.5071 | Train F1: 0.5339 | Val Loss: 0.7090 | Val F1: 0.3470\n",
      "[I 2025-12-13 13:02:18,642] Trial 75 finished with value: 0.4066084922438244 and parameters: {'lr': 0.000778755773443274, 'batch_size': 64, 'optimizer': 'AdamW', 'l2_reg': 0.00021764430126284412, 'dropout_rate': 0.347159644964666, 'head_type': 'original', 'head_hidden_dim': 1024, 'loss_config': 'focal_g2_no_weight'}. Best is trial 36 with value: 0.44862375808471944.\n",
      " Trial 76 | Epoch 1/10 | Train Loss: 0.7157 | Train F1: 0.1520 | Val Loss: 0.7388 | Val F1: 0.1497\n",
      " Trial 76 | Epoch 2/10 | Train Loss: 0.6764 | Train F1: 0.2532 | Val Loss: 0.7305 | Val F1: 0.2480\n",
      " Trial 76 | Epoch 3/10 | Train Loss: 0.6597 | Train F1: 0.3180 | Val Loss: 0.7212 | Val F1: 0.2815\n",
      " Trial 76 | Epoch 4/10 | Train Loss: 0.6522 | Train F1: 0.3350 | Val Loss: 0.7161 | Val F1: 0.2742\n",
      "Trial 76 Pruned at Epoch 4\n",
      "[I 2025-12-13 13:02:34,597] Trial 76 pruned. \n",
      " Trial 77 | Epoch 1/10 | Train Loss: 0.7444 | Train F1: 0.2208 | Val Loss: 0.7408 | Val F1: 0.1337\n",
      " Trial 77 | Epoch 2/10 | Train Loss: 0.6879 | Train F1: 0.2213 | Val Loss: 0.7382 | Val F1: 0.2108\n",
      " Trial 77 | Epoch 3/10 | Train Loss: 0.6614 | Train F1: 0.3092 | Val Loss: 0.7183 | Val F1: 0.2755\n",
      " Trial 77 | Epoch 4/10 | Train Loss: 0.6367 | Train F1: 0.3568 | Val Loss: 0.7084 | Val F1: 0.2718\n",
      "Trial 77 Pruned at Epoch 4\n",
      "[I 2025-12-13 13:02:50,812] Trial 77 pruned. \n",
      " Trial 78 | Epoch 1/10 | Train Loss: 0.5872 | Train F1: 0.2606 | Val Loss: 0.6112 | Val F1: 0.2269\n",
      " Trial 78 | Epoch 2/10 | Train Loss: 0.5328 | Train F1: 0.3855 | Val Loss: 0.6179 | Val F1: 0.3300\n",
      " Trial 78 | Epoch 3/10 | Train Loss: 0.5012 | Train F1: 0.4311 | Val Loss: 0.6101 | Val F1: 0.2967\n",
      " Trial 78 | Epoch 4/10 | Train Loss: 0.4769 | Train F1: 0.4473 | Val Loss: 0.6067 | Val F1: 0.3698\n",
      " Trial 78 | Epoch 5/10 | Train Loss: 0.4616 | Train F1: 0.4760 | Val Loss: 0.6339 | Val F1: 0.3763\n",
      " Trial 78 | Epoch 6/10 | Train Loss: 0.4528 | Train F1: 0.4920 | Val Loss: 0.5977 | Val F1: 0.3951\n",
      " Trial 78 | Epoch 7/10 | Train Loss: 0.4408 | Train F1: 0.4997 | Val Loss: 0.5951 | Val F1: 0.3980\n",
      " Trial 78 | Epoch 8/10 | Train Loss: 0.4287 | Train F1: 0.5298 | Val Loss: 0.6168 | Val F1: 0.3686\n",
      " Trial 78 | Epoch 9/10 | Train Loss: 0.4238 | Train F1: 0.5306 | Val Loss: 0.6296 | Val F1: 0.3503\n",
      " Trial 78 | Epoch 10/10 | Train Loss: 0.4184 | Train F1: 0.5297 | Val Loss: 0.5932 | Val F1: 0.3351\n",
      "[I 2025-12-13 13:03:30,312] Trial 78 finished with value: 0.3980204157096009 and parameters: {'lr': 0.0007828373606837546, 'batch_size': 64, 'optimizer': 'AdamW', 'l2_reg': 0.00016698529078534223, 'dropout_rate': 0.33638630721973906, 'head_type': 'original', 'head_hidden_dim': 1024, 'loss_config': 'focal_g2_weighted', 'w1': 0.6969496779071767, 'w2': 0.7834895702400683, 'w3': 0.7508735199471388, 'w4': 1.3015671894753305}. Best is trial 36 with value: 0.44862375808471944.\n",
      " Trial 79 | Epoch 1/10 | Train Loss: 0.6957 | Train F1: 0.2513 | Val Loss: 0.7241 | Val F1: 0.2660\n",
      " Trial 79 | Epoch 2/10 | Train Loss: 0.6362 | Train F1: 0.3336 | Val Loss: 0.7269 | Val F1: 0.2450\n",
      " Trial 79 | Epoch 3/10 | Train Loss: 0.6191 | Train F1: 0.3867 | Val Loss: 0.7090 | Val F1: 0.3186\n",
      " Trial 79 | Epoch 4/10 | Train Loss: 0.5830 | Train F1: 0.4417 | Val Loss: 0.6964 | Val F1: 0.3519\n",
      " Trial 79 | Epoch 5/10 | Train Loss: 0.5686 | Train F1: 0.4535 | Val Loss: 0.7150 | Val F1: 0.3596\n",
      "Trial 79 Pruned at Epoch 5\n",
      "[I 2025-12-13 13:03:49,825] Trial 79 pruned. \n",
      " Trial 80 | Epoch 1/10 | Train Loss: 0.6856 | Train F1: 0.2729 | Val Loss: 0.7016 | Val F1: 0.2711\n",
      " Trial 80 | Epoch 2/10 | Train Loss: 0.6315 | Train F1: 0.3591 | Val Loss: 0.7050 | Val F1: 0.2949\n",
      " Trial 80 | Epoch 3/10 | Train Loss: 0.6042 | Train F1: 0.4363 | Val Loss: 0.6898 | Val F1: 0.3032\n",
      " Trial 80 | Epoch 4/10 | Train Loss: 0.5672 | Train F1: 0.4467 | Val Loss: 0.6834 | Val F1: 0.3617\n",
      " Trial 80 | Epoch 5/10 | Train Loss: 0.5420 | Train F1: 0.4822 | Val Loss: 0.7068 | Val F1: 0.3837\n",
      " Trial 80 | Epoch 6/10 | Train Loss: 0.5420 | Train F1: 0.4930 | Val Loss: 0.7164 | Val F1: 0.3903\n",
      " Trial 80 | Epoch 7/10 | Train Loss: 0.5215 | Train F1: 0.5424 | Val Loss: 0.7931 | Val F1: 0.3208\n",
      " Trial 80 | Epoch 8/10 | Train Loss: 0.5258 | Train F1: 0.5188 | Val Loss: 0.6887 | Val F1: 0.4174\n",
      " Trial 80 | Epoch 9/10 | Train Loss: 0.5104 | Train F1: 0.5075 | Val Loss: 0.7031 | Val F1: 0.3116\n",
      " Trial 80 | Epoch 10/10 | Train Loss: 0.5262 | Train F1: 0.5037 | Val Loss: 0.6760 | Val F1: 0.4374\n",
      "[I 2025-12-13 13:04:29,080] Trial 80 finished with value: 0.4373838815528197 and parameters: {'lr': 0.0009359430414297347, 'batch_size': 64, 'optimizer': 'AdamW', 'l2_reg': 0.00037814900064221197, 'dropout_rate': 0.3566818294894082, 'head_type': 'original', 'head_hidden_dim': 1024, 'loss_config': 'focal_g2_no_weight'}. Best is trial 36 with value: 0.44862375808471944.\n",
      " Trial 81 | Epoch 1/10 | Train Loss: 0.6905 | Train F1: 0.2442 | Val Loss: 0.7445 | Val F1: 0.1958\n",
      " Trial 81 | Epoch 2/10 | Train Loss: 0.6395 | Train F1: 0.3396 | Val Loss: 0.7083 | Val F1: 0.3326\n",
      " Trial 81 | Epoch 3/10 | Train Loss: 0.6100 | Train F1: 0.4182 | Val Loss: 0.7195 | Val F1: 0.3069\n",
      " Trial 81 | Epoch 4/10 | Train Loss: 0.5758 | Train F1: 0.4639 | Val Loss: 0.7075 | Val F1: 0.3557\n",
      " Trial 81 | Epoch 5/10 | Train Loss: 0.5588 | Train F1: 0.4622 | Val Loss: 0.6755 | Val F1: 0.3870\n",
      " Trial 81 | Epoch 6/10 | Train Loss: 0.5400 | Train F1: 0.5033 | Val Loss: 0.6722 | Val F1: 0.4024\n",
      " Trial 81 | Epoch 7/10 | Train Loss: 0.5257 | Train F1: 0.5086 | Val Loss: 0.7353 | Val F1: 0.3300\n",
      " Trial 81 | Epoch 8/10 | Train Loss: 0.5301 | Train F1: 0.5179 | Val Loss: 0.6674 | Val F1: 0.3811\n",
      " Trial 81 | Epoch 9/10 | Train Loss: 0.5029 | Train F1: 0.5349 | Val Loss: 0.6738 | Val F1: 0.4291\n",
      " Trial 81 | Epoch 10/10 | Train Loss: 0.4845 | Train F1: 0.5491 | Val Loss: 0.6893 | Val F1: 0.4197\n",
      "[I 2025-12-13 13:05:07,683] Trial 81 finished with value: 0.42906854522630966 and parameters: {'lr': 0.0009298924266598946, 'batch_size': 64, 'optimizer': 'AdamW', 'l2_reg': 0.00035490639826963905, 'dropout_rate': 0.3550390343009515, 'head_type': 'original', 'head_hidden_dim': 1024, 'loss_config': 'focal_g2_no_weight'}. Best is trial 36 with value: 0.44862375808471944.\n",
      " Trial 82 | Epoch 1/10 | Train Loss: 0.6934 | Train F1: 0.2656 | Val Loss: 0.7345 | Val F1: 0.2556\n",
      " Trial 82 | Epoch 2/10 | Train Loss: 0.6252 | Train F1: 0.3665 | Val Loss: 0.7013 | Val F1: 0.2940\n",
      " Trial 82 | Epoch 3/10 | Train Loss: 0.6106 | Train F1: 0.3989 | Val Loss: 0.6871 | Val F1: 0.3361\n",
      " Trial 82 | Epoch 4/10 | Train Loss: 0.5754 | Train F1: 0.4602 | Val Loss: 0.7488 | Val F1: 0.2724\n",
      "Trial 82 Pruned at Epoch 4\n",
      "[I 2025-12-13 13:05:23,241] Trial 82 pruned. \n",
      " Trial 83 | Epoch 1/10 | Train Loss: 0.6953 | Train F1: 0.2419 | Val Loss: 0.7171 | Val F1: 0.2398\n",
      " Trial 83 | Epoch 2/10 | Train Loss: 0.6329 | Train F1: 0.3677 | Val Loss: 0.7008 | Val F1: 0.3365\n",
      " Trial 83 | Epoch 3/10 | Train Loss: 0.5985 | Train F1: 0.4181 | Val Loss: 0.7326 | Val F1: 0.2959\n",
      " Trial 83 | Epoch 4/10 | Train Loss: 0.5688 | Train F1: 0.4538 | Val Loss: 0.6936 | Val F1: 0.3781\n",
      " Trial 83 | Epoch 5/10 | Train Loss: 0.5555 | Train F1: 0.4694 | Val Loss: 0.6777 | Val F1: 0.3752\n",
      " Trial 83 | Epoch 6/10 | Train Loss: 0.5303 | Train F1: 0.5052 | Val Loss: 0.6729 | Val F1: 0.4103\n",
      " Trial 83 | Epoch 7/10 | Train Loss: 0.5176 | Train F1: 0.5317 | Val Loss: 0.6780 | Val F1: 0.4102\n",
      " Trial 83 | Epoch 8/10 | Train Loss: 0.5106 | Train F1: 0.5324 | Val Loss: 0.7089 | Val F1: 0.4278\n",
      " Trial 83 | Epoch 9/10 | Train Loss: 0.5054 | Train F1: 0.5301 | Val Loss: 0.6680 | Val F1: 0.4031\n",
      " Trial 83 | Epoch 10/10 | Train Loss: 0.4962 | Train F1: 0.5380 | Val Loss: 0.6980 | Val F1: 0.4373\n",
      "[I 2025-12-13 13:06:01,887] Trial 83 finished with value: 0.4373050797289451 and parameters: {'lr': 0.0009965348106863697, 'batch_size': 64, 'optimizer': 'AdamW', 'l2_reg': 0.00037401324802901727, 'dropout_rate': 0.3391923202816951, 'head_type': 'original', 'head_hidden_dim': 1024, 'loss_config': 'focal_g2_no_weight'}. Best is trial 36 with value: 0.44862375808471944.\n",
      " Trial 84 | Epoch 1/10 | Train Loss: 0.6921 | Train F1: 0.2653 | Val Loss: 0.7153 | Val F1: 0.2652\n",
      " Trial 84 | Epoch 2/10 | Train Loss: 0.6256 | Train F1: 0.3727 | Val Loss: 0.6892 | Val F1: 0.3178\n",
      " Trial 84 | Epoch 3/10 | Train Loss: 0.5912 | Train F1: 0.4305 | Val Loss: 0.7180 | Val F1: 0.3208\n",
      " Trial 84 | Epoch 4/10 | Train Loss: 0.5661 | Train F1: 0.4504 | Val Loss: 0.6739 | Val F1: 0.3618\n",
      " Trial 84 | Epoch 5/10 | Train Loss: 0.5446 | Train F1: 0.4759 | Val Loss: 0.6955 | Val F1: 0.3861\n",
      " Trial 84 | Epoch 6/10 | Train Loss: 0.5335 | Train F1: 0.5034 | Val Loss: 0.6872 | Val F1: 0.3775\n",
      " Trial 84 | Epoch 7/10 | Train Loss: 0.5207 | Train F1: 0.5235 | Val Loss: 0.7008 | Val F1: 0.3726\n",
      " Trial 84 | Epoch 8/10 | Train Loss: 0.5177 | Train F1: 0.5109 | Val Loss: 0.6997 | Val F1: 0.3774\n",
      " Trial 84 | Epoch 9/10 | Train Loss: 0.5234 | Train F1: 0.5146 | Val Loss: 0.6932 | Val F1: 0.4101\n",
      " Trial 84 | Epoch 10/10 | Train Loss: 0.4990 | Train F1: 0.5496 | Val Loss: 0.6967 | Val F1: 0.3762\n",
      "[I 2025-12-13 13:06:40,739] Trial 84 finished with value: 0.41009303835869515 and parameters: {'lr': 0.0009600490809172297, 'batch_size': 64, 'optimizer': 'AdamW', 'l2_reg': 0.00038261034175972477, 'dropout_rate': 0.34179251818901146, 'head_type': 'original', 'head_hidden_dim': 1024, 'loss_config': 'focal_g2_no_weight'}. Best is trial 36 with value: 0.44862375808471944.\n",
      " Trial 85 | Epoch 1/10 | Train Loss: 0.6985 | Train F1: 0.2630 | Val Loss: 0.7139 | Val F1: 0.2947\n",
      " Trial 85 | Epoch 2/10 | Train Loss: 0.6320 | Train F1: 0.3438 | Val Loss: 0.7098 | Val F1: 0.3062\n",
      " Trial 85 | Epoch 3/10 | Train Loss: 0.5924 | Train F1: 0.4286 | Val Loss: 0.7309 | Val F1: 0.2697\n",
      " Trial 85 | Epoch 4/10 | Train Loss: 0.5880 | Train F1: 0.4533 | Val Loss: 0.7024 | Val F1: 0.3346\n",
      "Trial 85 Pruned at Epoch 4\n",
      "[I 2025-12-13 13:06:58,130] Trial 85 pruned. \n",
      " Trial 86 | Epoch 1/10 | Train Loss: 0.7200 | Train F1: 0.2148 | Val Loss: 0.7613 | Val F1: 0.1337\n",
      " Trial 86 | Epoch 2/10 | Train Loss: 0.6690 | Train F1: 0.2805 | Val Loss: 0.7216 | Val F1: 0.2975\n",
      " Trial 86 | Epoch 3/10 | Train Loss: 0.6346 | Train F1: 0.3328 | Val Loss: 0.7111 | Val F1: 0.2684\n",
      " Trial 86 | Epoch 4/10 | Train Loss: 0.6054 | Train F1: 0.3770 | Val Loss: 0.6955 | Val F1: 0.3074\n",
      "Trial 86 Pruned at Epoch 4\n",
      "[I 2025-12-13 13:07:15,864] Trial 86 pruned. \n",
      " Trial 87 | Epoch 1/10 | Train Loss: 0.6973 | Train F1: 0.2645 | Val Loss: 0.7144 | Val F1: 0.2743\n",
      " Trial 87 | Epoch 2/10 | Train Loss: 0.6269 | Train F1: 0.3425 | Val Loss: 0.7216 | Val F1: 0.3087\n",
      " Trial 87 | Epoch 3/10 | Train Loss: 0.6041 | Train F1: 0.4167 | Val Loss: 0.7182 | Val F1: 0.2557\n",
      " Trial 87 | Epoch 4/10 | Train Loss: 0.5724 | Train F1: 0.4496 | Val Loss: 0.6699 | Val F1: 0.3790\n",
      " Trial 87 | Epoch 5/10 | Train Loss: 0.5498 | Train F1: 0.4853 | Val Loss: 0.7107 | Val F1: 0.3104\n",
      " Trial 87 | Epoch 6/10 | Train Loss: 0.5480 | Train F1: 0.4797 | Val Loss: 0.6954 | Val F1: 0.4020\n",
      " Trial 87 | Epoch 7/10 | Train Loss: 0.5433 | Train F1: 0.4872 | Val Loss: 0.7018 | Val F1: 0.4098\n",
      " Trial 87 | Epoch 8/10 | Train Loss: 0.5111 | Train F1: 0.5403 | Val Loss: 0.7312 | Val F1: 0.3922\n",
      " Trial 87 | Epoch 9/10 | Train Loss: 0.5166 | Train F1: 0.5245 | Val Loss: 0.6883 | Val F1: 0.4072\n",
      " Trial 87 | Epoch 10/10 | Train Loss: 0.4769 | Train F1: 0.5603 | Val Loss: 0.7289 | Val F1: 0.4334\n",
      "[I 2025-12-13 13:07:58,132] Trial 87 finished with value: 0.4333602864636095 and parameters: {'lr': 0.000991930667528894, 'batch_size': 64, 'optimizer': 'AdamW', 'l2_reg': 0.00028738873957514886, 'dropout_rate': 0.34185324990811206, 'head_type': 'original', 'head_hidden_dim': 512, 'loss_config': 'focal_g2_no_weight'}. Best is trial 36 with value: 0.44862375808471944.\n",
      " Trial 88 | Epoch 1/10 | Train Loss: 0.7263 | Train F1: 0.2544 | Val Loss: 0.7519 | Val F1: 0.1337\n",
      " Trial 88 | Epoch 2/10 | Train Loss: 0.6806 | Train F1: 0.2207 | Val Loss: 0.7398 | Val F1: 0.2830\n",
      " Trial 88 | Epoch 3/10 | Train Loss: 0.6501 | Train F1: 0.3227 | Val Loss: 0.7097 | Val F1: 0.2846\n",
      " Trial 88 | Epoch 4/10 | Train Loss: 0.6282 | Train F1: 0.3443 | Val Loss: 0.7043 | Val F1: 0.2877\n",
      "Trial 88 Pruned at Epoch 4\n",
      "[I 2025-12-13 13:08:14,338] Trial 88 pruned. \n",
      " Trial 89 | Epoch 1/10 | Train Loss: 1.3332 | Train F1: 0.2801 | Val Loss: 1.3535 | Val F1: 0.2825\n",
      " Trial 89 | Epoch 2/10 | Train Loss: 1.2704 | Train F1: 0.3649 | Val Loss: 1.3289 | Val F1: 0.3306\n",
      " Trial 89 | Epoch 3/10 | Train Loss: 1.2416 | Train F1: 0.4395 | Val Loss: 1.3274 | Val F1: 0.3761\n",
      " Trial 89 | Epoch 4/10 | Train Loss: 1.2033 | Train F1: 0.4723 | Val Loss: 1.3275 | Val F1: 0.3788\n",
      " Trial 89 | Epoch 5/10 | Train Loss: 1.1756 | Train F1: 0.5029 | Val Loss: 1.4489 | Val F1: 0.3291\n",
      " Trial 89 | Epoch 6/10 | Train Loss: 1.1592 | Train F1: 0.5158 | Val Loss: 1.3711 | Val F1: 0.3817\n",
      " Trial 89 | Epoch 7/10 | Train Loss: 1.1394 | Train F1: 0.5366 | Val Loss: 1.3585 | Val F1: 0.3711\n",
      " Trial 89 | Epoch 8/10 | Train Loss: 1.1279 | Train F1: 0.5374 | Val Loss: 1.3630 | Val F1: 0.4016\n",
      " Trial 89 | Epoch 9/10 | Train Loss: 1.1246 | Train F1: 0.5604 | Val Loss: 1.3685 | Val F1: 0.4126\n",
      " Trial 89 | Epoch 10/10 | Train Loss: 1.1000 | Train F1: 0.5587 | Val Loss: 1.3882 | Val F1: 0.3783\n",
      "[I 2025-12-13 13:08:55,180] Trial 89 finished with value: 0.4126291855298743 and parameters: {'lr': 0.0009855805954485976, 'batch_size': 64, 'optimizer': 'AdamW', 'l2_reg': 0.0002921330004504819, 'dropout_rate': 0.33720678662037423, 'head_type': 'original', 'head_hidden_dim': 512, 'loss_config': 'ce_weighted_smooth', 'w1': 0.953803198780401, 'w2': 0.87307032757875, 'w3': 0.8738931972673356, 'w4': 1.2075355115792512}. Best is trial 36 with value: 0.44862375808471944.\n",
      " Trial 90 | Epoch 1/10 | Train Loss: 0.7588 | Train F1: 0.1978 | Val Loss: 0.7439 | Val F1: 0.1337\n",
      " Trial 90 | Epoch 2/10 | Train Loss: 0.7002 | Train F1: 0.1441 | Val Loss: 0.7436 | Val F1: 0.1596\n",
      " Trial 90 | Epoch 3/10 | Train Loss: 0.6749 | Train F1: 0.2379 | Val Loss: 0.7306 | Val F1: 0.2717\n",
      " Trial 90 | Epoch 4/10 | Train Loss: 0.6541 | Train F1: 0.3286 | Val Loss: 0.7204 | Val F1: 0.2806\n",
      "Trial 90 Pruned at Epoch 4\n",
      "[I 2025-12-13 13:09:11,445] Trial 90 pruned. \n",
      " Trial 91 | Epoch 1/10 | Train Loss: 0.6850 | Train F1: 0.2573 | Val Loss: 0.7084 | Val F1: 0.2816\n",
      " Trial 91 | Epoch 2/10 | Train Loss: 0.6344 | Train F1: 0.3666 | Val Loss: 0.7247 | Val F1: 0.2632\n",
      " Trial 91 | Epoch 3/10 | Train Loss: 0.5956 | Train F1: 0.4142 | Val Loss: 0.6856 | Val F1: 0.3118\n",
      " Trial 91 | Epoch 4/10 | Train Loss: 0.5644 | Train F1: 0.4573 | Val Loss: 0.7349 | Val F1: 0.2952\n",
      "Trial 91 Pruned at Epoch 4\n",
      "[I 2025-12-13 13:09:27,799] Trial 91 pruned. \n",
      " Trial 92 | Epoch 1/10 | Train Loss: 0.6948 | Train F1: 0.2510 | Val Loss: 0.7288 | Val F1: 0.2233\n",
      " Trial 92 | Epoch 2/10 | Train Loss: 0.6338 | Train F1: 0.3564 | Val Loss: 0.7155 | Val F1: 0.2997\n",
      " Trial 92 | Epoch 3/10 | Train Loss: 0.5962 | Train F1: 0.4240 | Val Loss: 0.7025 | Val F1: 0.3258\n",
      " Trial 92 | Epoch 4/10 | Train Loss: 0.5715 | Train F1: 0.4581 | Val Loss: 0.6834 | Val F1: 0.3889\n",
      " Trial 92 | Epoch 5/10 | Train Loss: 0.5476 | Train F1: 0.4830 | Val Loss: 0.6647 | Val F1: 0.3992\n",
      " Trial 92 | Epoch 6/10 | Train Loss: 0.5401 | Train F1: 0.4911 | Val Loss: 0.7047 | Val F1: 0.3772\n",
      " Trial 92 | Epoch 7/10 | Train Loss: 0.5427 | Train F1: 0.4798 | Val Loss: 0.7142 | Val F1: 0.3343\n",
      " Trial 92 | Epoch 8/10 | Train Loss: 0.5137 | Train F1: 0.5336 | Val Loss: 0.7112 | Val F1: 0.3925\n",
      " Trial 92 | Epoch 9/10 | Train Loss: 0.5097 | Train F1: 0.5310 | Val Loss: 0.7040 | Val F1: 0.4107\n",
      " Trial 92 | Epoch 10/10 | Train Loss: 0.5062 | Train F1: 0.5331 | Val Loss: 0.7312 | Val F1: 0.3317\n",
      "[I 2025-12-13 13:10:08,456] Trial 92 finished with value: 0.4107238864546118 and parameters: {'lr': 0.0009327917742103535, 'batch_size': 64, 'optimizer': 'AdamW', 'l2_reg': 0.0007303360257807439, 'dropout_rate': 0.34404803196967887, 'head_type': 'original', 'head_hidden_dim': 512, 'loss_config': 'focal_g2_no_weight'}. Best is trial 36 with value: 0.44862375808471944.\n",
      " Trial 93 | Epoch 1/10 | Train Loss: 0.6968 | Train F1: 0.2583 | Val Loss: 0.7352 | Val F1: 0.2689\n",
      " Trial 93 | Epoch 2/10 | Train Loss: 0.6311 | Train F1: 0.3483 | Val Loss: 0.7228 | Val F1: 0.2786\n",
      " Trial 93 | Epoch 3/10 | Train Loss: 0.5931 | Train F1: 0.4210 | Val Loss: 0.7821 | Val F1: 0.2921\n",
      " Trial 93 | Epoch 4/10 | Train Loss: 0.5791 | Train F1: 0.4448 | Val Loss: 0.6987 | Val F1: 0.3448\n",
      "Trial 93 Pruned at Epoch 4\n",
      "[I 2025-12-13 13:10:24,794] Trial 93 pruned. \n",
      " Trial 94 | Epoch 1/10 | Train Loss: 1.2906 | Train F1: 0.2516 | Val Loss: 1.3139 | Val F1: 0.2685\n",
      " Trial 94 | Epoch 2/10 | Train Loss: 1.1984 | Train F1: 0.3420 | Val Loss: 1.3065 | Val F1: 0.2757\n",
      " Trial 94 | Epoch 3/10 | Train Loss: 1.1597 | Train F1: 0.4090 | Val Loss: 1.2952 | Val F1: 0.3611\n",
      " Trial 94 | Epoch 4/10 | Train Loss: 1.1227 | Train F1: 0.4563 | Val Loss: 1.3326 | Val F1: 0.2997\n",
      " Trial 94 | Epoch 5/10 | Train Loss: 1.0918 | Train F1: 0.4885 | Val Loss: 1.3311 | Val F1: 0.3027\n",
      "Trial 94 Pruned at Epoch 5\n",
      "[I 2025-12-13 13:10:45,229] Trial 94 pruned. \n",
      " Trial 95 | Epoch 1/10 | Train Loss: 1.3249 | Train F1: 0.2295 | Val Loss: 1.3477 | Val F1: 0.2421\n",
      " Trial 95 | Epoch 2/10 | Train Loss: 1.2405 | Train F1: 0.3710 | Val Loss: 1.3585 | Val F1: 0.2524\n",
      " Trial 95 | Epoch 3/10 | Train Loss: 1.1822 | Train F1: 0.4403 | Val Loss: 1.3070 | Val F1: 0.3769\n",
      " Trial 95 | Epoch 4/10 | Train Loss: 1.1410 | Train F1: 0.4702 | Val Loss: 1.3497 | Val F1: 0.3672\n",
      " Trial 95 | Epoch 5/10 | Train Loss: 1.1197 | Train F1: 0.5052 | Val Loss: 1.3030 | Val F1: 0.3727\n",
      " Trial 95 | Epoch 6/10 | Train Loss: 1.0940 | Train F1: 0.4942 | Val Loss: 1.2937 | Val F1: 0.3849\n",
      " Trial 95 | Epoch 7/10 | Train Loss: 1.0775 | Train F1: 0.5194 | Val Loss: 1.2885 | Val F1: 0.3989\n",
      " Trial 95 | Epoch 8/10 | Train Loss: 1.0421 | Train F1: 0.5335 | Val Loss: 1.3145 | Val F1: 0.3955\n",
      " Trial 95 | Epoch 9/10 | Train Loss: 1.0279 | Train F1: 0.5397 | Val Loss: 1.3158 | Val F1: 0.4057\n",
      " Trial 95 | Epoch 10/10 | Train Loss: 1.0591 | Train F1: 0.5265 | Val Loss: 1.3747 | Val F1: 0.3781\n",
      "[I 2025-12-13 13:11:25,352] Trial 95 finished with value: 0.4057077487997942 and parameters: {'lr': 0.0008646795484025083, 'batch_size': 64, 'optimizer': 'AdamW', 'l2_reg': 0.00016920293529876056, 'dropout_rate': 0.3397995395841233, 'head_type': 'original', 'head_hidden_dim': 1024, 'loss_config': 'ce_weighted', 'w1': 0.8826766739878736, 'w2': 0.6106730038740856, 'w3': 0.6852569306228374, 'w4': 1.155349178816528}. Best is trial 36 with value: 0.44862375808471944.\n",
      " Trial 96 | Epoch 1/10 | Train Loss: 0.7126 | Train F1: 0.1559 | Val Loss: 0.7464 | Val F1: 0.2639\n",
      " Trial 96 | Epoch 2/10 | Train Loss: 0.6753 | Train F1: 0.3140 | Val Loss: 0.7322 | Val F1: 0.2628\n",
      " Trial 96 | Epoch 3/10 | Train Loss: 0.6582 | Train F1: 0.3161 | Val Loss: 0.7234 | Val F1: 0.2642\n",
      " Trial 96 | Epoch 4/10 | Train Loss: 0.6453 | Train F1: 0.3346 | Val Loss: 0.7164 | Val F1: 0.2649\n",
      "Trial 96 Pruned at Epoch 4\n",
      "[I 2025-12-13 13:11:41,512] Trial 96 pruned. \n",
      " Trial 97 | Epoch 1/10 | Train Loss: 0.2267 | Train F1: 0.2855 | Val Loss: 0.2361 | Val F1: 0.3244\n",
      " Trial 97 | Epoch 2/10 | Train Loss: 0.2096 | Train F1: 0.3835 | Val Loss: 0.2288 | Val F1: 0.3341\n",
      " Trial 97 | Epoch 3/10 | Train Loss: 0.1907 | Train F1: 0.4329 | Val Loss: 0.2335 | Val F1: 0.3719\n",
      " Trial 97 | Epoch 4/10 | Train Loss: 0.1802 | Train F1: 0.4763 | Val Loss: 0.2485 | Val F1: 0.3796\n",
      " Trial 97 | Epoch 5/10 | Train Loss: 0.1730 | Train F1: 0.4827 | Val Loss: 0.2306 | Val F1: 0.3807\n",
      " Trial 97 | Epoch 6/10 | Train Loss: 0.1670 | Train F1: 0.4929 | Val Loss: 0.2322 | Val F1: 0.3968\n",
      " Trial 97 | Epoch 7/10 | Train Loss: 0.1700 | Train F1: 0.4798 | Val Loss: 0.2450 | Val F1: 0.3646\n",
      " Trial 97 | Epoch 8/10 | Train Loss: 0.1667 | Train F1: 0.4890 | Val Loss: 0.2442 | Val F1: 0.4115\n",
      " Trial 97 | Epoch 9/10 | Train Loss: 0.1633 | Train F1: 0.5098 | Val Loss: 0.2249 | Val F1: 0.3859\n",
      " Trial 97 | Epoch 10/10 | Train Loss: 0.1506 | Train F1: 0.5234 | Val Loss: 0.2606 | Val F1: 0.3504\n",
      "[I 2025-12-13 13:12:22,400] Trial 97 finished with value: 0.4115134040951411 and parameters: {'lr': 0.0007444428413973669, 'batch_size': 64, 'optimizer': 'AdamW', 'l2_reg': 0.0004904129179101877, 'dropout_rate': 0.34818504679270335, 'head_type': 'original', 'head_hidden_dim': 1024, 'loss_config': 'focal_g5_weighted', 'w1': 0.7503589933417762, 'w2': 0.7102186472862059, 'w3': 0.5840688923306541, 'w4': 1.309486238903956}. Best is trial 36 with value: 0.44862375808471944.\n",
      " Trial 98 | Epoch 1/10 | Train Loss: 0.6977 | Train F1: 0.2613 | Val Loss: 0.7152 | Val F1: 0.2791\n",
      " Trial 98 | Epoch 2/10 | Train Loss: 0.6299 | Train F1: 0.3497 | Val Loss: 0.7277 | Val F1: 0.3005\n",
      " Trial 98 | Epoch 3/10 | Train Loss: 0.5944 | Train F1: 0.4248 | Val Loss: 0.7269 | Val F1: 0.2619\n",
      " Trial 98 | Epoch 4/10 | Train Loss: 0.5732 | Train F1: 0.4608 | Val Loss: 0.7224 | Val F1: 0.3382\n",
      "Trial 98 Pruned at Epoch 4\n",
      "[I 2025-12-13 13:12:38,461] Trial 98 pruned. \n",
      " Trial 99 | Epoch 1/10 | Train Loss: 0.6933 | Train F1: 0.2573 | Val Loss: 0.7261 | Val F1: 0.2544\n",
      " Trial 99 | Epoch 2/10 | Train Loss: 0.6297 | Train F1: 0.3379 | Val Loss: 0.7020 | Val F1: 0.3096\n",
      " Trial 99 | Epoch 3/10 | Train Loss: 0.6036 | Train F1: 0.3991 | Val Loss: 0.6924 | Val F1: 0.3166\n",
      " Trial 99 | Epoch 4/10 | Train Loss: 0.5804 | Train F1: 0.4547 | Val Loss: 0.6808 | Val F1: 0.3329\n",
      "Trial 99 Pruned at Epoch 4\n",
      "[I 2025-12-13 13:12:54,068] Trial 99 pruned. \n",
      "Best Params: {'lr': 0.0008367433034670895, 'batch_size': 64, 'optimizer': 'AdamW', 'l2_reg': 0.00023922618482545056, 'dropout_rate': 0.39563913357721187, 'head_type': 'original', 'head_hidden_dim': 1024, 'loss_config': 'focal_g2_no_weight'}\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Run the Expanded Study ---\n",
    "sampler = TPESampler(seed=42)\n",
    "pruner = optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=3)\n",
    "\n",
    "study = optuna.create_study(\n",
    "    study_name=\"retccl_head_search\", \n",
    "    direction=\"maximize\", \n",
    "    sampler=sampler, \n",
    "    pruner=pruner\n",
    ")\n",
    "N_TRIALS = 100\n",
    "print(f\"Starting TPE Search with {N_TRIALS} trials...\") # Fixed print statement\n",
    "\n",
    "# Ensure n_trials is sufficient for TPE to converge (100 is a good start)\n",
    "study.optimize(objective, n_trials=N_TRIALS, show_progress_bar=True, n_jobs=1) \n",
    "\n",
    "print(\"Best Params:\", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10f73ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Study Statistics\n",
      "==================================================\n",
      "Number of finished trials: 100\n",
      "Best F1 Score: 0.4486\n",
      "Best Hyperparameters:\n",
      "  lr: 0.0008367433034670895\n",
      "  batch_size: 64\n",
      "  optimizer: AdamW\n",
      "  l2_reg: 0.00023922618482545056\n",
      "  dropout_rate: 0.39563913357721187\n",
      "  head_type: original\n",
      "  head_hidden_dim: 1024\n",
      "  loss_config: focal_g2_no_weight\n"
     ]
    }
   ],
   "source": [
    "# --- Display Results ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Study Statistics\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Number of finished trials: {len(study.trials)}\")\n",
    "print(f\"Best F1 Score: {study.best_value:.4f}\")\n",
    "print(\"Best Hyperparameters:\")\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b62a5b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "name": "Objective Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          9,
          11,
          12,
          13,
          17,
          20,
          22,
          23,
          25,
          31,
          32,
          33,
          36,
          38,
          40,
          42,
          45,
          46,
          49,
          51,
          52,
          53,
          54,
          57,
          63,
          66,
          70,
          71,
          72,
          73,
          74,
          75,
          78,
          80,
          81,
          83,
          84,
          87,
          89,
          92,
          95,
          97
         ],
         "y": [
          0.40124035760828214,
          0.23153577306119677,
          0.2835318912308744,
          0.3418246950649823,
          0.2655309148682643,
          0.3438856748924979,
          0.37037836240201083,
          0.3816731357485135,
          0.3934442454633423,
          0.3904884389007476,
          0.37583884906731146,
          0.3962182085751677,
          0.42733525497261327,
          0.43010175589593114,
          0.41527063937456604,
          0.38604365741796914,
          0.3833417260835231,
          0.4156745248127839,
          0.4281428015274605,
          0.44862375808471944,
          0.40683128700192456,
          0.416634482365978,
          0.42828031515197484,
          0.4313205407640663,
          0.3980784108839932,
          0.4090983571625766,
          0.3894017576047503,
          0.38855884534918794,
          0.4019356262824868,
          0.41595871349556,
          0.397823850983603,
          0.39588816390563775,
          0.41356533116447847,
          0.4276640435785529,
          0.40439928458518914,
          0.4304659185213488,
          0.43526683128661803,
          0.43592104834582523,
          0.4066084922438244,
          0.3980204157096009,
          0.4373838815528197,
          0.42906854522630966,
          0.4373050797289451,
          0.41009303835869515,
          0.4333602864636095,
          0.4126291855298743,
          0.4107238864546118,
          0.4057077487997942,
          0.4115134040951411
         ]
        },
        {
         "mode": "lines",
         "name": "Best Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99
         ],
         "y": [
          0.40124035760828214,
          0.40124035760828214,
          0.40124035760828214,
          0.40124035760828214,
          0.40124035760828214,
          0.40124035760828214,
          0.40124035760828214,
          0.40124035760828214,
          0.40124035760828214,
          0.40124035760828214,
          0.40124035760828214,
          0.40124035760828214,
          0.40124035760828214,
          0.40124035760828214,
          0.40124035760828214,
          0.40124035760828214,
          0.40124035760828214,
          0.40124035760828214,
          0.40124035760828214,
          0.40124035760828214,
          0.42733525497261327,
          0.42733525497261327,
          0.43010175589593114,
          0.43010175589593114,
          0.43010175589593114,
          0.43010175589593114,
          0.43010175589593114,
          0.43010175589593114,
          0.43010175589593114,
          0.43010175589593114,
          0.43010175589593114,
          0.43010175589593114,
          0.43010175589593114,
          0.43010175589593114,
          0.43010175589593114,
          0.43010175589593114,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944,
          0.44862375808471944
         ]
        },
        {
         "marker": {
          "color": "#cccccc"
         },
         "mode": "markers",
         "name": "Infeasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [],
         "y": []
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Optimization History Plot"
        },
        "xaxis": {
         "title": {
          "text": "Trial"
         }
        },
        "yaxis": {
         "title": {
          "text": "Objective Value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "cliponaxis": false,
         "hovertemplate": [
          "batch_size (CategoricalDistribution): 0.0<extra></extra>",
          "dropout_rate (FloatDistribution): 0.018022556623066777<extra></extra>",
          "l2_reg (FloatDistribution): 0.018186808835259836<extra></extra>",
          "head_hidden_dim (CategoricalDistribution): 0.030072400848925485<extra></extra>",
          "loss_config (CategoricalDistribution): 0.08394180119916306<extra></extra>",
          "lr (FloatDistribution): 0.12260443112349155<extra></extra>",
          "optimizer (CategoricalDistribution): 0.3132239354726698<extra></extra>",
          "head_type (CategoricalDistribution): 0.4139480658974236<extra></extra>"
         ],
         "name": "Objective Value",
         "orientation": "h",
         "text": [
          "<0.01",
          "0.02",
          "0.02",
          "0.03",
          "0.08",
          "0.12",
          "0.31",
          "0.41"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          0,
          0.018022556623066777,
          0.018186808835259836,
          0.030072400848925485,
          0.08394180119916306,
          0.12260443112349155,
          0.3132239354726698,
          0.4139480658974236
         ],
         "y": [
          "batch_size",
          "dropout_rate",
          "l2_reg",
          "head_hidden_dim",
          "loss_config",
          "lr",
          "optimizer",
          "head_type"
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Hyperparameter Importances"
        },
        "xaxis": {
         "title": {
          "text": "Hyperparameter Importance"
         }
        },
        "yaxis": {
         "title": {
          "text": "Hyperparameter"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "dimensions": [
          {
           "label": "Objective Value",
           "range": [
            0.3418246950649823,
            0.41595871349556
           ],
           "values": [
            0.3418246950649823,
            0.3438856748924979,
            0.4126291855298743,
            0.40124035760828214,
            0.3934442454633423,
            0.3904884389007476,
            0.37583884906731146,
            0.3962182085751677,
            0.3833417260835231,
            0.38855884534918794,
            0.41595871349556,
            0.397823850983603,
            0.3980204157096009,
            0.4057077487997942,
            0.4115134040951411
           ]
          },
          {
           "label": "batch_size",
           "range": [
            0,
            0
           ],
           "ticktext": [
            "64"
           ],
           "tickvals": [
            0
           ],
           "values": [
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0
           ]
          },
          {
           "label": "dropout_rate",
           "range": [
            0.30671717698689444,
            0.4693102103606831
           ],
           "values": [
            0.36506606615265286,
            0.3855082036717099,
            0.33720678662037423,
            0.3312037280884873,
            0.3339786557616442,
            0.30671717698689444,
            0.4092100414323442,
            0.434633811628221,
            0.4693102103606831,
            0.39332660381666834,
            0.40528476890240633,
            0.3828645496384041,
            0.33638630721973906,
            0.3397995395841233,
            0.34818504679270335
           ]
          },
          {
           "label": "head_hidden_dim",
           "range": [
            0,
            1
           ],
           "ticktext": [
            "512",
            "1024"
           ],
           "tickvals": [
            0,
            1
           ],
           "values": [
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1
           ]
          },
          {
           "label": "head_type",
           "range": [
            0,
            1
           ],
           "ticktext": [
            "original",
            "mlp_1_layer"
           ],
           "tickvals": [
            0,
            1
           ],
           "values": [
            0,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0
           ]
          },
          {
           "label": "l2_reg",
           "range": [
            -4.864318133268386,
            -2.0784917887998047
           ],
           "ticktext": [
            "1.37e-05",
            "0.0001",
            "0.001",
            "0.00835"
           ],
           "tickvals": [
            -4.864318133268386,
            -4,
            -3,
            -2.0784917887998047
           ],
           "values": [
            -4.864318133268386,
            -3.431801511854018,
            -3.5344193807052573,
            -3.20402454740889,
            -2.901336810076609,
            -2.8703929166340645,
            -2.8948889327384917,
            -3.212992743547531,
            -3.7181234333758963,
            -3.316100263807981,
            -2.0784917887998047,
            -3.7387998582442834,
            -3.7773217828171233,
            -3.7715921071776273,
            -3.3094380986380445
           ]
          },
          {
           "label": "loss_config",
           "range": [
            0,
            3
           ],
           "ticktext": [
            "focal_g5_weighted",
            "ce_weighted",
            "ce_weighted_smooth",
            "focal_g2_weighted"
           ],
           "tickvals": [
            0,
            1,
            2,
            3
           ],
           "values": [
            1,
            0,
            2,
            0,
            2,
            2,
            2,
            3,
            0,
            1,
            0,
            3,
            3,
            1,
            0
           ]
          },
          {
           "label": "lr",
           "range": [
            -3.6324400512631865,
            -3.0027719002806754
           ],
           "ticktext": [
            "0.000233",
            "0.000994"
           ],
           "tickvals": [
            -3.6324400512631865,
            -3.0027719002806754
           ],
           "values": [
            -3.078125764976883,
            -3.4387228024305037,
            -3.006307855679404,
            -3.625459881152637,
            -3.59820955287703,
            -3.6324400512631865,
            -3.613075529588427,
            -3.5278774248239517,
            -3.0967221678625476,
            -3.0027719002806754,
            -3.179623801649941,
            -3.0484567780572216,
            -3.106328455942487,
            -3.0631448129348384,
            -3.128168641926147
           ]
          },
          {
           "label": "optimizer",
           "range": [
            0,
            1
           ],
           "ticktext": [
            "AdamW",
            "RAdam"
           ],
           "tickvals": [
            0,
            1
           ],
           "values": [
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0
           ]
          },
          {
           "label": "w1",
           "range": [
            0.5027610585618012,
            0.953803198780401
           ],
           "values": [
            0.5027610585618012,
            0.6448757264568841,
            0.953803198780401,
            0.762378215816119,
            0.7142007482935182,
            0.7159385181728962,
            0.7626696154846466,
            0.6715160797353724,
            0.5417176108691886,
            0.9356976690324332,
            0.9137143384605635,
            0.5940437298024008,
            0.6969496779071767,
            0.8826766739878736,
            0.7503589933417762
           ]
          },
          {
           "label": "w2",
           "range": [
            0.5156434439922856,
            0.9105460154288381
           ],
           "values": [
            0.9077307142274171,
            0.5806106436270022,
            0.87307032757875,
            0.7159725093210578,
            0.7549028507040043,
            0.7340027538893085,
            0.7391685708265656,
            0.8096541667564223,
            0.6407176061020254,
            0.5156434439922856,
            0.8943233107659394,
            0.9105460154288381,
            0.7834895702400683,
            0.6106730038740856,
            0.7102186472862059
           ]
          },
          {
           "label": "w3",
           "range": [
            0.5004385644504841,
            0.9648488261712865
           ],
           "values": [
            0.8534286719238086,
            0.9648488261712865,
            0.8738931972673356,
            0.645614570099021,
            0.7137566656216701,
            0.7146815040890725,
            0.726752985693656,
            0.8423877967059843,
            0.5004385644504841,
            0.9228129601328928,
            0.5622338388686031,
            0.6558591613600282,
            0.7508735199471388,
            0.6852569306228374,
            0.5840688923306541
           ]
          },
          {
           "label": "w4",
           "range": [
            1.0591898334299397,
            1.4992901519334427
           ],
           "values": [
            1.3645035840204938,
            1.4040601897822085,
            1.2075355115792512,
            1.3059264473611898,
            1.263889446515016,
            1.2532665572573536,
            1.2718677337816662,
            1.1363270683904247,
            1.4763551405686437,
            1.1851067707435634,
            1.0591898334299397,
            1.4992901519334427,
            1.3015671894753305,
            1.155349178816528,
            1.309486238903956
           ]
          }
         ],
         "labelangle": 30,
         "labelside": "bottom",
         "line": {
          "color": [
           0.3418246950649823,
           0.3438856748924979,
           0.4126291855298743,
           0.40124035760828214,
           0.3934442454633423,
           0.3904884389007476,
           0.37583884906731146,
           0.3962182085751677,
           0.3833417260835231,
           0.38855884534918794,
           0.41595871349556,
           0.397823850983603,
           0.3980204157096009,
           0.4057077487997942,
           0.4115134040951411
          ],
          "colorbar": {
           "title": {
            "text": "Objective Value"
           }
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "reversescale": false,
          "showscale": true
         },
         "type": "parcoords"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Parallel Coordinate Plot"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from optuna.visualization import plot_optimization_history, plot_param_importances, plot_parallel_coordinate\n",
    "\n",
    "\n",
    "# 1. History (Did it improve over time?)\n",
    "fig1 = plot_optimization_history(study)\n",
    "fig1.show()\n",
    "\n",
    "# 2. Importance (Which parameter affects the F1 score the most?)\n",
    "fig2 = plot_param_importances(study)\n",
    "fig2.show()\n",
    "\n",
    "# 3. Parallel Coordinate (How do parameters interact?)\n",
    "fig3 = plot_parallel_coordinate(study)\n",
    "fig3.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
