{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "020adc77",
   "metadata": {},
   "source": [
    "## **I. Google Colab Initializtion (Only on Colab)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a81ad74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# cur_dir = \"/content/drive/MyDrive/CH2/Notebooks\"\n",
    "# %cd $cur_dir\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ada10e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install torchview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4969644a",
   "metadata": {},
   "source": [
    "## **1. Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "109a22c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "\n",
    "# Set environment variables before importing module\n",
    "os.environ['MPLCONFIGDIR'] = os.getcwd() + '/configs/'\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from PIL import Image\n",
    "# Import other libraries\n",
    "import cv2\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6087eb0c",
   "metadata": {},
   "source": [
    "## **2. Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188fcb47",
   "metadata": {},
   "source": [
    "- Preprocessing pipeline : \n",
    "    - Get Loaded Images\n",
    "    - Create Goo Masks\n",
    "    - Apply Goo Removal + Resizing\n",
    "    - Discard Shrek Images\n",
    "    - Apply the external Masks (optional)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc6208d",
   "metadata": {},
   "source": [
    "### 2.1 Preprocessing Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a2ca48",
   "metadata": {},
   "source": [
    "#### 2.1.1 _get_smart_goo_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9df4948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_smart_goo_mask(img_bgr):\n",
    "    \"\"\"\n",
    "    Internal helper to detect goo using Core & Shell logic + 1px Nudge.\n",
    "    Returns a binary mask (White = Goo, Black = Safe).\n",
    "    \"\"\"\n",
    "    # 1. Convert to HSV\n",
    "    hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # 2. Define Ranges\n",
    "    # CORE: Solid Green (Strict)\n",
    "    core_lower = np.array([35, 100, 50])\n",
    "    core_upper = np.array([85, 255, 255])\n",
    "    \n",
    "    # SHELL: Faint Halo (Loose/Transparent)\n",
    "    shell_lower = np.array([30, 30, 30])\n",
    "    shell_upper = np.array([95, 255, 255])\n",
    "\n",
    "    # 3. Create initial masks\n",
    "    mask_core = cv2.inRange(hsv, core_lower, core_upper)\n",
    "    mask_shell = cv2.inRange(hsv, shell_lower, shell_upper)\n",
    "\n",
    "    # 4. Smart Combine (Connected Components)\n",
    "    # Keep 'Shell' blobs ONLY if they touch 'Core' blobs\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask_shell, connectivity=8)\n",
    "    smart_mask = np.zeros_like(mask_core)\n",
    "\n",
    "    for label_id in range(1, num_labels): # Skip background (0)\n",
    "        blob_mask = (labels == label_id).astype(np.uint8) * 255\n",
    "        \n",
    "        # Check overlap with Core\n",
    "        overlap = cv2.bitwise_and(blob_mask, mask_core)\n",
    "        \n",
    "        # If there is ANY overlap, keep the blob\n",
    "        if cv2.countNonZero(overlap) > 0:\n",
    "            smart_mask = cv2.bitwise_or(smart_mask, blob_mask)\n",
    "\n",
    "    # 5. Fill Holes (in case the goo has shiny reflections)\n",
    "    contours, _ = cv2.findContours(smart_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    final_filled_mask = np.zeros_like(smart_mask)\n",
    "    for contour in contours:\n",
    "        # Minimum area filter (200px) to remove tiny stray noise\n",
    "        if cv2.contourArea(contour) > 200:\n",
    "            cv2.drawContours(final_filled_mask, [contour], -1, (255), thickness=cv2.FILLED)\n",
    "\n",
    "    # 6. The \"1-Pixel Nudge\"\n",
    "    # Safely expand by 1 pixel to cover the final anti-aliased fringe\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    final_expanded_mask = cv2.dilate(final_filled_mask, kernel, iterations=1)\n",
    "\n",
    "    return final_expanded_mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d4f365",
   "metadata": {},
   "source": [
    "#### 2.1.2 remove_goo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12c2ed58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_goo(input_dir, output_dir, target_size=(224, 224), remove_goo=True, save_masks=True, replacement_color=(0, 0, 0)):\n",
    "    \"\"\"\n",
    "    Iterates through input_dir, finds 'img_xxxx', resizes them to target_size, \n",
    "    and saves the result to output_dir.\n",
    "    If remove_goo is True, it replaces green pixels (using Smart Core/Shell logic) with replacement_color.\n",
    "    replacement_color: Tuple of (B, G, R) values. Default is black (0, 0, 0).\n",
    "    \"\"\"\n",
    "    input_dir = Path(input_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Extensions to look for\n",
    "    valid_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}\n",
    "    \n",
    "    # 1. Gather all valid image files first\n",
    "    print(f\"Scanning for images in: {input_dir}...\")\n",
    "    image_files = [\n",
    "        f for f in input_dir.iterdir() \n",
    "        if f.name.startswith('img_') and f.suffix.lower() in valid_extensions\n",
    "    ]\n",
    "    \n",
    "    if not image_files:\n",
    "        print(\"No images found starting with 'img_' in the directory.\")\n",
    "        return\n",
    "\n",
    "    # 2. Iterate with tqdm\n",
    "    count = 0\n",
    "    \n",
    "    for file_path in tqdm(image_files, desc=\"Removing Goo from Images\", unit=\"img\"):\n",
    "        output_path = output_dir / file_path.name\n",
    "        \n",
    "        if output_path.exists():\n",
    "            # Skip silently\n",
    "            continue\n",
    "\n",
    "        img = cv2.imread(str(file_path))\n",
    "        if img is None:\n",
    "            continue\n",
    "            \n",
    "        if target_size is not None:\n",
    "            img = cv2.resize(img, target_size)\n",
    "            \n",
    "        if remove_goo:\n",
    "            # --- NEW SMART GOO LOGIC ---\n",
    "            # Get the smart mask (White = Goo)\n",
    "            goo_mask = _get_smart_goo_mask(img)\n",
    "            \n",
    "            # Invert Goo Mask (White = Safe)\n",
    "            not_goo_mask = cv2.bitwise_not(goo_mask)\n",
    "            \n",
    "            # Apply Mask to keep safe areas (Goo areas become black/0)\n",
    "            img_safe = cv2.bitwise_and(img, img, mask=not_goo_mask)\n",
    "            \n",
    "            # Create background with replacement color\n",
    "            bg = np.full_like(img, replacement_color)\n",
    "            \n",
    "            # Keep background only where Goo is\n",
    "            bg_goo = cv2.bitwise_and(bg, bg, mask=goo_mask)\n",
    "            \n",
    "            # Combine: Safe Image + Colored Goo Areas\n",
    "            img = cv2.add(img_safe, bg_goo)\n",
    "\n",
    "            if save_masks:\n",
    "                # Save the mask (White = Safe/Tissue, Black = Goo)\n",
    "                mask_name = file_path.name.replace('img_', 'goo_mask_', 1)\n",
    "                mask_output_path = os.path.join(output_dir, \"goo_masks\", mask_name)\n",
    "                Path(os.path.dirname(mask_output_path)).mkdir(parents=True, exist_ok=True)\n",
    "                cv2.imwrite(str(mask_output_path), not_goo_mask)\n",
    "            \n",
    "        cv2.imwrite(str(output_path), img)\n",
    "        count += 1\n",
    "\n",
    "    print(f\"Resizing complete. Processed {count} new images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59eb8937",
   "metadata": {},
   "source": [
    "#### 2.1.3 clean_and_save_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63fdde37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_save_masks(goo_masks_dir, external_masks_dir, output_dir, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Loads goo masks (White=Safe) and original external masks.\n",
    "    Removes goo areas from external masks and saves the cleaned versions.\n",
    "    Skips processing if a cleaned mask already exists in the output directory.\n",
    "    \"\"\"\n",
    "    goo_masks_dir = Path(goo_masks_dir)\n",
    "    external_masks_dir = Path(external_masks_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    goo_mask_files = list(goo_masks_dir.glob('goo_mask_*.png'))\n",
    "    \n",
    "    if not goo_mask_files:\n",
    "        print(f\"No goo masks found in {goo_masks_dir}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(goo_mask_files)} goo masks. Checking for existing and processing new masks...\")\n",
    "\n",
    "    processed_count = 0\n",
    "    skipped_count = 0\n",
    "    for goo_mask_path in tqdm(goo_mask_files, desc=\"Cleaning External Masks\"):\n",
    "        # Derive the corresponding output mask name\n",
    "        mask_name = goo_mask_path.name.replace('goo_mask_', 'mask_', 1)\n",
    "        output_path = output_dir / mask_name\n",
    "\n",
    "\n",
    "        # Check if the cleaned mask already exists to skip reprocessing\n",
    "        if output_path.exists():\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "\n",
    "\n",
    "        external_mask_path = external_masks_dir / mask_name\n",
    "        \n",
    "        if not external_mask_path.exists():\n",
    "            # This part was commented out in the original, but it's good practice\n",
    "            # to log when a corresponding file is missing.\n",
    "            # tqdm.write(f\"Warning: External mask not found for {goo_mask_path.name}\")\n",
    "            continue\n",
    "\n",
    "        # Load masks\n",
    "        goo_mask = cv2.imread(str(goo_mask_path), cv2.IMREAD_GRAYSCALE)\n",
    "        external_mask = cv2.imread(str(external_mask_path), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if goo_mask is None or external_mask is None:\n",
    "            tqdm.write(f\"Warning: Could not read one of the masks for {mask_name}\")\n",
    "            continue\n",
    "\n",
    "        # Resize external mask if a target size is specified\n",
    "        if target_size is not None:\n",
    "             external_mask = cv2.resize(external_mask, target_size, interpolation=cv2.INTER_NEAREST)\n",
    "             # Ensure goo_mask also matches the target size\n",
    "             if goo_mask.shape[:2] != (target_size[1], target_size[0]):\n",
    "                 goo_mask = cv2.resize(goo_mask, target_size, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        # Ensure masks are binary (0 or 255)\n",
    "        _, external_mask = cv2.threshold(external_mask, 127, 255, cv2.THRESH_BINARY)\n",
    "        _, goo_mask = cv2.threshold(goo_mask, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Combine masks: The resulting pixel is white only if it's white in BOTH masks.\n",
    "        # This effectively removes \"goo\" areas from the \"region of interest\".\n",
    "        cleaned_mask = cv2.bitwise_and(external_mask, goo_mask)\n",
    "\n",
    "        # Save the final cleaned mask\n",
    "        cv2.imwrite(str(output_path), cleaned_mask)\n",
    "        processed_count += 1\n",
    "\n",
    "    print(\"\\nProcessing complete.\")\n",
    "    print(f\"  - Cleaned and saved: {processed_count} masks to {output_dir}\")\n",
    "    if skipped_count > 0:\n",
    "        print(f\"  - Skipped: {skipped_count} masks that already existed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c4f03f",
   "metadata": {},
   "source": [
    "#### 2.1.4 apply_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82d1ba7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mask(image_path, mask_path, output_path, target_size=(224, 224), remove_goo=True):\n",
    "    \"\"\"\n",
    "    Loads an image and a mask. \n",
    "    If remove_goo is True, it subtracts green pixels (using Smart Core/Shell logic) \n",
    "    from the valid mask area. Resizes and saves the result.\n",
    "    \"\"\"\n",
    "    # 1. Load Image\n",
    "    img = cv2.imread(str(image_path))\n",
    "    if img is None:\n",
    "        tqdm.write(f\"Error: Could not load image at {image_path}\")\n",
    "        return\n",
    "\n",
    "    # 2. Load External Mask (Read as grayscale)\n",
    "    mask = cv2.imread(str(mask_path), 0)\n",
    "    if mask is None:\n",
    "        tqdm.write(f\"Error: Could not load mask at {mask_path}\")\n",
    "        return\n",
    "\n",
    "    # 3. Resize both to target size\n",
    "    if target_size is not None:\n",
    "        img = cv2.resize(img, target_size)\n",
    "        mask = cv2.resize(mask, target_size)\n",
    "\n",
    "    # 4. Standardize External Mask (Binary 0 or 255)\n",
    "    _, binary_mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # 5. Determine Final Mask\n",
    "    if remove_goo:\n",
    "        # --- NEW SMART GOO LOGIC ---\n",
    "        # Get the smart mask (White = Goo)\n",
    "        goo_mask = _get_smart_goo_mask(img)\n",
    "        \n",
    "        # Invert Goo Mask (White = Safe)\n",
    "        not_goo_mask = cv2.bitwise_not(goo_mask)\n",
    "        \n",
    "        # Combine: Must be Tissue (binary_mask) AND Safe (not_goo_mask)\n",
    "        final_mask = cv2.bitwise_and(binary_mask, not_goo_mask)\n",
    "    else:\n",
    "        # --- ORIGINAL LOGIC ---\n",
    "        final_mask = binary_mask\n",
    "\n",
    "    # 6. Apply Final Mask\n",
    "    # Areas outside the final mask become Black (0)\n",
    "    masked_img = cv2.bitwise_and(img, img, mask=final_mask)\n",
    "\n",
    "    # 7. Save result\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(os.path.dirname(str(output_path)), exist_ok=True)\n",
    "    cv2.imwrite(str(output_path), masked_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ef40d9",
   "metadata": {},
   "source": [
    "#### 2.1.5 filter_bright_green_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2e66cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_bright_green_areas(image, lg_H=20, lg_S=45, lg_V=0, ug_H=84, ug_S=255, ug_V=255, dilate_iterations=2):\n",
    "    \"\"\"\n",
    "    Filters out bright green areas from the input image with improved residual removal.\n",
    "    \n",
    "    Args:\n",
    "        image: Input image in RGB format (0-1 range)\n",
    "        lg_H, lg_S, lg_V: Lower bounds for HSV green detection\n",
    "        ug_H, ug_S, ug_V: Upper bounds for HSV green detection\n",
    "        dilate_iterations: Number of dilation iterations to expand mask (removes edge artifacts)\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert from RGB (0-1) to BGR (0-255) for OpenCV\n",
    "    original_bgr = (image * 255).astype(np.uint8)[..., ::-1]\n",
    "\n",
    "    # 1. Convert to HSV (Hue, Saturation, Value)\n",
    "    hsv = cv2.cvtColor(original_bgr, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # 2. Define the \"Bright Green\" Range\n",
    "    lower_green = (lg_H, lg_S, lg_V)\n",
    "    upper_green = (ug_H, ug_S, ug_V)\n",
    "\n",
    "    # Create the initial mask\n",
    "    mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "\n",
    "    # 3. Morphological operations to clean up the mask\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "\n",
    "    # OPEN: Remove small noise\n",
    "    clean_mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "\n",
    "    # DILATE: Expand the mask to catch edge artifacts and residuals\n",
    "    # This ensures we remove green pixels at the boundaries\n",
    "    if dilate_iterations > 0:\n",
    "        clean_mask = cv2.dilate(clean_mask, kernel, iterations=dilate_iterations)\n",
    "\n",
    "    # 4. Additional step: Detect any remaining green-ish pixels\n",
    "    # Create a more aggressive mask for subtle green tones\n",
    "    lower_green_subtle = (max(0, lg_H - 10), max(0, lg_S - 10), 0)\n",
    "    upper_green_subtle = (min(180, ug_H + 10), 255, 255)\n",
    "    subtle_mask = cv2.inRange(hsv, lower_green_subtle, upper_green_subtle)\n",
    "    \n",
    "    # Only keep subtle green pixels that are near the main green area\n",
    "    subtle_mask = cv2.morphologyEx(subtle_mask, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    \n",
    "    # Combine masks\n",
    "    combined_mask = cv2.bitwise_or(clean_mask, subtle_mask)\n",
    "\n",
    "    # 5. Invert mask to keep the useful parts\n",
    "    mask_inv = cv2.bitwise_not(combined_mask)\n",
    "\n",
    "    # 6. Apply the mask\n",
    "    result_bgr = cv2.bitwise_and(original_bgr, original_bgr, mask=mask_inv)\n",
    "\n",
    "    return result_bgr, combined_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1a9a86",
   "metadata": {},
   "source": [
    "#### 2.1.6 analyze_dataset_for_shreks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb8cbc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dataset_for_shreks(directory, shrek_dir, ratio_threshold=0.0125):\n",
    "    shrek_images = []\n",
    "    tissue_images = []\n",
    "    \n",
    "    image_files = glob.glob(os.path.join(directory, 'img_*.png'))\n",
    "    print(f\"Found {len(image_files)} images in {directory}\")\n",
    "\n",
    "    for f in tqdm(image_files, desc=\"Analyzing for Shreks\"):\n",
    "        try:\n",
    "            # Load image (BGR)\n",
    "            img = cv2.imread(f)\n",
    "            if img is None: continue\n",
    "            \n",
    "            # Prepare image for the new filter: Convert BGR to RGB (0-1 float)\n",
    "            img_rgb_norm = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
    "            \n",
    "            # Apply Filter\n",
    "            result_bgr, mask = filter_bright_green_areas(img_rgb_norm)\n",
    "            \n",
    "            # Calculate Ratio of Green Pixels from the combined mask\n",
    "            total_pixels = img.shape[0] * img.shape[1]\n",
    "            green_pixels = np.count_nonzero(mask)\n",
    "            ratio = green_pixels / total_pixels\n",
    "            \n",
    "            # Convert BGR to RGB for plotting\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            entry = {\n",
    "                'name': os.path.basename(f), \n",
    "                'path': f,\n",
    "                'img': img_rgb, \n",
    "                'ratio': ratio,\n",
    "                'mask': mask\n",
    "            }\n",
    "\n",
    "            # === CLASSIFICATION LOGIC ===\n",
    "            if ratio > ratio_threshold:\n",
    "                shrek_images.append(entry)\n",
    "            else:\n",
    "                tissue_images.append(entry)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {f}: {e}\")\n",
    "\n",
    "    return shrek_images, tissue_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216ae7c8",
   "metadata": {},
   "source": [
    "#### 2.1.7 process_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bfb7c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dataset_for_shreks(directory, shrek_dir, ratio_threshold=0.0125, expected_count=150):\n",
    "    \"\"\"\n",
    "    Analyzes images in a directory to classify them as \"shrek\" or \"tissue\".\n",
    "\n",
    "    If the target shrek_dir already exists and contains the expected_count of images,\n",
    "    this function will skip the analysis to save time.\n",
    "\n",
    "    Args:\n",
    "        directory (str): The source directory containing images to analyze.\n",
    "        shrek_dir (str): The target directory where \"shrek\" images are saved.\n",
    "                         This is used to check if processing can be skipped.\n",
    "        ratio_threshold (float): The threshold for green pixel ratio to be classified as \"shrek\".\n",
    "        expected_count (int): The number of images expected in shrek_dir to skip processing.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two lists: (shrek_images, tissue_images).\n",
    "               Returns ([], []) if processing is skipped.\n",
    "    \"\"\"\n",
    "    # --- Start of new implementation ---\n",
    "    shrek_dir_path = Path(shrek_dir)\n",
    "    if shrek_dir_path.is_dir():\n",
    "        # Count image files (e.g., .png, .jpg) in the shrek directory\n",
    "        num_existing_images = len(list(shrek_dir_path.glob('img_*.png')))\n",
    "        \n",
    "        if num_existing_images == expected_count:\n",
    "            print(f\"'{shrek_dir}' already contains exactly {expected_count} images. Skipping analysis.\")\n",
    "            return [], [] # Return empty lists as the analysis is skipped\n",
    "    # --- End of new implementation ---\n",
    "\n",
    "    shrek_images = []\n",
    "    tissue_images = []\n",
    "    \n",
    "    image_files = glob.glob(os.path.join(directory, 'img_*.png'))\n",
    "    print(f\"Found {len(image_files)} images in '{directory}'. Analyzing for 'Shreks'...\")\n",
    "\n",
    "    for f in tqdm(image_files, desc=\"Analyzing for Shreks\"):\n",
    "        try:\n",
    "            img = cv2.imread(f)\n",
    "            if img is None: continue\n",
    "            \n",
    "            img_rgb_norm = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
    "            \n",
    "            # This function call is part of your original code\n",
    "            result_bgr, mask = filter_bright_green_areas(img_rgb_norm)\n",
    "            \n",
    "            total_pixels = img.shape[0] * img.shape[1]\n",
    "            green_pixels = np.count_nonzero(mask)\n",
    "            ratio = green_pixels / total_pixels\n",
    "            \n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            entry = {\n",
    "                'name': os.path.basename(f), \n",
    "                'path': f,\n",
    "                'img': img_rgb, \n",
    "                'ratio': ratio,\n",
    "                'mask': mask\n",
    "            }\n",
    "\n",
    "            if ratio > ratio_threshold:\n",
    "                shrek_images.append(entry)\n",
    "            else:\n",
    "                tissue_images.append(entry)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {f}: {e}\")\n",
    "\n",
    "    return shrek_images, tissue_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c27e2e",
   "metadata": {},
   "source": [
    "#### 2.1.8 process_classification_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b5f7b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_classification_results(shrek_list, tissue_list, shrek_dir, tissue_dir, threshold, visualize = True):\n",
    "    \"\"\"\n",
    "    Saves classified images to respective directories and visualizes the results.\n",
    "    \n",
    "    Args:\n",
    "        shrek_list (list): List of dicts containing Shrek image data.\n",
    "        tissue_list (list): List of dicts containing Tissue image data.\n",
    "        shrek_dir (str): Path to save Shrek images.\n",
    "        tissue_dir (str): Path to save Tissue images.\n",
    "        threshold (float): The green ratio threshold used for classification.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Print Summary\n",
    "    print(f\"Classified {len(shrek_list)} as Shrek\")\n",
    "    print(f\"Classified {len(tissue_list)} as Tissue\")\n",
    "\n",
    "    # Ensure directories exist\n",
    "    os.makedirs(shrek_dir, exist_ok=True)\n",
    "    os.makedirs(tissue_dir, exist_ok=True)\n",
    "\n",
    "    # 2. Save Shrek images\n",
    "    print(f\"Saving {len(shrek_list)} Shrek images to {shrek_dir}...\")\n",
    "    for item in tqdm(shrek_list, desc=\"Saving Shrek Images\"):\n",
    "        dest_path = os.path.join(shrek_dir, item['name'])\n",
    "        \n",
    "        # Check if file exists to prevent overwriting\n",
    "        if os.path.exists(dest_path):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            shutil.copy2(item['path'], dest_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error copying {item['name']} to shrek folder: {e}\")\n",
    "\n",
    "    # 3. Save Tissue images\n",
    "    print(f\"Saving {len(tissue_list)} Tissue images to {tissue_dir}...\")\n",
    "    for item in tqdm(tissue_list, desc=\"Saving Tissue Images\"):\n",
    "        dest_path = os.path.join(tissue_dir, item['name'])\n",
    "        \n",
    "        # Check if file exists to prevent overwriting\n",
    "        if os.path.exists(dest_path):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            shutil.copy2(item['path'], dest_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error copying {item['name']} to tissue folder: {e}\")\n",
    "    if visualize == True:\n",
    "        # 4. Visualize Examples (2x2 Grid)\n",
    "        if len(shrek_list) >= 2 and len(tissue_list) >= 2:\n",
    "            fig_ex, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "            fig_ex.suptitle(f\"Classification Results (Threshold: {threshold:.1%})\", fontsize=16)\n",
    "\n",
    "            def show_img(ax, item, label):\n",
    "                ax.imshow(item['img'])\n",
    "                # Show the Green Ratio in the title so you can see WHY it was classified\n",
    "                ax.set_title(f\"{label}\\n{item['name']}\\nGreen Pixels: {item['ratio']:.2%}\")\n",
    "                ax.axis('off')\n",
    "\n",
    "            # Row 1: Detected Shrek\n",
    "            show_img(axes[0, 0], shrek_list[0], \"Detected Shrek\")\n",
    "            show_img(axes[0, 1], shrek_list[1], \"Detected Shrek\")\n",
    "\n",
    "            # Row 2: Detected Tissue\n",
    "            show_img(axes[1, 0], tissue_list[0], \"Detected Tissue\")\n",
    "            show_img(axes[1, 1], tissue_list[1], \"Detected Tissue\")\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"Not enough images in one or both classes to generate 2x2 sample grid.\")\n",
    "\n",
    "        # 5. Plot Scatter Distribution for Tuning\n",
    "        shrek_ratios = [x['ratio'] for x in shrek_list]\n",
    "        tissue_ratios = [x['ratio'] for x in tissue_list]\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "\n",
    "        # Plot Tissue points (Blue)\n",
    "        plt.scatter(range(len(tissue_ratios)), tissue_ratios, color='blue', alpha=0.6, label='Classified as Tissue')\n",
    "\n",
    "        # Plot Shrek points (Green) - Shifted on x-axis to be distinct\n",
    "        # We shift the x-axis index for Shrek so they appear after the tissue points\n",
    "        plt.scatter(range(len(tissue_ratios), len(tissue_ratios) + len(shrek_ratios)), shrek_ratios, color='green', alpha=0.6, label='Classified as Shrek')\n",
    "\n",
    "        # Draw the Threshold Line\n",
    "        plt.axhline(y=threshold, color='red', linestyle='--', linewidth=2, label=f'Threshold ({threshold:.1%})')\n",
    "\n",
    "        plt.title('Green Pixel Ratio per Image', fontsize=14)\n",
    "        plt.ylabel('Ratio of Green Pixels (0.0 - 1.0)')\n",
    "        plt.xlabel('Image Index')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Shrek removal visulization OFF.\")\n",
    "\n",
    "# --- Example Usage ---\n",
    "# shrek_list, tissue_list = analyze_dataset(DATASET_PATH) # Assuming this runs before\n",
    "# process_classification_results(shrek_list, tissue_list, SHREK_DIR, TISSUE_DIR, RATIO_THRESHOLD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b15c4ec",
   "metadata": {},
   "source": [
    "#### 2.1.9 copy_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "188a5659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_masks(image_list, masks_dir, output_dir):\n",
    "    image_names = image_list\n",
    "    mask_names = [name.replace('img_', 'mask_', 1) for name in image_names]\n",
    "\n",
    "    for mask_name in tqdm(mask_names, desc=\"Copying Masks\"):\n",
    "        src_path = os.path.join(masks_dir, mask_name)\n",
    "        dst_path = os.path.join(output_dir, mask_name)\n",
    "        shutil.copy(src_path, dst_path)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42cc6b5",
   "metadata": {},
   "source": [
    "#### 2.1.10 extract_smart_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0447644e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_smart_patches(\n",
    "    img_path,\n",
    "    mask_path,\n",
    "    patch_size=224,\n",
    "    stride=224,\n",
    "    threshold=0.01,\n",
    "    dilate_iterations=15,\n",
    "    enforce_blob_overlap=True,\n",
    "\n",
    "    # --- patch count controls ---\n",
    "    pad_fraction=0.0,          # 0.0 = no bbox padding (recommended to reduce count)\n",
    "    max_patches_per_blob=None,    # cap kept patches per blob\n",
    "    iou_thresh=0.5,           # NMS: reject if overlaps too much with already kept patches\n",
    "    score_mode=\"mask_ratio\", # \"tumor_pixels\" or \"mask_ratio\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Extract patches over tumor blobs, with multi-patch coverage for big blobs BUT controlled patch count.\n",
    "\n",
    "    - Dilate + label to form blobs\n",
    "    - Tile candidate patches over each blob bbox (optionally padded)\n",
    "    - Filter by tumor ratio + tissue ratio\n",
    "    - Optional: ensure each patch overlaps its specific blob label\n",
    "    - Reduce redundancy via NMS (IoU) and cap max_patches_per_blob\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Load images ---\n",
    "    try:\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "    except FileNotFoundError:\n",
    "        if img_path.endswith(\".png\"):\n",
    "            img = Image.open(img_path.replace(\".png\", \".jpg\")).convert(\"RGB\")\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    mask = Image.open(mask_path).convert(\"L\")\n",
    "\n",
    "    img_arr = np.array(img)\n",
    "    mask_arr = np.array(mask)\n",
    "\n",
    "    # Normalize mask to 0..255 for consistent thresholding\n",
    "    mask_check = (mask_arr * 255) if mask_arr.max() <= 1 else mask_arr\n",
    "\n",
    "    h, w = img_arr.shape[:2]\n",
    "\n",
    "    if isinstance(patch_size, int):\n",
    "        ph, pw = patch_size, patch_size\n",
    "    else:\n",
    "        ph, pw = patch_size\n",
    "\n",
    "    if isinstance(stride, int):\n",
    "        sh, sw = stride, stride\n",
    "    else:\n",
    "        sh, sw = stride\n",
    "\n",
    "    # --- helpers ---\n",
    "    def clamp_start(v, max_v, p):\n",
    "        return max(0, min(int(v), int(max_v - p)))\n",
    "\n",
    "    def make_starts(min_v, max_v, p, s, limit):\n",
    "        \"\"\"Cover [min_v, max_v) with windows of size p using stride s, include endpoint.\"\"\"\n",
    "        min_v = int(min_v)\n",
    "        max_v = int(max_v)\n",
    "        if max_v - min_v <= p:\n",
    "            mid = (min_v + max_v) // 2 - p // 2\n",
    "            return [clamp_start(mid, limit, p)]\n",
    "        starts = list(range(min_v, max_v - p + 1, s))\n",
    "        end = max_v - p\n",
    "        if not starts:\n",
    "            starts = [end]\n",
    "        elif starts[-1] != end:\n",
    "            starts.append(end)\n",
    "        return [clamp_start(v, limit, p) for v in starts]\n",
    "\n",
    "    def iou_xywh(a, b):\n",
    "        \"\"\"IoU for boxes in (x, y, w, h).\"\"\"\n",
    "        ax, ay, aw, ah = a\n",
    "        bx, by, bw, bh = b\n",
    "        ax2, ay2 = ax + aw, ay + ah\n",
    "        bx2, by2 = bx + bw, by + bh\n",
    "\n",
    "        ix1, iy1 = max(ax, bx), max(ay, by)\n",
    "        ix2, iy2 = min(ax2, bx2), min(ay2, by2)\n",
    "        iw, ih = max(0, ix2 - ix1), max(0, iy2 - iy1)\n",
    "        inter = iw * ih\n",
    "        if inter == 0:\n",
    "            return 0.0\n",
    "        union = aw * ah + bw * bh - inter\n",
    "        return inter / union\n",
    "\n",
    "    # --- grouping: dilate + label ---\n",
    "    dilated_mask = ndimage.binary_dilation(mask_check > 128, iterations=dilate_iterations)\n",
    "    labeled_mask, num_features = ndimage.label(dilated_mask)\n",
    "    objects = ndimage.find_objects(labeled_mask)\n",
    "\n",
    "\n",
    "    kept_patches = []\n",
    "    kept_coords = []\n",
    "    kept_xy = set()  # avoid duplicates across blobs\n",
    "\n",
    "    # --- per blob: make candidates, score, NMS, cap ---\n",
    "    for i, slice_obj in enumerate(objects):\n",
    "        if slice_obj is None:\n",
    "            continue\n",
    "\n",
    "        label_id = i + 1\n",
    "        y_slice, x_slice = slice_obj\n",
    "        y_min, y_max = y_slice.start, y_slice.stop\n",
    "        x_min, x_max = x_slice.start, x_slice.stop\n",
    "\n",
    "        # bbox padding control (pad_fraction=0.0 keeps tight bbox)\n",
    "        pad_y = int(ph * pad_fraction)\n",
    "        pad_x = int(pw * pad_fraction)\n",
    "\n",
    "        y0 = max(0, y_min - pad_y)\n",
    "        y1 = min(h, y_max + pad_y)\n",
    "        x0 = max(0, x_min - pad_x)\n",
    "        x1 = min(w, x_max + pad_x)\n",
    "\n",
    "        y_starts = make_starts(y0, y1, ph, sh, h)\n",
    "        x_starts = make_starts(x0, x1, pw, sw, w)\n",
    "\n",
    "        candidates = []\n",
    "        for y in y_starts:\n",
    "            for x in x_starts:\n",
    "                # ensure patch is for this blob (optional)\n",
    "                if enforce_blob_overlap:\n",
    "                    lbl_patch = labeled_mask[y:y + ph, x:x + pw]\n",
    "                    if not np.any(lbl_patch == label_id):\n",
    "                        continue\n",
    "\n",
    "                img_patch = img_arr[y:y + ph, x:x + pw]\n",
    "                mask_patch = mask_check[y:y + ph, x:x + pw]\n",
    "\n",
    "                # tissue ratio (avoid mostly background)\n",
    "                img_gray = np.mean(img_patch, axis=2)\n",
    "                tissue_ratio = np.sum(img_gray < 235) / (ph * pw)\n",
    "                if tissue_ratio <= 0.15:\n",
    "                    continue\n",
    "\n",
    "                # tumor ratio threshold\n",
    "                tumor_pixels = int(np.sum(mask_patch > 128))\n",
    "                mask_ratio = tumor_pixels / (ph * pw)\n",
    "                if mask_ratio < threshold:\n",
    "                    continue\n",
    "\n",
    "                # score for ranking (higher = keep first)\n",
    "                if score_mode == \"mask_ratio\":\n",
    "                    score = float(mask_ratio)\n",
    "                else:\n",
    "                    score = float(tumor_pixels)  # default: prioritize most tumor content\n",
    "\n",
    "                candidates.append((score, x, y))\n",
    "\n",
    "        if not candidates:\n",
    "            continue\n",
    "\n",
    "        # sort best-first\n",
    "        candidates.sort(key=lambda t: t[0], reverse=True)\n",
    "\n",
    "        # greedy NMS within this blob + cap\n",
    "        selected_boxes = []\n",
    "        selected = 0\n",
    "\n",
    "        for score, x, y in candidates:\n",
    "            if (x, y) in kept_xy:\n",
    "                continue\n",
    "\n",
    "            box = (x, y, pw, ph)\n",
    "\n",
    "            if iou_thresh is not None and selected_boxes:\n",
    "                too_much_overlap = any(iou_xywh(box, b) >= iou_thresh for b in selected_boxes)\n",
    "                if too_much_overlap:\n",
    "                    continue\n",
    "\n",
    "            # accept\n",
    "            kept_patches.append(img_arr[y:y + ph, x:x + pw])\n",
    "            kept_coords.append((x, y))\n",
    "            kept_xy.add((x, y))\n",
    "            selected_boxes.append(box)\n",
    "            selected += 1\n",
    "\n",
    "            if max_patches_per_blob is not None and selected >= max_patches_per_blob:\n",
    "                break\n",
    "\n",
    "    return kept_patches, kept_coords, img_arr, mask_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261850b3",
   "metadata": {},
   "source": [
    "#### 2.1.11 create_patches_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d86d4381",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_patches_dataset(input_dir, output_dir, mask_dir, \n",
    "                           threshold=0.01, \n",
    "                           patch_size=224, \n",
    "                           stride=224,\n",
    "                           iou_thresh=0.5, \n",
    "                           dilate_iterations=15, \n",
    "                           max_patches_per_blob=10):\n",
    "    \"\"\"\n",
    "    Iterates over images in input_dir, finds corresponding masks in mask_dir,\n",
    "    extracts smart patches, and saves them to output_dir.\n",
    "    Also saves corresponding mask patches to a 'masks' subdirectory.\n",
    "\n",
    "    This function will skip processing for any source image if its corresponding\n",
    "    patches are already found in the output directory.\n",
    "    \"\"\"\n",
    "    input_dir = Path(input_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "    mask_dir = Path(mask_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Create subdirectory for mask patches\n",
    "    masks_output_dir = output_dir / \"masks\"\n",
    "    masks_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Filter for image files\n",
    "    image_files = sorted([\n",
    "        f for f in input_dir.iterdir()\n",
    "        if f.name.startswith('img_') and f.suffix.lower() in {'.png', '.jpg', '.jpeg'}\n",
    "    ])\n",
    "\n",
    "    total_patches_saved = 0\n",
    "    images_processed = 0\n",
    "    images_skipped = 0\n",
    "    \n",
    "    print(f\"Starting patch extraction from {input_dir} to {output_dir}...\")\n",
    "    print(f\"Found {len(image_files)} source images.\")\n",
    "\n",
    "    for source_image_path in tqdm(image_files, desc=\"Processing Images\"):\n",
    "        base_name = source_image_path.stem\n",
    "\n",
    "        # --- CHECK FOR EXISTING PATCHES ---\n",
    "        # Check if any patch file for this image already exists.\n",
    "        # We use glob to find files matching the pattern like 'img_xxxx_p*.png'.\n",
    "        # next() with a default value is an efficient way to check for existence\n",
    "        # without listing all files.\n",
    "        if next(output_dir.glob(f\"{base_name}_p*.png\"), None):\n",
    "            # tqdm.write(f\"Skipping {source_image_path.name}, patches already exist.\")\n",
    "            images_skipped += 1\n",
    "            continue\n",
    "\n",
    "        # Construct mask filename (e.g., 'img_xxxx.png' -> 'mask_xxxx.png')\n",
    "        mask_name = source_image_path.name.replace('img_', 'mask_', 1)\n",
    "        mask_path = mask_dir / mask_name\n",
    "\n",
    "        # Fallback if mask has a different extension or wasn't found initially\n",
    "        if not mask_path.exists():\n",
    "             mask_path = mask_dir / (base_name.replace('img_', 'mask_', 1) + \".png\")\n",
    "\n",
    "        if mask_path.exists():\n",
    "            # Extract patches\n",
    "            patches, coords, _, mask_arr = extract_smart_patches(\n",
    "                str(source_image_path),\n",
    "                str(mask_path),\n",
    "                patch_size=patch_size,\n",
    "                stride=stride,\n",
    "                threshold=threshold,\n",
    "                dilate_iterations=dilate_iterations,\n",
    "                iou_thresh=iou_thresh,\n",
    "                max_patches_per_blob=max_patches_per_blob,  # Example cap\n",
    "\n",
    "            )\n",
    "\n",
    "            if not patches:\n",
    "                continue\n",
    "\n",
    "            # Save each patch and corresponding mask patch\n",
    "            for i, (patch_array, (x, y)) in enumerate(zip(patches, coords)):\n",
    "                # Save image patch\n",
    "                patch_img = Image.fromarray(patch_array)\n",
    "                save_name = f\"{base_name}_p{i}.png\"\n",
    "                patch_img.save(output_dir / save_name)\n",
    "                \n",
    "                # Extract and save mask patch\n",
    "                if isinstance(patch_size, int):\n",
    "                    ph, pw = patch_size, patch_size\n",
    "                else:\n",
    "                    ph, pw = patch_size\n",
    "                    \n",
    "                mask_patch = mask_arr[y:y+ph, x:x+pw]\n",
    "                mask_patch_img = Image.fromarray(mask_patch)\n",
    "                mask_save_name = f\"mask_{base_name.replace('img_', '')}_p{i}.png\"\n",
    "                mask_patch_img.save(masks_output_dir / mask_save_name)\n",
    "            \n",
    "            total_patches_saved += len(patches)\n",
    "            images_processed += 1\n",
    "        else:\n",
    "            tqdm.write(f\"Warning: Mask not found for {source_image_path.name}\")\n",
    "\n",
    "    print(\"\\n--- Extraction Summary ---\")\n",
    "    print(f\"Images Processed: {images_processed}\")\n",
    "    print(f\"Images Skipped:   {images_skipped}\")\n",
    "    print(f\"Total Patches Saved in this run: {total_patches_saved}\")\n",
    "    print(f\"Patches are located in: {output_dir}\")\n",
    "    print(f\"Mask patches are located in: {masks_output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e250c9a2",
   "metadata": {},
   "source": [
    "#### 2.1.12 batch_blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ae567e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def apply_blur_batch(images_dir, masks_dir, output_dir, blur_strength=(51, 51)):\n",
    "    \"\"\"\n",
    "    Applies the blur mask logic to all images in a directory.\n",
    "    Assumes mask filenames match image filenames.\n",
    "    \"\"\"\n",
    "    # 1. Create output directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        print(f\"Created output directory: {output_dir}\")\n",
    "\n",
    "    # 2. Iterate through files in the images directory\n",
    "    supported_extensions = ('.png', '.jpg', '.jpeg', '.bmp', '.tiff')\n",
    "    files = [f for f in os.listdir(images_dir) if f.lower().endswith(supported_extensions)]\n",
    "\n",
    "    print(f\"Found {len(files)} images to process.\")\n",
    "\n",
    "    for filename in tqdm(files, desc=\"Processing images\", unit=\"img\"):\n",
    "        img_path = os.path.join(images_dir, filename)\n",
    "        mask_filename = filename.replace('img_', 'mask_', 1) if filename.startswith('img_') else filename\n",
    "        mask_path = os.path.join(masks_dir, mask_filename)\n",
    "        output_path = os.path.join(output_dir, filename)\n",
    "\n",
    "        # 3. Validation\n",
    "        if not os.path.exists(mask_path):\n",
    "            print(f\"Skipping {filename}: No corresponding mask found at {mask_path}\")\n",
    "            continue\n",
    "\n",
    "        # 4. Load images\n",
    "        img = cv2.imread(img_path)\n",
    "        mask = cv2.imread(mask_path, 0) # Load mask as grayscale\n",
    "\n",
    "        if img is None or mask is None:\n",
    "            print(f\"Error: Could not load data for {filename}\")\n",
    "            continue\n",
    "\n",
    "        # 5. Resize mask if dimensions don't match\n",
    "        if img.shape[:2] != mask.shape:\n",
    "            # print(f\"Resizing mask for {filename}\")\n",
    "            mask = cv2.resize(mask, (img.shape[1], img.shape[0]))\n",
    "\n",
    "        # 6. Apply Blur Logic\n",
    "        blurred_img = cv2.GaussianBlur(img, blur_strength, 0)\n",
    "        \n",
    "        # Ensure mask is binary: White (255) = Intact, Black (0) = Blurred\n",
    "        _, binary_mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Region A: Intact (where mask is 255)\n",
    "        intact_parts = cv2.bitwise_and(img, img, mask=binary_mask)\n",
    "\n",
    "        # Region B: Blurred (where mask is 0)\n",
    "        mask_inverted = cv2.bitwise_not(binary_mask)\n",
    "        blurred_parts = cv2.bitwise_and(blurred_img, blurred_img, mask=mask_inverted)\n",
    "\n",
    "        # Combine\n",
    "        result = cv2.add(intact_parts, blurred_parts)\n",
    "\n",
    "        # 7. Save Result\n",
    "        cv2.imwrite(output_path, result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f350406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_patch_masks_to_images(patches_dir, masks_dir=None, output_dir=None):\n",
    "    \"\"\"Apply mask patches to image patches and save masked outputs.\n",
    "    Args:\n",
    "        patches_dir: directory with img_*_p*.png\n",
    "        masks_dir: directory with mask_*_p*.png (default: patches_dir / 'masks')\n",
    "        output_dir: destination for masked patches (default: patches_dir / 'masked')\n",
    "    \"\"\"\n",
    "    patches_dir = Path(patches_dir)\n",
    "    masks_dir = Path(masks_dir) if masks_dir else patches_dir / \"masks\"\n",
    "    output_dir = Path(output_dir) if output_dir else patches_dir / \"masked\"\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    patch_files = sorted(patches_dir.glob(\"img_*_p*.png\"))\n",
    "    if not patch_files:\n",
    "        print(f\"No patch images found in {patches_dir}\")\n",
    "        return\n",
    "\n",
    "    applied, skipped = 0, 0\n",
    "    for patch_path in tqdm(patch_files, desc=\"Applying mask patches\"):\n",
    "        mask_name = patch_path.stem.replace(\"img_\", \"mask_\", 1) + patch_path.suffix\n",
    "        mask_path = masks_dir / mask_name\n",
    "        out_path = output_dir / patch_path.name\n",
    "\n",
    "        if out_path.exists():\n",
    "            skipped += 1\n",
    "            continue\n",
    "        if not mask_path.exists():\n",
    "            tqdm.write(f\"Mask not found for {patch_path.name}\")\n",
    "            continue\n",
    "\n",
    "        img = np.array(Image.open(patch_path).convert(\"RGB\"))\n",
    "        mask = np.array(Image.open(mask_path).convert(\"L\"))\n",
    "        if mask.shape[:2] != img.shape[:2]:\n",
    "            mask = np.array(Image.open(mask_path).convert(\"L\").resize((img.shape[1], img.shape[0]), Image.NEAREST))\n",
    "\n",
    "        mask_bin = (mask > 127).astype(np.uint8)\n",
    "        masked = cv2.bitwise_and(img, img, mask=mask_bin)\n",
    "        Image.fromarray(masked).save(out_path)\n",
    "        applied += 1\n",
    "\n",
    "    print(f\"Applied masks to {applied} patches. Skipped {skipped} existing outputs. Results in: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99692554",
   "metadata": {},
   "source": [
    "# **3. Run Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c03d7b",
   "metadata": {},
   "source": [
    "## **3.1 Preprocess the Train Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15f4b930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset path: ../../an2dl2526c2\n",
      "Train data path: ../../an2dl2526c2/train_data\n",
      "Train labels path: ../../an2dl2526c2/train_labels.csv\n",
      "Test data path: ../../an2dl2526c2/test_data\n"
     ]
    }
   ],
   "source": [
    "datasets_path = os.path.join(os.path.pardir,os.path.pardir, \"an2dl2526c2\")\n",
    "\n",
    "train_data_path = os.path.join(datasets_path, \"train_data\")\n",
    "train_labels_path = os.path.join(datasets_path, \"train_labels.csv\")\n",
    "test_data_path = os.path.join(datasets_path, \"test_data\")\n",
    "\n",
    "CSV_PATH = train_labels_path                # Path to the CSV file with labels\n",
    "SOURCE_FOLDER = train_data_path\n",
    "\n",
    "print(f\"Dataset path: {datasets_path}\")\n",
    "print(f\"Train data path: {train_data_path}\")\n",
    "print(f\"Train labels path: {train_labels_path}\")\n",
    "print(f\"Test data path: {test_data_path}\")\n",
    "# preprocessing output paths\n",
    "#preprocessing step 1 output path\n",
    "GOO_REMOVAL_OUT = os.path.join(datasets_path, \"preprocessing_results\",\"train_nogoo\")\n",
    "\n",
    "#preprocessing step 2 output path\n",
    "SHREK_REMOVAL_OUT = os.path.join(datasets_path, \"preprocessing_results\",\"train_noshreks\")\n",
    "SHREKS_OUT = os.path.join(SHREK_REMOVAL_OUT, \"train_shreks\")\n",
    "TISSUE_OUT = os.path.join(SHREK_REMOVAL_OUT, \"train_tissue\")\n",
    "\n",
    "\n",
    "  # Where the resized unmasked images will be saved\n",
    "PATCHES_OUT = os.path.join(datasets_path, \"preprocessing_results\",\"train_patches\")\n",
    "BLURRED_OUT = os.path.join(datasets_path, \"preprocessing_results\",\"train_patches_blurred\")\n",
    "\n",
    "\n",
    "SUBMISSION_SOURCE_FOLDER = os.path.join(datasets_path, \"test_data\")\n",
    "SUBMISSION_PATCHES_OUT = os.path.join(datasets_path, \"preprocessing_results\",\"submission_patches\")\n",
    "SUBMISSION_BLURRED_OUT = os.path.join(datasets_path, \"preprocessing_results\",\"submission_patches_blurred\")\n",
    "\n",
    "PATCHES_OUT_MASKED = os.path.join(datasets_path, \"preprocessing_results\",\"train_patches_masked\")\n",
    "SUBMISSION_PATCHES_OUT_MASKED = os.path.join(datasets_path, \"preprocessing_results\",\"submission_patches_masked\")\n",
    "\n",
    "TARGET_SIZE = (224, 224)                    # Target size for the resized images and masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54719952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning for images in: ../../an2dl2526c2/train_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing Goo from Images: 100%|| 691/691 [00:00<00:00, 75733.99img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing complete. Processed 0 new images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Remove goo and do not resize images\n",
    "remove_goo(SOURCE_FOLDER,GOO_REMOVAL_OUT, target_size=None, remove_goo=True, save_masks=True, replacement_color=(195, 195, 195))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c3bc574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 691 goo masks. Checking for existing and processing new masks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning External Masks: 100%|| 691/691 [00:00<00:00, 123293.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing complete.\n",
      "  - Cleaned and saved: 0 masks to ../../an2dl2526c2/preprocessing_results/train_nogoo/cleaned_masks\n",
      "  - Skipped: 691 masks that already existed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "clean_and_save_masks(\n",
    "    goo_masks_dir=os.path.join(GOO_REMOVAL_OUT, \"goo_masks\"), \n",
    "    external_masks_dir=SOURCE_FOLDER, \n",
    "    output_dir=os.path.join(GOO_REMOVAL_OUT, \"cleaned_masks\"), \n",
    "    target_size=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6008bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 691 images in '../../an2dl2526c2/preprocessing_results/train_nogoo'. Analyzing for 'Shreks'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing for Shreks: 100%|| 691/691 [00:33<00:00, 20.60it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified 60 as Shrek\n",
      "Classified 631 as Tissue\n",
      "Saving 60 Shrek images to ../../an2dl2526c2/preprocessing_results/train_noshreks/train_shreks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving Shrek Images: 100%|| 60/60 [00:00<00:00, 175249.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 631 Tissue images to ../../an2dl2526c2/preprocessing_results/train_noshreks/train_tissue...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving Tissue Images: 100%|| 631/631 [00:00<00:00, 526792.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shrek removal visulization OFF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying Masks: 100%|| 631/631 [00:00<00:00, 3877.25it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 2: Discard Shrek Images\n",
    "shreks_list, tissue_list = analyze_dataset_for_shreks(GOO_REMOVAL_OUT, shrek_dir=SHREKS_OUT, ratio_threshold=0.0125, expected_count=150)\n",
    "\n",
    "process_classification_results(shreks_list, tissue_list, SHREKS_OUT, TISSUE_OUT, 0.0125, visualize=False)\n",
    "\n",
    "tissue_image_names = [item['name'] for item in tissue_list]\n",
    "copy_masks(tissue_image_names, SOURCE_FOLDER, TISSUE_OUT)\n",
    "\n",
    "# Clean up memory\n",
    "del shreks_list\n",
    "del tissue_list\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7d8c886",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting patch extraction from ../../an2dl2526c2/preprocessing_results/train_noshreks/train_tissue to ../../an2dl2526c2/preprocessing_results/train_patches...\n",
      "Found 631 source images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|| 631/631 [00:00<00:00, 1190.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Extraction Summary ---\n",
      "Images Processed: 0\n",
      "Images Skipped:   631\n",
      "Total Patches Saved in this run: 0\n",
      "Patches are located in: ../../an2dl2526c2/preprocessing_results/train_patches\n",
      "Mask patches are located in: ../../an2dl2526c2/preprocessing_results/train_patches/masks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "CLEANED_MASKS_DIR = os.path.join(GOO_REMOVAL_OUT, \"cleaned_masks\")\n",
    "\n",
    "create_patches_dataset(\n",
    "    TISSUE_OUT, \n",
    "    PATCHES_OUT, \n",
    "    mask_dir=CLEANED_MASKS_DIR,\n",
    "    patch_size=224, \n",
    "    stride=224, \n",
    "    threshold=0.01,\n",
    "    max_patches_per_blob=10,\n",
    "    iou_thresh=0.5,\n",
    "    dilate_iterations=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4fb4e54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3097 images to process.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|| 3097/3097 [00:15<00:00, 205.72img/s]\n",
      "Applying mask patches: 100%|| 3097/3097 [00:08<00:00, 355.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied masks to 3097 patches. Skipped 0 existing outputs. Results in: ../../an2dl2526c2/preprocessing_results/train_patches_masked\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(BLURRED_OUT, exist_ok=True)\n",
    "apply_blur_batch(\n",
    "    images_dir=PATCHES_OUT, \n",
    "    masks_dir=os.path.join(PATCHES_OUT, \"masks\"), \n",
    "    output_dir=BLURRED_OUT, \n",
    "    blur_strength=(51, 51)\n",
    ")\n",
    "\n",
    "\n",
    "apply_patch_masks_to_images(PATCHES_OUT, output_dir=PATCHES_OUT_MASKED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879490b3",
   "metadata": {},
   "source": [
    "## **3.2 Preprocess the Submission Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "756b19c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting patch extraction from ../../an2dl2526c2/test_data to ../../an2dl2526c2/preprocessing_results/submission_patches...\n",
      "Found 477 source images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|| 477/477 [00:00<00:00, 1641.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Extraction Summary ---\n",
      "Images Processed: 0\n",
      "Images Skipped:   477\n",
      "Total Patches Saved in this run: 0\n",
      "Patches are located in: ../../an2dl2526c2/preprocessing_results/submission_patches\n",
      "Mask patches are located in: ../../an2dl2526c2/preprocessing_results/submission_patches/masks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "create_patches_dataset(\n",
    "    SUBMISSION_SOURCE_FOLDER, \n",
    "    SUBMISSION_PATCHES_OUT, \n",
    "    mask_dir=SUBMISSION_SOURCE_FOLDER,\n",
    "    patch_size=224, \n",
    "    stride=224, \n",
    "    threshold=0.01,\n",
    "    max_patches_per_blob=10,\n",
    "    iou_thresh=0.5,\n",
    "    dilate_iterations=15\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad0be035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created output directory: ../../an2dl2526c2/preprocessing_results/submission_patches_blurred\n",
      "Found 2301 images to process.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|| 2301/2301 [00:12<00:00, 181.43img/s]\n",
      "Applying mask patches: 100%|| 2301/2301 [00:06<00:00, 353.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied masks to 2301 patches. Skipped 0 existing outputs. Results in: ../../an2dl2526c2/preprocessing_results/submission_patches_masked\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "apply_blur_batch(\n",
    "    images_dir=SUBMISSION_PATCHES_OUT, \n",
    "    masks_dir=os.path.join(SUBMISSION_PATCHES_OUT, \"masks\"), \n",
    "    output_dir=SUBMISSION_BLURRED_OUT, \n",
    "    blur_strength=(51, 51)\n",
    ")\n",
    "\n",
    "apply_patch_masks_to_images(SUBMISSION_PATCHES_OUT, output_dir=SUBMISSION_PATCHES_OUT_MASKED)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
