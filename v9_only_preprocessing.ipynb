{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OBulun/AN2DL_CH_2/blob/Francesco/v9_only_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ubQHkqz_Y0Fn",
      "metadata": {
        "id": "ubQHkqz_Y0Fn"
      },
      "source": [
        "## ðŸŒ **Google Drive Connection**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wHmsvkwuY2p8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHmsvkwuY2p8",
        "outputId": "6fe56a79-d0ba-48ec-e33a-bba6e3766461"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive/My Drive/AN2DL Challenge 2\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/gdrive\")\n",
        "# Define current_dir correctly for Python (no backslashes for spaces)\n",
        "current_dir = \"/gdrive/My Drive/[2025 - 2026] AN2DL/Challenge 2\"\n",
        "# Use the correctly formatted path for the %cd magic command, quoting it for safety\n",
        "%cd \"$current_dir\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4969644a",
      "metadata": {
        "id": "4969644a"
      },
      "source": [
        "## 1. Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "109a22c9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "109a22c9",
        "outputId": "7cb77cbc-3ba1-46a5-f8e4-1280e71a7acb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.9.0+cu126\n",
            "Device: cpu\n",
            "Collecting torchview\n",
            "  Downloading torchview-0.2.7-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from torchview) (0.21)\n",
            "Downloading torchview-0.2.7-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: torchview\n",
            "Successfully installed torchview-0.2.7\n",
            "Collecting adabelief_pytorch\n",
            "  Downloading adabelief_pytorch-0.2.1-py3-none-any.whl.metadata (616 bytes)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from adabelief_pytorch) (2.9.0+cu126)\n",
            "Collecting colorama>=0.4.0 (from adabelief_pytorch)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: tabulate>=0.7 in /usr/local/lib/python3.12/dist-packages (from adabelief_pytorch) (0.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->adabelief_pytorch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->adabelief_pytorch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->adabelief_pytorch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->adabelief_pytorch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->adabelief_pytorch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->adabelief_pytorch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->adabelief_pytorch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->adabelief_pytorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->adabelief_pytorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->adabelief_pytorch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->adabelief_pytorch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->adabelief_pytorch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->adabelief_pytorch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->adabelief_pytorch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->adabelief_pytorch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->adabelief_pytorch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->adabelief_pytorch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->adabelief_pytorch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->adabelief_pytorch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->adabelief_pytorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->adabelief_pytorch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->adabelief_pytorch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->adabelief_pytorch) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=0.4.0->adabelief_pytorch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=0.4.0->adabelief_pytorch) (3.0.3)\n",
            "Downloading adabelief_pytorch-0.2.1-py3-none-any.whl (5.8 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: colorama, adabelief_pytorch\n",
            "Successfully installed adabelief_pytorch-0.2.1 colorama-0.4.6\n"
          ]
        }
      ],
      "source": [
        "# Set seed for reproducibility\n",
        "SEED = 42\n",
        "\n",
        "# Import necessary libraries\n",
        "import os\n",
        "\n",
        "# Set environment variables before importing modules\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "os.environ['MPLCONFIGDIR'] = os.getcwd() + '/configs/'\n",
        "\n",
        "# Suppress warnings\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=Warning)\n",
        "\n",
        "# Import necessary modules\n",
        "import logging\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Set seeds for random number generators in NumPy and Python\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "# Import PyTorch\n",
        "import torch\n",
        "torch.manual_seed(SEED)\n",
        "from torch import nn\n",
        "from torchsummary import summary\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torchvision\n",
        "from torchvision.transforms import v2 as transforms\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# Configurazione di TensorBoard e directory\n",
        "logs_dir = \"tensorboard\"\n",
        "!pkill -f tensorboard\n",
        "%load_ext tensorboard\n",
        "!mkdir -p models\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "# Import other libraries\n",
        "import cv2\n",
        "import copy\n",
        "import shutil\n",
        "import gc\n",
        "from itertools import product\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "import matplotlib.gridspec as gridspec\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from tqdm import tqdm\n",
        "import glob\n",
        "from pathlib import Path\n",
        "!pip install torchview\n",
        "!pip install adabelief_pytorch\n",
        "from torchview import draw_graph\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.transforms import RandAugment\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torchvision import models, transforms\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import torch.nn as nn\n",
        "from torch.optim import RAdam\n",
        "from adabelief_pytorch import AdaBelief\n",
        "import scipy.ndimage as ndimage # Import scipy.ndimage\n",
        "\n",
        "# Configure plot display settings\n",
        "sns.set(font_scale=1.4)\n",
        "sns.set_style('white')\n",
        "plt.rc('font', size=14)\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def _get_smart_goo_mask(img_bgr):\n",
        "    \"\"\"\n",
        "    Internal helper to detect goo using Core & Shell logic + 1px Nudge.\n",
        "    Returns a binary mask (White = Goo, Black = Safe).\n",
        "    \"\"\"\n",
        "    # 1. Convert to HSV\n",
        "    hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # 2. Define Ranges\n",
        "    # CORE: Solid Green (Strict)\n",
        "    core_lower = np.array([35, 100, 50])\n",
        "    core_upper = np.array([85, 255, 255])\n",
        "\n",
        "    # SHELL: Faint Halo (Loose/Transparent)\n",
        "    shell_lower = np.array([30, 30, 30])\n",
        "    shell_upper = np.array([95, 255, 255])\n",
        "\n",
        "    # 3. Create initial masks\n",
        "    mask_core = cv2.inRange(hsv, core_lower, core_upper)\n",
        "    mask_shell = cv2.inRange(hsv, shell_lower, shell_upper)\n",
        "\n",
        "    # 4. Smart Combine (Connected Components)\n",
        "    # Keep 'Shell' blobs ONLY if they touch 'Core' blobs\n",
        "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask_shell, connectivity=8)\n",
        "    smart_mask = np.zeros_like(mask_core)\n",
        "\n",
        "    for label_id in range(1, num_labels): # Skip background (0)\n",
        "        blob_mask = (labels == label_id).astype(np.uint8) * 255\n",
        "\n",
        "        # Check overlap with Core\n",
        "        overlap = cv2.bitwise_and(blob_mask, mask_core)\n",
        "\n",
        "        # If there is ANY overlap, keep the blob\n",
        "        if cv2.countNonZero(overlap) > 0:\n",
        "            smart_mask = cv2.bitwise_or(smart_mask, blob_mask)\n",
        "\n",
        "    # 5. Fill Holes (in case the goo has shiny reflections)\n",
        "    contours, _ = cv2.findContours(smart_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    final_filled_mask = np.zeros_like(smart_mask)\n",
        "    for contour in contours:\n",
        "        # Minimum area filter (200px) to remove tiny stray noise\n",
        "        if cv2.contourArea(contour) > 200:\n",
        "            cv2.drawContours(final_filled_mask, [contour], -1, (255), thickness=cv2.FILLED)\n",
        "\n",
        "    # 6. The \"1-Pixel Nudge\"\n",
        "    # Safely expand by 1 pixel to cover the final anti-aliased fringe\n",
        "    kernel = np.ones((3, 3), np.uint8)\n",
        "    final_expanded_mask = cv2.dilate(final_filled_mask, kernel, iterations=1)\n",
        "\n",
        "    return final_expanded_mask\n",
        "\n"
      ],
      "metadata": {
        "id": "tC7F6l59EwBc"
      },
      "id": "tC7F6l59EwBc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_goo(input_dir, output_dir, target_size=(224, 224), remove_goo=True, save_masks=True, replacement_color=(0, 0, 0)):\n",
        "    \"\"\"\n",
        "    Iterates through input_dir, finds 'img_xxxx', resizes them to target_size,\n",
        "    and saves the result to output_dir.\n",
        "    If remove_goo is True, it replaces green pixels (using Smart Core/Shell logic) with replacement_color.\n",
        "    replacement_color: Tuple of (B, G, R) values. Default is black (0, 0, 0).\n",
        "    \"\"\"\n",
        "    input_dir = Path(input_dir)\n",
        "    output_dir = Path(output_dir)\n",
        "\n",
        "    # Create output directory if it doesn't exist\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Extensions to look for\n",
        "    valid_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}\n",
        "\n",
        "    # 1. Gather all valid image files first\n",
        "    print(f\"Scanning for images in: {input_dir}...\")\n",
        "    image_files = [\n",
        "        f for f in input_dir.iterdir()\n",
        "        if f.name.startswith('img_') and f.suffix.lower() in valid_extensions\n",
        "    ]\n",
        "\n",
        "    if not image_files:\n",
        "        print(\"No images found starting with 'img_' in the directory.\")\n",
        "        return\n",
        "\n",
        "    # 2. Iterate with tqdm\n",
        "    count = 0\n",
        "\n",
        "    for file_path in tqdm(image_files, desc=\"Removing Goo from Images\", unit=\"img\"):\n",
        "        output_path = output_dir / file_path.name\n",
        "\n",
        "        if output_path.exists():\n",
        "            # Skip silently\n",
        "            continue\n",
        "\n",
        "        img = cv2.imread(str(file_path))\n",
        "        if img is None:\n",
        "            continue\n",
        "\n",
        "        if target_size is not None:\n",
        "            img = cv2.resize(img, target_size)\n",
        "\n",
        "        if remove_goo:\n",
        "            # --- NEW SMART GOO LOGIC ---\n",
        "            # Get the smart mask (White = Goo)\n",
        "            goo_mask = _get_smart_goo_mask(img)\n",
        "\n",
        "            # Invert Goo Mask (White = Safe)\n",
        "            not_goo_mask = cv2.bitwise_not(goo_mask)\n",
        "\n",
        "            # Apply Mask to keep safe areas (Goo areas become black/0)\n",
        "            img_safe = cv2.bitwise_and(img, img, mask=not_goo_mask)\n",
        "\n",
        "            # Create background with replacement color\n",
        "            bg = np.full_like(img, replacement_color)\n",
        "\n",
        "            # Keep background only where Goo is\n",
        "            bg_goo = cv2.bitwise_and(bg, bg, mask=goo_mask)\n",
        "\n",
        "            # Combine: Safe Image + Colored Goo Areas\n",
        "            img = cv2.add(img_safe, bg_goo)\n",
        "\n",
        "            if save_masks:\n",
        "                # Save the mask (White = Safe/Tissue, Black = Goo)\n",
        "                mask_name = file_path.name.replace('img_', 'goo_mask_', 1)\n",
        "                mask_output_path = os.path.join(output_dir, \"goo_masks\", mask_name)\n",
        "                Path(os.path.dirname(mask_output_path)).mkdir(parents=True, exist_ok=True)\n",
        "                cv2.imwrite(str(mask_output_path), not_goo_mask)\n",
        "\n",
        "        cv2.imwrite(str(output_path), img)\n",
        "        count += 1\n",
        "\n",
        "    print(f\"Resizing complete. Processed {count} new images.\")"
      ],
      "metadata": {
        "id": "D5u3WM3fEy6i"
      },
      "id": "D5u3WM3fEy6i",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_and_save_masks(goo_masks_dir, external_masks_dir, output_dir, target_size=(224, 224)):\n",
        "    \"\"\"\n",
        "    Loads goo masks (White=Safe) and original external masks.\n",
        "    Removes goo areas from external masks and saves the cleaned versions.\n",
        "    Skips processing if a cleaned mask already exists in the output directory.\n",
        "    \"\"\"\n",
        "    goo_masks_dir = Path(goo_masks_dir)\n",
        "    external_masks_dir = Path(external_masks_dir)\n",
        "    output_dir = Path(output_dir)\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    goo_mask_files = list(goo_masks_dir.glob('goo_mask_*.png'))\n",
        "\n",
        "    if not goo_mask_files:\n",
        "        print(f\"No goo masks found in {goo_masks_dir}\")\n",
        "        return\n",
        "\n",
        "    print(f\"Found {len(goo_mask_files)} goo masks. Checking for existing and processing new masks...\")\n",
        "\n",
        "    processed_count = 0\n",
        "    skipped_count = 0\n",
        "    for goo_mask_path in tqdm(goo_mask_files, desc=\"Cleaning External Masks\"):\n",
        "        # Derive the corresponding output mask name\n",
        "        mask_name = goo_mask_path.name.replace('goo_mask_', 'mask_', 1)\n",
        "        output_path = output_dir / mask_name\n",
        "\n",
        "\n",
        "        # Check if the cleaned mask already exists to skip reprocessing\n",
        "        if output_path.exists():\n",
        "            skipped_count += 1\n",
        "            continue\n",
        "\n",
        "\n",
        "        external_mask_path = external_masks_dir / mask_name\n",
        "\n",
        "        if not external_mask_path.exists():\n",
        "            # This part was commented out in the original, but it's good practice\n",
        "            # to log when a corresponding file is missing.\n",
        "            # tqdm.write(f\"Warning: External mask not found for {goo_mask_path.name}\")\n",
        "            continue\n",
        "\n",
        "        # Load masks\n",
        "        goo_mask = cv2.imread(str(goo_mask_path), cv2.IMREAD_GRAYSCALE)\n",
        "        external_mask = cv2.imread(str(external_mask_path), cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        if goo_mask is None or external_mask is None:\n",
        "            tqdm.write(f\"Warning: Could not read one of the masks for {mask_name}\")\n",
        "            continue\n",
        "\n",
        "        # Resize external mask if a target size is specified\n",
        "        if target_size is not None:\n",
        "             external_mask = cv2.resize(external_mask, target_size, interpolation=cv2.INTER_NEAREST)\n",
        "             # Ensure goo_mask also matches the target size\n",
        "             if goo_mask.shape[:2] != (target_size[1], target_size[0]):\n",
        "                 goo_mask = cv2.resize(goo_mask, target_size, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        # Ensure masks are binary (0 or 255)\n",
        "        _, external_mask = cv2.threshold(external_mask, 127, 255, cv2.THRESH_BINARY)\n",
        "        _, goo_mask = cv2.threshold(goo_mask, 127, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "        # Combine masks: The resulting pixel is white only if it's white in BOTH masks.\n",
        "        # This effectively removes \"goo\" areas from the \"region of interest\".\n",
        "        cleaned_mask = cv2.bitwise_and(external_mask, goo_mask)\n",
        "\n",
        "        # Save the final cleaned mask\n",
        "        cv2.imwrite(str(output_path), cleaned_mask)\n",
        "        processed_count += 1\n",
        "\n",
        "    print(\"\\nProcessing complete.\")\n",
        "    print(f\"  - Cleaned and saved: {processed_count} masks to {output_dir}\")\n",
        "    if skipped_count > 0:\n",
        "        print(f\"  - Skipped: {skipped_count} masks that already existed.\")"
      ],
      "metadata": {
        "id": "wp-JLl--EzoT"
      },
      "id": "wp-JLl--EzoT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_mask(image_path, mask_path, output_path, target_size=(224, 224), remove_goo=True):\n",
        "    \"\"\"\n",
        "    Loads an image and a mask.\n",
        "    If remove_goo is True, it subtracts green pixels (using Smart Core/Shell logic)\n",
        "    from the valid mask area. Resizes and saves the result.\n",
        "    \"\"\"\n",
        "    # 1. Load Image\n",
        "    img = cv2.imread(str(image_path))\n",
        "    if img is None:\n",
        "        tqdm.write(f\"Error: Could not load image at {image_path}\")\n",
        "        return\n",
        "\n",
        "    # 2. Load External Mask (Read as grayscale)\n",
        "    mask = cv2.imread(str(mask_path), 0)\n",
        "    if mask is None:\n",
        "        tqdm.write(f\"Error: Could not load mask at {mask_path}\")\n",
        "        return\n",
        "\n",
        "    # 3. Resize both to target size\n",
        "    if target_size is not None:\n",
        "        img = cv2.resize(img, target_size)\n",
        "        mask = cv2.resize(mask, target_size)\n",
        "\n",
        "    # 4. Standardize External Mask (Binary 0 or 255)\n",
        "    _, binary_mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # 5. Determine Final Mask\n",
        "    if remove_goo:\n",
        "        # --- NEW SMART GOO LOGIC ---\n",
        "        # Get the smart mask (White = Goo)\n",
        "        goo_mask = _get_smart_goo_mask(img)\n",
        "\n",
        "        # Invert Goo Mask (White = Safe)\n",
        "        not_goo_mask = cv2.bitwise_not(goo_mask)\n",
        "\n",
        "        # Combine: Must be Tissue (binary_mask) AND Safe (not_goo_mask)\n",
        "        final_mask = cv2.bitwise_and(binary_mask, not_goo_mask)\n",
        "    else:\n",
        "        # --- ORIGINAL LOGIC ---\n",
        "        final_mask = binary_mask\n",
        "\n",
        "    # 6. Apply Final Mask\n",
        "    # Areas outside the final mask become Black (0)\n",
        "    masked_img = cv2.bitwise_and(img, img, mask=final_mask)\n",
        "\n",
        "    # 7. Save result\n",
        "    # Ensure output directory exists\n",
        "    os.makedirs(os.path.dirname(str(output_path)), exist_ok=True)\n",
        "    cv2.imwrite(str(output_path), masked_img)"
      ],
      "metadata": {
        "id": "m1JcIs0yE402"
      },
      "id": "m1JcIs0yE402",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_bright_green_areas(image, lg_H=20, lg_S=45, lg_V=0, ug_H=84, ug_S=255, ug_V=255, dilate_iterations=2):\n",
        "    \"\"\"\n",
        "    Filters out bright green areas from the input image with improved residual removal.\n",
        "\n",
        "    Args:\n",
        "        image: Input image in RGB format (0-1 range)\n",
        "        lg_H, lg_S, lg_V: Lower bounds for HSV green detection\n",
        "        ug_H, ug_S, ug_V: Upper bounds for HSV green detection\n",
        "        dilate_iterations: Number of dilation iterations to expand mask (removes edge artifacts)\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert from RGB (0-1) to BGR (0-255) for OpenCV\n",
        "    original_bgr = (image * 255).astype(np.uint8)[..., ::-1]\n",
        "\n",
        "    # 1. Convert to HSV (Hue, Saturation, Value)\n",
        "    hsv = cv2.cvtColor(original_bgr, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # 2. Define the \"Bright Green\" Range\n",
        "    lower_green = (lg_H, lg_S, lg_V)\n",
        "    upper_green = (ug_H, ug_S, ug_V)\n",
        "\n",
        "    # Create the initial mask\n",
        "    mask = cv2.inRange(hsv, lower_green, upper_green)\n",
        "\n",
        "    # 3. Morphological operations to clean up the mask\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
        "\n",
        "    # OPEN: Remove small noise\n",
        "    clean_mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=2)\n",
        "\n",
        "    # DILATE: Expand the mask to catch edge artifacts and residuals\n",
        "    # This ensures we remove green pixels at the boundaries\n",
        "    if dilate_iterations > 0:\n",
        "        clean_mask = cv2.dilate(clean_mask, kernel, iterations=dilate_iterations)\n",
        "\n",
        "    # 4. Additional step: Detect any remaining green-ish pixels\n",
        "    # Create a more aggressive mask for subtle green tones\n",
        "    lower_green_subtle = (max(0, lg_H - 10), max(0, lg_S - 10), 0)\n",
        "    upper_green_subtle = (min(180, ug_H + 10), 255, 255)\n",
        "    subtle_mask = cv2.inRange(hsv, lower_green_subtle, upper_green_subtle)\n",
        "\n",
        "    # Only keep subtle green pixels that are near the main green area\n",
        "    subtle_mask = cv2.morphologyEx(subtle_mask, cv2.MORPH_OPEN, kernel, iterations=1)\n",
        "\n",
        "    # Combine masks\n",
        "    combined_mask = cv2.bitwise_or(clean_mask, subtle_mask)\n",
        "\n",
        "    # 5. Invert mask to keep the useful parts\n",
        "    mask_inv = cv2.bitwise_not(combined_mask)\n",
        "\n",
        "    # 6. Apply the mask\n",
        "    result_bgr = cv2.bitwise_and(original_bgr, original_bgr, mask=mask_inv)\n",
        "\n",
        "    return result_bgr, combined_mask"
      ],
      "metadata": {
        "id": "Ay-77OqfE7JB"
      },
      "id": "Ay-77OqfE7JB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_dataset_for_shreks(directory, shrek_dir, ratio_threshold=0.0125, expected_count=150):\n",
        "    \"\"\"\n",
        "    Analyzes images in a directory to classify them as \"shrek\" or \"tissue\".\n",
        "    \"\"\"\n",
        "\n",
        "    # --- Start of existing skip logic ---\n",
        "    shrek_dir_path = Path(shrek_dir)\n",
        "    if shrek_dir_path.is_dir():\n",
        "        num_existing_images = len(list(shrek_dir_path.glob('img_*.png')))\n",
        "        if num_existing_images == expected_count:\n",
        "            print(f\"'{shrek_dir}' already contains exactly {expected_count} images. Skipping analysis.\")\n",
        "            return [], []\n",
        "    # --- End of existing skip logic ---\n",
        "\n",
        "    shrek_images = []\n",
        "    tissue_images = []\n",
        "\n",
        "    # Escape the directory path so glob works with [ ] and other special chars\n",
        "    directory_escaped = glob.escape(directory)\n",
        "\n",
        "    # Search for multiple extensions (png, jpg, jpeg)\n",
        "    image_files = []\n",
        "    for ext in [\"png\", \"jpg\", \"jpeg\"]:\n",
        "        image_files.extend(glob.glob(os.path.join(directory_escaped, f'img_*.{ext}')))\n",
        "\n",
        "    print(f\"Found {len(image_files)} images in '{directory}'. Analyzing for 'Shreks'...\")\n",
        "\n",
        "    for f in tqdm(image_files, desc=\"Analyzing for Shreks\"):\n",
        "        try:\n",
        "            img = cv2.imread(f)\n",
        "            if img is None:\n",
        "                continue\n",
        "\n",
        "            img_rgb_norm = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
        "            result_bgr, mask = filter_bright_green_areas(img_rgb_norm)\n",
        "\n",
        "            total_pixels = img.shape[0] * img.shape[1]\n",
        "            green_pixels = np.count_nonzero(mask)\n",
        "            ratio = green_pixels / total_pixels\n",
        "\n",
        "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            entry = {\n",
        "                'name': os.path.basename(f),\n",
        "                'path': f,\n",
        "                'img': img_rgb,\n",
        "                'ratio': ratio,\n",
        "                'mask': mask\n",
        "            }\n",
        "\n",
        "            if ratio > ratio_threshold:\n",
        "                shrek_images.append(entry)\n",
        "            else:\n",
        "                tissue_images.append(entry)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Skipping {f}: {e}\")\n",
        "\n",
        "    return shrek_images, tissue_images\n"
      ],
      "metadata": {
        "id": "ig-0qkMs9EZI"
      },
      "id": "ig-0qkMs9EZI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_classification_results(shrek_list, tissue_list, shrek_dir, tissue_dir, threshold, visualize = True):\n",
        "    \"\"\"\n",
        "    Saves classified images to respective directories and visualizes the results.\n",
        "\n",
        "    Args:\n",
        "        shrek_list (list): List of dicts containing Shrek image data.\n",
        "        tissue_list (list): List of dicts containing Tissue image data.\n",
        "        shrek_dir (str): Path to save Shrek images.\n",
        "        tissue_dir (str): Path to save Tissue images.\n",
        "        threshold (float): The green ratio threshold used for classification.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Print Summary\n",
        "    print(f\"Classified {len(shrek_list)} as Shrek\")\n",
        "    print(f\"Classified {len(tissue_list)} as Tissue\")\n",
        "\n",
        "    # Ensure directories exist\n",
        "    os.makedirs(shrek_dir, exist_ok=True)\n",
        "    os.makedirs(tissue_dir, exist_ok=True)\n",
        "\n",
        "    # 2. Save Shrek images\n",
        "    print(f\"Saving {len(shrek_list)} Shrek images to {shrek_dir}...\")\n",
        "    for item in tqdm(shrek_list, desc=\"Saving Shrek Images\"):\n",
        "        dest_path = os.path.join(shrek_dir, item['name'])\n",
        "\n",
        "        # Check if file exists to prevent overwriting\n",
        "        if os.path.exists(dest_path):\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            shutil.copy2(item['path'], dest_path)\n",
        "        except Exception as e:\n",
        "            print(f\"Error copying {item['name']} to shrek folder: {e}\")\n",
        "\n",
        "    # 3. Save Tissue images\n",
        "    print(f\"Saving {len(tissue_list)} Tissue images to {tissue_dir}...\")\n",
        "    for item in tqdm(tissue_list, desc=\"Saving Tissue Images\"):\n",
        "        dest_path = os.path.join(tissue_dir, item['name'])\n",
        "\n",
        "        # Check if file exists to prevent overwriting\n",
        "        if os.path.exists(dest_path):\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            shutil.copy2(item['path'], dest_path)\n",
        "        except Exception as e:\n",
        "            print(f\"Error copying {item['name']} to tissue folder: {e}\")\n",
        "    if visualize == True:\n",
        "        # 4. Visualize Examples (2x2 Grid)\n",
        "        if len(shrek_list) >= 2 and len(tissue_list) >= 2:\n",
        "            fig_ex, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "            fig_ex.suptitle(f\"Classification Results (Threshold: {threshold:.1%})\", fontsize=16)\n",
        "\n",
        "            def show_img(ax, item, label):\n",
        "                ax.imshow(item['img'])\n",
        "                # Show the Green Ratio in the title so you can see WHY it was classified\n",
        "                ax.set_title(f\"{label}\\n{item['name']}\\nGreen Pixels: {item['ratio']:.2%}\")\n",
        "                ax.axis('off')\n",
        "\n",
        "            # Row 1: Detected Shrek\n",
        "            show_img(axes[0, 0], shrek_list[0], \"Detected Shrek\")\n",
        "            show_img(axes[0, 1], shrek_list[1], \"Detected Shrek\")\n",
        "\n",
        "            # Row 2: Detected Tissue\n",
        "            show_img(axes[1, 0], tissue_list[0], \"Detected Tissue\")\n",
        "            show_img(axes[1, 1], tissue_list[1], \"Detected Tissue\")\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(\"Not enough images in one or both classes to generate 2x2 sample grid.\")\n",
        "\n",
        "        # 5. Plot Scatter Distribution for Tuning\n",
        "        shrek_ratios = [x['ratio'] for x in shrek_list]\n",
        "        tissue_ratios = [x['ratio'] for x in tissue_list]\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "\n",
        "        # Plot Tissue points (Blue)\n",
        "        plt.scatter(range(len(tissue_ratios)), tissue_ratios, color='blue', alpha=0.6, label='Classified as Tissue')\n",
        "\n",
        "        # Plot Shrek points (Green) - Shifted on x-axis to be distinct\n",
        "        # We shift the x-axis index for Shrek so they appear after the tissue points\n",
        "        plt.scatter(range(len(tissue_ratios), len(tissue_ratios) + len(shrek_ratios)), shrek_ratios, color='green', alpha=0.6, label='Classified as Shrek')\n",
        "\n",
        "        # Draw the Threshold Line\n",
        "        plt.axhline(y=threshold, color='red', linestyle='--', linewidth=2, label=f'Threshold ({threshold:.1%})')\n",
        "\n",
        "        plt.title('Green Pixel Ratio per Image', fontsize=14)\n",
        "        plt.ylabel('Ratio of Green Pixels (0.0 - 1.0)')\n",
        "        plt.xlabel('Image Index')\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"Shrek removal visulization OFF.\")\n",
        "\n",
        "# --- Example Usage ---\n",
        "# shrek_list, tissue_list = analyze_dataset(DATASET_PATH) # Assuming this runs before\n",
        "# process_classification_results(shrek_list, tissue_list, SHREK_DIR, TISSUE_DIR, RATIO_THRESHOLD)"
      ],
      "metadata": {
        "id": "SgD7ZWRZFA9u"
      },
      "id": "SgD7ZWRZFA9u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def copy_masks(image_list, masks_dir, output_dir):\n",
        "    image_names = image_list\n",
        "    mask_names = [name.replace('img_', 'mask_', 1) for name in image_names]\n",
        "\n",
        "    for mask_name in tqdm(mask_names, desc=\"Copying Masks\"):\n",
        "        src_path = os.path.join(masks_dir, mask_name)\n",
        "        dst_path = os.path.join(output_dir, mask_name)\n",
        "        shutil.copy(src_path, dst_path)\n",
        "\n",
        "    return"
      ],
      "metadata": {
        "id": "0NvFppgaFDQb"
      },
      "id": "0NvFppgaFDQb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_smart_patches_old(img_path, mask_path, patch_size=320, stride=160, threshold=0.30):\n",
        "    \"\"\"\n",
        "    Intelligently extracts patches.\n",
        "    UPDATED: Groups nearby tumor spots and centers the patch on the region.\n",
        "    \"\"\"\n",
        "    # Load images\n",
        "    try:\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "    except FileNotFoundError:\n",
        "        # Fallback for common extension swap if .png not found\n",
        "        if img_path.endswith(\".png\"):\n",
        "            img = Image.open(img_path.replace(\".png\", \".jpg\")).convert(\"RGB\")\n",
        "        else:\n",
        "            raise\n",
        "\n",
        "    mask = Image.open(mask_path).convert(\"L\")\n",
        "    img_arr = np.array(img)\n",
        "    mask_arr = np.array(mask)\n",
        "\n",
        "    # Normalize mask\n",
        "    if mask_arr.max() <= 1:\n",
        "        mask_check = mask_arr * 255\n",
        "    else:\n",
        "        mask_check = mask_arr\n",
        "\n",
        "    h, w, _ = img_arr.shape\n",
        "\n",
        "    if isinstance(patch_size, int):\n",
        "        ph, pw = patch_size, patch_size\n",
        "    else:\n",
        "        ph, pw = patch_size\n",
        "\n",
        "    if isinstance(stride, int):\n",
        "        sh, sw = stride, stride\n",
        "    else:\n",
        "        sh, sw = stride\n",
        "\n",
        "    # --- Intelligent Extraction Logic ---\n",
        "\n",
        "    # 1. GROUPING: Dilate the mask to merge nearby small dots into larger regions.\n",
        "    # This prevents generating 1 patch per pixel-sized dot.\n",
        "    # iterations=15 means dots within ~15 pixels of each other get merged.\n",
        "    dilated_mask = ndimage.binary_dilation(mask_check > 128, iterations=10)\n",
        "\n",
        "    # 2. Label the merged regions\n",
        "    labeled_mask, num_features = ndimage.label(dilated_mask)\n",
        "    objects = ndimage.find_objects(labeled_mask)\n",
        "\n",
        "    candidate_coords = set()\n",
        "\n",
        "    def get_valid_start(val, max_val, p_dim):\n",
        "        return max(0, min(val, max_val - p_dim))\n",
        "\n",
        "    # print(f\"Found {num_features} clustered tumor regions.\") # Commented out for batch processing\n",
        "\n",
        "    for i, slice_obj in enumerate(objects):\n",
        "        y_slice, x_slice = slice_obj\n",
        "\n",
        "        # Region boundaries\n",
        "        y_min, y_max = y_slice.start, y_slice.stop\n",
        "        x_min, x_max = x_slice.start, x_slice.stop\n",
        "\n",
        "        # --- Strategy: Center on Blob ---\n",
        "        # We calculate the center of the blob and place the patch there.\n",
        "\n",
        "        blob_cy = (y_min + y_max) // 2\n",
        "        blob_cx = (x_min + x_max) // 2\n",
        "\n",
        "        # Top-left corner for the patch to be centered on the blob center\n",
        "        start_y = blob_cy - ph // 2\n",
        "        start_x = blob_cx - pw // 2\n",
        "\n",
        "        valid_y = get_valid_start(start_y, h, ph)\n",
        "        valid_x = get_valid_start(start_x, w, pw)\n",
        "\n",
        "        candidate_coords.add((valid_x, valid_y))\n",
        "\n",
        "    # 3. Final Validation\n",
        "    patches = []\n",
        "    coords = []\n",
        "\n",
        "    for (x, y) in candidate_coords:\n",
        "        mask_patch = mask_check[y:y+ph, x:x+pw]\n",
        "        img_patch = img_arr[y:y+ph, x:x+pw]\n",
        "\n",
        "        # Use Tissue Threshold (non-white pixels)\n",
        "        img_gray = np.mean(img_patch, axis=2)\n",
        "        tissue_ratio = np.sum(img_gray < 235) / (ph * pw)\n",
        "\n",
        "        # Use Mask Threshold (tumor pixels)\n",
        "        mask_ratio = np.sum(mask_patch > 128) / (ph * pw)\n",
        "\n",
        "        # Keep patch only if it has enough tumor AND enough tissue\n",
        "        if mask_ratio >= threshold and tissue_ratio > 0.15:\n",
        "            patches.append(img_patch)\n",
        "            coords.append((x, y))\n",
        "\n",
        "    return patches, coords, img_arr, mask_arr"
      ],
      "metadata": {
        "id": "aIGvJOS6FFgR"
      },
      "id": "aIGvJOS6FFgR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_smart_patches(img_path, mask_path, patch_size=320, stride=160, threshold=0.30):\n",
        "    \"\"\"\n",
        "    Smart extraction with BLOB SPLITTING:\n",
        "    - If a blob is larger than the patch size, split its bounding box\n",
        "      into a grid and extract multiple patch centroids.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load images\n",
        "    try:\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "    except FileNotFoundError:\n",
        "        if img_path.endswith(\".png\"):\n",
        "            img = Image.open(img_path.replace(\".png\", \".jpg\")).convert(\"RGB\")\n",
        "        else:\n",
        "            raise\n",
        "\n",
        "    mask = Image.open(mask_path).convert(\"L\")\n",
        "    img_arr = np.array(img)\n",
        "    mask_arr = np.array(mask)\n",
        "\n",
        "    # Normalize mask\n",
        "    if mask_arr.max() <= 1:\n",
        "        mask_check = mask_arr * 255\n",
        "    else:\n",
        "        mask_check = mask_arr\n",
        "\n",
        "    h, w, _ = img_arr.shape\n",
        "    ph, pw = patch_size, patch_size\n",
        "    sh, sw = stride, stride\n",
        "\n",
        "    # --- 1. DILATE (same as original)\n",
        "    dilated_mask = ndimage.binary_dilation(mask_check > 128, iterations=10)\n",
        "\n",
        "    # --- 2. CONNECTED COMPONENTS\n",
        "    labeled_mask, num_features = ndimage.label(dilated_mask)\n",
        "    objects = ndimage.find_objects(labeled_mask)\n",
        "\n",
        "    candidate_coords = set()\n",
        "\n",
        "    def clamp(val, max_val, size):\n",
        "        return max(0, min(val, max_val - size))\n",
        "\n",
        "    # --- 3. PROCESS EACH BLOB\n",
        "    for slice_obj in objects:\n",
        "        y_slice, x_slice = slice_obj\n",
        "        y_min, y_max = y_slice.start, y_slice.stop\n",
        "        x_min, x_max = x_slice.start, x_slice.stop\n",
        "\n",
        "        blob_h = y_max - y_min\n",
        "        blob_w = x_max - x_min\n",
        "\n",
        "        # ------------------------------\n",
        "        # NEW PART: BLOB SPLITTING LOGIC\n",
        "        # ------------------------------\n",
        "\n",
        "        # How many patch centers we insert along each dimension?\n",
        "        n_h = max(1, int(np.ceil(blob_h / ph)))\n",
        "        n_w = max(1, int(np.ceil(blob_w / pw)))\n",
        "\n",
        "        # For each cell of the grid, we compute a pseudo-centroid\n",
        "        for i in range(n_h):\n",
        "            for j in range(n_w):\n",
        "\n",
        "                cy = y_min + int((i + 0.5) * (blob_h / n_h))\n",
        "                cx = x_min + int((j + 0.5) * (blob_w / n_w))\n",
        "\n",
        "                # Convert centroid to top-left patch corner\n",
        "                start_y = clamp(cy - ph // 2, h, ph)\n",
        "                start_x = clamp(cx - pw // 2, w, pw)\n",
        "\n",
        "                candidate_coords.add((start_x, start_y))\n",
        "\n",
        "    # -------------------------------------------------------\n",
        "    # 4. FINAL VALIDATION (unchanged from your working code)\n",
        "    # -------------------------------------------------------\n",
        "\n",
        "    patches = []\n",
        "    coords = []\n",
        "\n",
        "    for (x, y) in candidate_coords:\n",
        "        mask_patch = mask_check[y:y+ph, x:x+pw]\n",
        "        img_patch = img_arr[y:y+ph, x:x+pw]\n",
        "\n",
        "        # tissue ratio\n",
        "        img_gray = np.mean(img_patch, axis=2)\n",
        "        tissue_ratio = np.sum(img_gray < 235) / (ph * pw)\n",
        "\n",
        "        # mask ratio\n",
        "        mask_ratio = np.sum(mask_patch > 128) / (ph * pw)\n",
        "\n",
        "        if mask_ratio >= threshold and tissue_ratio > 0.15:\n",
        "            patches.append(img_patch)\n",
        "            coords.append((x, y))\n",
        "\n",
        "    return patches, coords, img_arr, mask_arr\n"
      ],
      "metadata": {
        "id": "S_p0H8dTxCrE"
      },
      "id": "S_p0H8dTxCrE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_patches_dataset(input_dir, output_dir, mask_dir, patch_size=224, stride=224, threshold=0.01):\n",
        "    \"\"\"\n",
        "    Iterates over images in input_dir, finds corresponding masks in mask_dir,\n",
        "    extracts smart patches, and saves them to output_dir.\n",
        "    Also saves corresponding mask patches to a 'masks' subdirectory.\n",
        "\n",
        "    This function will skip processing for any source image if its corresponding\n",
        "    patches are already found in the output directory.\n",
        "    \"\"\"\n",
        "    input_dir = Path(input_dir)\n",
        "    output_dir = Path(output_dir)\n",
        "    mask_dir = Path(mask_dir)\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Create subdirectory for mask patches\n",
        "    masks_output_dir = output_dir / \"masks\"\n",
        "    masks_output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Filter for image files\n",
        "    image_files = sorted([\n",
        "        f for f in input_dir.iterdir()\n",
        "        if f.name.startswith('img_') and f.suffix.lower() in {'.png', '.jpg', '.jpeg'}\n",
        "    ])\n",
        "\n",
        "    total_patches_saved = 0\n",
        "    images_processed = 0\n",
        "    images_skipped = 0\n",
        "\n",
        "    print(f\"Starting patch extraction from {input_dir} to {output_dir}...\")\n",
        "    print(f\"Found {len(image_files)} source images.\")\n",
        "\n",
        "    for source_image_path in tqdm(image_files, desc=\"Processing Images\"):\n",
        "        base_name = source_image_path.stem\n",
        "\n",
        "        # --- CHECK FOR EXISTING PATCHES ---\n",
        "        # Check if any patch file for this image already exists.\n",
        "        # We use glob to find files matching the pattern like 'img_xxxx_p*.png'.\n",
        "        # next() with a default value is an efficient way to check for existence\n",
        "        # without listing all files.\n",
        "        if next(output_dir.glob(f\"{base_name}_p*.png\"), None):\n",
        "            # tqdm.write(f\"Skipping {source_image_path.name}, patches already exist.\")\n",
        "            images_skipped += 1\n",
        "            continue\n",
        "\n",
        "        # Construct mask filename (e.g., 'img_xxxx.png' -> 'mask_xxxx.png')\n",
        "        mask_name = source_image_path.name.replace('img_', 'mask_', 1)\n",
        "        mask_path = mask_dir / mask_name\n",
        "\n",
        "        # Fallback if mask has a different extension or wasn't found initially\n",
        "        if not mask_path.exists():\n",
        "             mask_path = mask_dir / (base_name.replace('img_', 'mask_', 1) + \".png\")\n",
        "\n",
        "        if mask_path.exists():\n",
        "            # Extract patches\n",
        "            patches, coords, _, mask_arr = extract_smart_patches(\n",
        "                str(source_image_path),\n",
        "                str(mask_path),\n",
        "                patch_size=patch_size,\n",
        "                stride=stride,\n",
        "                threshold=threshold\n",
        "            )\n",
        "\n",
        "            if not patches:\n",
        "                continue\n",
        "\n",
        "            # Save each patch and corresponding mask patch\n",
        "            for i, (patch_array, (x, y)) in enumerate(zip(patches, coords)):\n",
        "                # Save image patch\n",
        "                patch_img = Image.fromarray(patch_array)\n",
        "                save_name = f\"{base_name}_p{i}.png\"\n",
        "                patch_img.save(output_dir / save_name)\n",
        "\n",
        "                # Extract and save mask patch\n",
        "                if isinstance(patch_size, int):\n",
        "                    ph, pw = patch_size, patch_size\n",
        "                else:\n",
        "                    ph, pw = patch_size\n",
        "\n",
        "                mask_patch = mask_arr[y:y+ph, x:x+pw]\n",
        "                mask_patch_img = Image.fromarray(mask_patch)\n",
        "                mask_save_name = f\"mask_{base_name.replace('img_', '')}_p{i}.png\"\n",
        "                mask_patch_img.save(masks_output_dir / mask_save_name)\n",
        "\n",
        "            total_patches_saved += len(patches)\n",
        "            images_processed += 1\n",
        "        else:\n",
        "            tqdm.write(f\"Warning: Mask not found for {source_image_path.name}\")\n",
        "\n",
        "    print(\"\\n--- Extraction Summary ---\")\n",
        "    print(f\"Images Processed: {images_processed}\")\n",
        "    print(f\"Images Skipped:   {images_skipped}\")\n",
        "    print(f\"Total Patches Saved in this run: {total_patches_saved}\")\n",
        "    print(f\"Patches are located in: {output_dir}\")\n",
        "    print(f\"Mask patches are located in: {masks_output_dir}\")"
      ],
      "metadata": {
        "id": "o0LTGvg-FH5S"
      },
      "id": "o0LTGvg-FH5S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_patch_masks_to_images(patches_dir, masks_dir=None, output_dir=None):\n",
        "    \"\"\"Apply mask patches to image patches and save masked outputs.\n",
        "    Args:\n",
        "        patches_dir: directory with img_*_p*.png\n",
        "        masks_dir: directory with mask_*_p*.png (default: patches_dir / 'masks')\n",
        "        output_dir: destination for masked patches (default: patches_dir / 'masked')\n",
        "    \"\"\"\n",
        "    patches_dir = Path(patches_dir)\n",
        "    masks_dir = Path(masks_dir) if masks_dir else patches_dir / \"masks\"\n",
        "    output_dir = Path(output_dir) if output_dir else patches_dir / \"masked\"\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    patch_files = sorted(patches_dir.glob(\"img_*_p*.png\"))\n",
        "    if not patch_files:\n",
        "        print(f\"No patch images found in {patches_dir}\")\n",
        "        return\n",
        "\n",
        "    applied, skipped = 0, 0\n",
        "    for patch_path in tqdm(patch_files, desc=\"Applying mask patches\"):\n",
        "        mask_name = patch_path.stem.replace(\"img_\", \"mask_\", 1) + patch_path.suffix\n",
        "        mask_path = masks_dir / mask_name\n",
        "        out_path = output_dir / patch_path.name\n",
        "\n",
        "        if out_path.exists():\n",
        "            skipped += 1\n",
        "            continue\n",
        "        if not mask_path.exists():\n",
        "            tqdm.write(f\"Mask not found for {patch_path.name}\")\n",
        "            continue\n",
        "\n",
        "        img = np.array(Image.open(patch_path).convert(\"RGB\"))\n",
        "        mask = np.array(Image.open(mask_path).convert(\"L\"))\n",
        "        if mask.shape[:2] != img.shape[:2]:\n",
        "            mask = np.array(Image.open(mask_path).convert(\"L\").resize((img.shape[1], img.shape[0]), Image.NEAREST))\n",
        "\n",
        "        mask_bin = (mask > 127).astype(np.uint8)\n",
        "        masked = cv2.bitwise_and(img, img, mask=mask_bin)\n",
        "        Image.fromarray(masked).save(out_path)\n",
        "        applied += 1\n",
        "\n",
        "    print(f\"Applied masks to {applied} patches. Skipped {skipped} existing outputs. Results in: {output_dir}\")"
      ],
      "metadata": {
        "id": "UCSf2f5NPEJs"
      },
      "id": "UCSf2f5NPEJs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_blur_batch(images_dir, masks_dir, output_dir, blur_strength=(51, 51)):\n",
        "    \"\"\"\n",
        "    Applies the blur mask logic to all images in a directory.\n",
        "    Assumes mask filenames match image filenames.\n",
        "    \"\"\"\n",
        "    # 1. Create output directory if it doesn't exist\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "        print(f\"Created output directory: {output_dir}\")\n",
        "\n",
        "    # 2. Iterate through files in the images directory\n",
        "    supported_extensions = ('.png', '.jpg', '.jpeg', '.bmp', '.tiff')\n",
        "    files = [f for f in os.listdir(images_dir) if f.lower().endswith(supported_extensions)]\n",
        "\n",
        "    print(f\"Found {len(files)} images to process.\")\n",
        "\n",
        "    for filename in tqdm(files, desc=\"Processing images\", unit=\"img\"):\n",
        "        img_path = os.path.join(images_dir, filename)\n",
        "        mask_filename = filename.replace('img_', 'mask_', 1) if filename.startswith('img_') else filename\n",
        "        mask_path = os.path.join(masks_dir, mask_filename)\n",
        "        output_path = os.path.join(output_dir, filename)\n",
        "\n",
        "        # 3. Validation\n",
        "        if not os.path.exists(mask_path):\n",
        "            print(f\"Skipping {filename}: No corresponding mask found at {mask_path}\")\n",
        "            continue\n",
        "\n",
        "        # 4. Load images\n",
        "        img = cv2.imread(img_path)\n",
        "        mask = cv2.imread(mask_path, 0) # Load mask as grayscale\n",
        "\n",
        "        if img is None or mask is None:\n",
        "            print(f\"Error: Could not load data for {filename}\")\n",
        "            continue\n",
        "\n",
        "        # 5. Resize mask if dimensions don't match\n",
        "        if img.shape[:2] != mask.shape:\n",
        "            # print(f\"Resizing mask for {filename}\")\n",
        "            mask = cv2.resize(mask, (img.shape[1], img.shape[0]))\n",
        "\n",
        "        # 6. Apply Blur Logic\n",
        "        blurred_img = cv2.GaussianBlur(img, blur_strength, 0)\n",
        "\n",
        "        # Ensure mask is binary: White (255) = Intact, Black (0) = Blurred\n",
        "        _, binary_mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "        # Region A: Intact (where mask is 255)\n",
        "        intact_parts = cv2.bitwise_and(img, img, mask=binary_mask)\n",
        "\n",
        "        # Region B: Blurred (where mask is 0)\n",
        "        mask_inverted = cv2.bitwise_not(binary_mask)\n",
        "        blurred_parts = cv2.bitwise_and(blurred_img, blurred_img, mask=mask_inverted)\n",
        "\n",
        "        # Combine\n",
        "        result = cv2.add(intact_parts, blurred_parts)\n",
        "\n",
        "        # 7. Save Result\n",
        "        cv2.imwrite(output_path, result)\n"
      ],
      "metadata": {
        "id": "INX9K-hEFKIx"
      },
      "id": "INX9K-hEFKIx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "490fcb3f",
      "metadata": {
        "id": "490fcb3f"
      },
      "source": [
        "## **2. Data Loading**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30b5f384",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30b5f384",
        "outputId": "50ea5f57-e1db-4779-efce-a45c91d428b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset path: /gdrive/My Drive/AN2DL Challenge 2\n",
            "Train data path: /gdrive/My Drive/AN2DL Challenge 2/train_data\n",
            "Train labels path: /gdrive/My Drive/AN2DL Challenge 2/train_labels.csv\n",
            "Test data path: /gdrive/My Drive/AN2DL Challenge 2/test_data\n"
          ]
        }
      ],
      "source": [
        "# Assume datasets are in the current working directory, which is now correctly formatted\n",
        "datasets_path = current_dir\n",
        "\n",
        "train_data_path = os.path.join(datasets_path, \"train_data\")\n",
        "train_labels_path = os.path.join(datasets_path, \"train_labels.csv\")\n",
        "test_data_path = os.path.join(datasets_path, \"test_data\")\n",
        "\n",
        "print(f\"Dataset path: {datasets_path}\")\n",
        "print(f\"Train data path: {train_data_path}\")\n",
        "print(f\"Train labels path: {train_labels_path}\")\n",
        "print(f\"Test data path: {test_data_path}\")\n",
        "\n",
        "CSV_PATH = train_labels_path                # Path to the CSV file with labels\n",
        "SOURCE_FOLDER = train_data_path             # Folder containing img_xxxx and mask_xxxx\n",
        "\n",
        "# PREPROCESSING OUTPUT PATHS\n",
        "# preprocessing step 1 output path\n",
        "GOO_REMOVAL_OUT = os.path.join(datasets_path, \"preprocessing_results_masked\",\"train_nogoo\")\n",
        "\n",
        "# preprocessing step 2 output path\n",
        "SHREK_REMOVAL_OUT = os.path.join(datasets_path, \"preprocessing_results_masked\",\"train_noshreks\")\n",
        "SHREKS_OUT = os.path.join(SHREK_REMOVAL_OUT, \"train_shreks\")\n",
        "TISSUE_OUT = os.path.join(SHREK_REMOVAL_OUT, \"train_tissue\")\n",
        "\n",
        "# where the resized unmasked images will be saved\n",
        "PATCHES_OUT = os.path.join(datasets_path, \"preprocessing_results_masked\",\"train_patches\")\n",
        "# BLURRED_OUT = os.path.join(datasets_path, \"preprocessing_results\",\"train_patches_blurred\")\n",
        "PATCHES_OUT_MASKED = os.path.join(datasets_path, \"preprocessing_results_masked\",\"train_patches_masked\")\n",
        "\n",
        "\n",
        "SUBMISSION_SOURCE_FOLDER = os.path.join(datasets_path, \"test_data\")\n",
        "SUBMISSION_PATCHES_OUT = os.path.join(datasets_path, \"preprocessing_results_masked\",\"submission_patches\")\n",
        "# SUBMISSION_BLURRED_OUT = os.path.join(datasets_path, \"preprocessing_results\",\"submission_patches_blurred\")\n",
        "\n",
        "TARGET_SIZE = (320, 320)                    # Target size for the resized images and masks\n",
        "Target_dimension = 320\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Remove goo and do not resize images\n",
        "remove_goo(SOURCE_FOLDER, GOO_REMOVAL_OUT, target_size=None, remove_goo=True, save_masks=True, replacement_color=(195, 195, 195))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ad6J9ihuIuDN",
        "outputId": "7fcd0fc0-c8c3-4e7f-8b0e-5f087e9e68ce"
      },
      "id": "Ad6J9ihuIuDN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scanning for images in: /gdrive/My Drive/AN2DL Challenge 2/train_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Removing Goo from Images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 691/691 [00:03<00:00, 213.76img/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resizing complete. Processed 0 new images.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_and_save_masks(\n",
        "    goo_masks_dir=os.path.join(GOO_REMOVAL_OUT, \"goo_masks\"),\n",
        "    external_masks_dir=SOURCE_FOLDER,\n",
        "    output_dir=os.path.join(GOO_REMOVAL_OUT, \"cleaned_masks\"),\n",
        "    target_size=None\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8WO9J0rIw0M",
        "outputId": "30165da8-7d1f-479c-a405-b72eeba1c843"
      },
      "id": "q8WO9J0rIw0M",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 691 goo masks. Checking for existing and processing new masks...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Cleaning External Masks: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 691/691 [00:00<00:00, 2539.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing complete.\n",
            "  - Cleaned and saved: 0 masks to /gdrive/My Drive/AN2DL Challenge 2/preprocessing_results_masked/train_nogoo/cleaned_masks\n",
            "  - Skipped: 691 masks that already existed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Just a check\n",
        "\n",
        "import glob, os\n",
        "\n",
        "path = \"/gdrive/My Drive/[2025 - 2026] AN2DL/Challenge 2/preprocessing_results_masked/train_nogoo\"\n",
        "\n",
        "escaped_path = glob.escape(path)\n",
        "\n",
        "files = glob.glob(os.path.join(escaped_path, \"img_*.png\"))\n",
        "\n",
        "print(\"FOUND:\", len(files))\n",
        "print(files[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Cjd009p7Ut4",
        "outputId": "ffa83468-f18b-4218-9ff7-f1f9094420f6"
      },
      "id": "4Cjd009p7Ut4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOUND: 691\n",
            "['/gdrive/My Drive/AN2DL Challenge 2/preprocessing_results_masked/train_nogoo/img_0390.png', '/gdrive/My Drive/AN2DL Challenge 2/preprocessing_results_masked/train_nogoo/img_0375.png', '/gdrive/My Drive/AN2DL Challenge 2/preprocessing_results_masked/train_nogoo/img_0382.png', '/gdrive/My Drive/AN2DL Challenge 2/preprocessing_results_masked/train_nogoo/img_0373.png', '/gdrive/My Drive/AN2DL Challenge 2/preprocessing_results_masked/train_nogoo/img_0380.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Discard Shrek Images\n",
        "shreks_list, tissue_list = analyze_dataset_for_shreks(\n",
        "    GOO_REMOVAL_OUT,\n",
        "    shrek_dir=SHREKS_OUT,\n",
        "    ratio_threshold=0.0125,\n",
        "    expected_count=150\n",
        ")\n",
        "\n",
        "# Process results as before\n",
        "process_classification_results(\n",
        "    shreks_list,\n",
        "    tissue_list,\n",
        "    SHREKS_OUT,\n",
        "    TISSUE_OUT,\n",
        "    0.0125,\n",
        "    visualize=False\n",
        ")\n",
        "\n",
        "# Extract image names from tissue_list\n",
        "tissue_image_names = [item['name'] for item in tissue_list]\n",
        "\n",
        "# Copy masks based on image names\n",
        "copy_masks(tissue_image_names, SOURCE_FOLDER, TISSUE_OUT)\n",
        "\n",
        "# Clean up memory\n",
        "del shreks_list, tissue_list\n",
        "gc.collect()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmp9c9Pn8BPR",
        "outputId": "0bca5039-e9e4-4965-cd49-b833e99a6f98"
      },
      "id": "lmp9c9Pn8BPR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 691 images in '/gdrive/My Drive/AN2DL Challenge 2/preprocessing_results_masked/train_nogoo'. Analyzing for 'Shreks'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Analyzing for Shreks: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 691/691 [02:04<00:00,  5.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classified 60 as Shrek\n",
            "Classified 631 as Tissue\n",
            "Saving 60 Shrek images to /gdrive/My Drive/AN2DL Challenge 2/preprocessing_results_masked/train_noshreks/train_shreks...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving Shrek Images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:00<00:00, 2794.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 631 Tissue images to /gdrive/My Drive/AN2DL Challenge 2/preprocessing_results_masked/train_noshreks/train_tissue...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving Tissue Images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 631/631 [00:00<00:00, 3479.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shrek removal visulization OFF.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying Masks: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 631/631 [09:10<00:00,  1.15it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CLEANED_MASKS_DIR = os.path.join(GOO_REMOVAL_OUT, \"cleaned_masks\")\n",
        "\n",
        "create_patches_dataset(\n",
        "    TISSUE_OUT,\n",
        "    PATCHES_OUT,\n",
        "    mask_dir=CLEANED_MASKS_DIR,\n",
        "    patch_size=320,\n",
        "    stride=160,\n",
        "    threshold=0.001\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oagrp5pI2GT",
        "outputId": "09b6bd96-9cc1-419b-af47-899f11ea64f2"
      },
      "id": "0oagrp5pI2GT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting patch extraction from /gdrive/My Drive/AN2DL Challenge 2/preprocessing_results_masked/train_noshreks/train_tissue to /gdrive/My Drive/AN2DL Challenge 2/preprocessing_results_masked/train_patches...\n",
            "Found 631 source images.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 631/631 [11:01<00:00,  1.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Extraction Summary ---\n",
            "Images Processed: 631\n",
            "Images Skipped:   0\n",
            "Total Patches Saved in this run: 3546\n",
            "Patches are located in: /gdrive/My Drive/AN2DL Challenge 2/preprocessing_results_masked/train_patches\n",
            "Mask patches are located in: /gdrive/My Drive/AN2DL Challenge 2/preprocessing_results_masked/train_patches/masks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# os.makedirs(BLURRED_OUT, exist_ok=True)\n",
        "# apply_blur_batch(\n",
        "#     images_dir=PATCHES_OUT,\n",
        "#     masks_dir=os.path.join(PATCHES_OUT, \"masks\"),\n",
        "#     output_dir=BLURRED_OUT,\n",
        "#     blur_strength=(51, 51)\n",
        "# )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adT4XCA1I5Je",
        "outputId": "1235ab5f-3bba-43a0-ebf3-581f34f01342"
      },
      "id": "adT4XCA1I5Je",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 images to process.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing images: 0img [00:00, ?img/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the masks\n",
        "apply_patch_masks_to_images(PATCHES_OUT, output_dir=PATCHES_OUT_MASKED)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHSuACNyPasz",
        "outputId": "49c3e0b1-d80e-4f57-f467-50cf6949804b"
      },
      "id": "OHSuACNyPasz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No patch images found in /gdrive/My Drive/[2025 - 2026] AN2DL/Challenge 2/preprocessing_results_masked/train_patches\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PREPROCESS THE TEST SET FOR SUBMISSION"
      ],
      "metadata": {
        "id": "zg_drLqCPuG8"
      },
      "id": "zg_drLqCPuG8"
    },
    {
      "cell_type": "code",
      "source": [
        "SUBMISSION_PATCHES_OUT = os.path.join(datasets_path, \"preprocessing_results_masked\",\"submission_patches\")\n",
        "SUBMISSION_SOURCE_FOLDER = os.path.join(datasets_path, \"test_data\")\n",
        "\n",
        "create_patches_dataset(\n",
        "    SUBMISSION_SOURCE_FOLDER,\n",
        "    SUBMISSION_PATCHES_OUT,\n",
        "    mask_dir=SUBMISSION_SOURCE_FOLDER,\n",
        "    patch_size=320,\n",
        "    stride=160,\n",
        "    threshold=0.001\n",
        ")\n",
        "\n",
        "SUBMISSION_PATCHES_OUT_MASKED = os.path.join(datasets_path, \"preprocessing_results_masked\",\"submission_patches_masked\")\n",
        "\n",
        "# apply_patch_masks_to_images(SUBMISSION_PATCHES_OUT, output_dir=SUBMISSION_PATCHES_OUT_MASKED)"
      ],
      "metadata": {
        "id": "Bb5ecXaMPtWc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40e47948-301e-4788-d087-a8e8051e5327"
      },
      "id": "Bb5ecXaMPtWc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting patch extraction from /gdrive/My Drive/AN2DL Challenge 2/test_data to /gdrive/My Drive/AN2DL Challenge 2/preprocessing_results_masked/submission_patches...\n",
            "Found 477 source images.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 477/477 [05:38<00:00,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Extraction Summary ---\n",
            "Images Processed: 477\n",
            "Images Skipped:   0\n",
            "Total Patches Saved in this run: 2595\n",
            "Patches are located in: /gdrive/My Drive/AN2DL Challenge 2/preprocessing_results_masked/submission_patches\n",
            "Mask patches are located in: /gdrive/My Drive/AN2DL Challenge 2/preprocessing_results_masked/submission_patches/masks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}